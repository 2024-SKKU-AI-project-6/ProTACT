{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Load autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload behavior\n",
    "%autoreload 2\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from models.ProTACT import ProTACT\n",
    "from models.Loss import LossFunctions\n",
    "from configs.configs import Configs\n",
    "from utils.read_data_pr import read_pos_vocab, read_word_vocab, read_prompts_we, read_essays_prompts, read_prompts_pos\n",
    "from utils.general_utils import get_scaled_down_scores, pad_hierarchical_text_sequences, get_attribute_masks, load_word_embedding_dict, build_embedd_table\n",
    "from evaluators.multitask_evaluator_all_attributes import Evaluator as AllAttEvaluator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Test prompt id is 1 of type <class 'int'>\n",
      "Seed: 1\n",
      "Numhead :  2  | Features :  ../data/hand_crafted_v3.csv  | Pos_emb :  50\n"
     ]
    }
   ],
   "source": [
    "# print(\"main started\")\n",
    "# parser = argparse.ArgumentParser(description=\"ProTACT model\")\n",
    "# parser.add_argument('--test_prompt_id', type=int,\n",
    "#                     default=1, help='prompt id of test essay set')\n",
    "# parser.add_argument('--seed', type=int, default=12, help='set random seed')\n",
    "# parser.add_argument('--model_name', type=str,\n",
    "#                     choices=['ProTACT'],\n",
    "#                     help='name of model')\n",
    "# parser.add_argument('--num_heads', type=int, default=2,\n",
    "#                     help='set the number of heads in Multihead Attention')\n",
    "# parser.add_argument('--features_path', type=str,\n",
    "#                     default='data/hand_crafted_v3.csv')\n",
    "test_prompt_id = 1\n",
    "seed = 1\n",
    "num_heads = 2\n",
    "features_path = '../data/hand_crafted_v3.csv'\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(\"Test prompt id is {} of type {}\".format(\n",
    "    test_prompt_id, type(test_prompt_id)))\n",
    "print(\"Seed: {}\".format(seed))\n",
    "\n",
    "configs = Configs()\n",
    "\n",
    "data_path = configs.DATA_PATH\n",
    "train_path = data_path + str(test_prompt_id) + '/train.pk'\n",
    "dev_path = data_path + str(test_prompt_id) + '/dev.pk'\n",
    "test_path = data_path + str(test_prompt_id) + '/test.pk'\n",
    "pretrained_embedding = configs.PRETRAINED_EMBEDDING\n",
    "embedding_path = configs.EMBEDDING_PATH\n",
    "readability_path = configs.READABILITY_PATH\n",
    "prompt_path = configs.PROMPT_PATH\n",
    "vocab_size = configs.VOCAB_SIZE\n",
    "epochs = configs.EPOCHS\n",
    "batch_size = configs.BATCH_SIZE\n",
    "print(\"Numhead : \", num_heads, \" | Features : \",\n",
    "      features_path, \" | Pos_emb : \", configs.EMBEDDING_DIM)\n",
    "\n",
    "read_configs = {\n",
    "    'train_path': train_path,\n",
    "    'dev_path': dev_path,\n",
    "    'test_path': test_path,\n",
    "    'features_path': features_path,\n",
    "    'readability_path': readability_path,\n",
    "    'vocab_size': vocab_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " prompt_pos size: 8\n",
      " prompt_words size: 8\n",
      " pos_x size: 9513\n",
      " readability_x size: 9513\n",
      " pos_x size: 1680\n",
      " readability_x size: 1680\n",
      " pos_x size: 1783\n",
      " readability_x size: 1783\n",
      "Loading GloVe ...\n",
      "OOV number =189, OOV ratio = 0.047262\n"
     ]
    }
   ],
   "source": [
    "# read POS for prompts\n",
    "pos_vocab = read_pos_vocab(read_configs)\n",
    "prompt_pos_data = read_prompts_pos(\n",
    "    prompt_path, pos_vocab)  # for prompt POS embedding\n",
    "\n",
    "# read words for prompts\n",
    "word_vocab = read_word_vocab(read_configs)\n",
    "# for prompt word embedding\n",
    "prompt_data = read_prompts_we(prompt_path, word_vocab)\n",
    "\n",
    "train_data, dev_data, test_data = read_essays_prompts(\n",
    "    read_configs, prompt_data, prompt_pos_data, pos_vocab)\n",
    "\n",
    "if pretrained_embedding:\n",
    "    embedd_dict, embedd_dim, _ = load_word_embedding_dict(embedding_path)\n",
    "    embedd_matrix = build_embedd_table(\n",
    "        word_vocab, embedd_dict, embedd_dim, caseless=True)\n",
    "    embed_table = embedd_matrix\n",
    "else:\n",
    "    embed_table = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sent length: 50\n",
      "max sent num: 97\n",
      "max prompt sent length: 18\n",
      "max prompt sent num: 8\n",
      "================================\n",
      "X_train_pos:  (9513, 4850)\n",
      "X_train_prompt_words:  (9513, 4850)\n",
      "X_train_prompt_pos:  (9513, 4850)\n",
      "X_train_readability:  (9513, 35)\n",
      "X_train_ling:  (9513, 51)\n",
      "X_train_attribute_rel:  (9513, 9)\n",
      "Y_train:  (9513, 9)\n",
      "================================\n",
      "X_dev_pos:  (1680, 4850)\n",
      "X_dev_prompt_words:  (1680, 4850)\n",
      "X_dev_prompt_pos:  (1680, 4850)\n",
      "X_dev_readability:  (1680, 35)\n",
      "X_dev_ling:  (1680, 51)\n",
      "X_dev_attribute_rel:  (1680, 9)\n",
      "Y_dev:  (1680, 9)\n",
      "================================\n",
      "X_test_pos:  (1783, 4850)\n",
      "X_test_prompt_words:  (1783, 4850)\n",
      "X_test_prompt_pos:  (1783, 4850)\n",
      "X_test_readability:  (1783, 35)\n",
      "X_test_ling:  (1783, 51)\n",
      "X_test_attribute_rel:  (1783, 9)\n",
      "Y_test:  (1783, 9)\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "max_sentlen = max(train_data['max_sentlen'],\n",
    "                  dev_data['max_sentlen'], test_data['max_sentlen'])\n",
    "max_sentnum = max(train_data['max_sentnum'],\n",
    "                  dev_data['max_sentnum'], test_data['max_sentnum'])\n",
    "prompt_max_sentlen = prompt_data['max_sentlen']\n",
    "prompt_max_sentnum = prompt_data['max_sentnum']\n",
    "\n",
    "print('max sent length: {}'.format(max_sentlen))\n",
    "print('max sent num: {}'.format(max_sentnum))\n",
    "print('max prompt sent length: {}'.format(prompt_max_sentlen))\n",
    "print('max prompt sent num: {}'.format(prompt_max_sentnum))\n",
    "\n",
    "train_data['y_scaled'] = get_scaled_down_scores(\n",
    "    train_data['data_y'], train_data['prompt_ids'])\n",
    "dev_data['y_scaled'] = get_scaled_down_scores(\n",
    "    dev_data['data_y'], dev_data['prompt_ids'])\n",
    "test_data['y_scaled'] = get_scaled_down_scores(\n",
    "    test_data['data_y'], test_data['prompt_ids'])\n",
    "\n",
    "X_train_pos = pad_hierarchical_text_sequences(\n",
    "    train_data['pos_x'], max_sentnum, max_sentlen)\n",
    "X_dev_pos = pad_hierarchical_text_sequences(\n",
    "    dev_data['pos_x'], max_sentnum, max_sentlen)\n",
    "X_test_pos = pad_hierarchical_text_sequences(\n",
    "    test_data['pos_x'], max_sentnum, max_sentlen)\n",
    "\n",
    "X_train_pos = X_train_pos.reshape(\n",
    "    (X_train_pos.shape[0], X_train_pos.shape[1] * X_train_pos.shape[2]))\n",
    "X_dev_pos = X_dev_pos.reshape(\n",
    "    (X_dev_pos.shape[0], X_dev_pos.shape[1] * X_dev_pos.shape[2]))\n",
    "X_test_pos = X_test_pos.reshape(\n",
    "    (X_test_pos.shape[0], X_test_pos.shape[1] * X_test_pos.shape[2]))\n",
    "\n",
    "X_train_prompt = pad_hierarchical_text_sequences(\n",
    "    train_data['prompt_words'], max_sentnum, max_sentlen)\n",
    "X_dev_prompt = pad_hierarchical_text_sequences(\n",
    "    dev_data['prompt_words'], max_sentnum, max_sentlen)\n",
    "X_test_prompt = pad_hierarchical_text_sequences(\n",
    "    test_data['prompt_words'], max_sentnum, max_sentlen)\n",
    "\n",
    "X_train_prompt = X_train_prompt.reshape(\n",
    "    (X_train_prompt.shape[0], X_train_prompt.shape[1] * X_train_prompt.shape[2]))\n",
    "X_dev_prompt = X_dev_prompt.reshape(\n",
    "    (X_dev_prompt.shape[0], X_dev_prompt.shape[1] * X_dev_prompt.shape[2]))\n",
    "X_test_prompt = X_test_prompt.reshape(\n",
    "    (X_test_prompt.shape[0], X_test_prompt.shape[1] * X_test_prompt.shape[2]))\n",
    "\n",
    "X_train_prompt_pos = pad_hierarchical_text_sequences(\n",
    "    train_data['prompt_pos'], max_sentnum, max_sentlen)\n",
    "X_dev_prompt_pos = pad_hierarchical_text_sequences(\n",
    "    dev_data['prompt_pos'], max_sentnum, max_sentlen)\n",
    "X_test_prompt_pos = pad_hierarchical_text_sequences(\n",
    "    test_data['prompt_pos'], max_sentnum, max_sentlen)\n",
    "\n",
    "X_train_prompt_pos = X_train_prompt_pos.reshape(\n",
    "    (X_train_prompt_pos.shape[0], X_train_prompt_pos.shape[1] * X_train_prompt_pos.shape[2]))\n",
    "X_dev_prompt_pos = X_dev_prompt_pos.reshape(\n",
    "    (X_dev_prompt_pos.shape[0], X_dev_prompt_pos.shape[1] * X_dev_prompt_pos.shape[2]))\n",
    "X_test_prompt_pos = X_test_prompt_pos.reshape(\n",
    "    (X_test_prompt_pos.shape[0], X_test_prompt_pos.shape[1] * X_test_prompt_pos.shape[2]))\n",
    "\n",
    "X_train_linguistic_features = np.array(train_data['features_x'])\n",
    "X_dev_linguistic_features = np.array(dev_data['features_x'])\n",
    "X_test_linguistic_features = np.array(test_data['features_x'])\n",
    "\n",
    "X_train_readability = np.array(train_data['readability_x'])\n",
    "X_dev_readability = np.array(dev_data['readability_x'])\n",
    "X_test_readability = np.array(test_data['readability_x'])\n",
    "\n",
    "Y_train = np.array(train_data['y_scaled'])\n",
    "Y_dev = np.array(dev_data['y_scaled'])\n",
    "Y_test = np.array(test_data['y_scaled'])\n",
    "\n",
    "X_train_attribute_rel = get_attribute_masks(Y_train)\n",
    "X_dev_attribute_rel = get_attribute_masks(Y_dev)\n",
    "X_test_attribute_rel = get_attribute_masks(Y_test)\n",
    "\n",
    "print('================================')\n",
    "print('X_train_pos: ', X_train_pos.shape)\n",
    "print('X_train_prompt_words: ', X_train_prompt.shape)\n",
    "print('X_train_prompt_pos: ', X_train_prompt_pos.shape)\n",
    "print('X_train_readability: ', X_train_readability.shape)\n",
    "print('X_train_ling: ', X_train_linguistic_features.shape)\n",
    "print('X_train_attribute_rel: ', X_train_attribute_rel.shape)\n",
    "print('Y_train: ', Y_train.shape)\n",
    "\n",
    "print('================================')\n",
    "print('X_dev_pos: ', X_dev_pos.shape)\n",
    "print('X_dev_prompt_words: ', X_dev_prompt.shape)\n",
    "print('X_dev_prompt_pos: ', X_dev_prompt_pos.shape)\n",
    "print('X_dev_readability: ', X_dev_readability.shape)\n",
    "print('X_dev_ling: ', X_dev_linguistic_features.shape)\n",
    "print('X_dev_attribute_rel: ', X_dev_attribute_rel.shape)\n",
    "print('Y_dev: ', Y_dev.shape)\n",
    "\n",
    "print('================================')\n",
    "print('X_test_pos: ', X_test_pos.shape)\n",
    "print('X_test_prompt_words: ', X_test_prompt.shape)\n",
    "print('X_test_prompt_pos: ', X_test_prompt_pos.shape)\n",
    "print('X_test_readability: ', X_test_readability.shape)\n",
    "print('X_test_ling: ', X_test_linguistic_features.shape)\n",
    "print('X_test_attribute_rel: ', X_test_attribute_rel.shape)\n",
    "print('Y_test: ', Y_test.shape)\n",
    "print('================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to torch tensor\n",
    "train_dataset = TensorDataset(\n",
    "    torch.from_numpy(X_train_pos),\n",
    "    torch.from_numpy(X_train_prompt),\n",
    "    torch.from_numpy(X_train_prompt_pos),\n",
    "    torch.from_numpy(X_train_linguistic_features),\n",
    "    torch.from_numpy(X_train_readability),\n",
    "    torch.from_numpy(Y_train)\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dev_dataset = TensorDataset(\n",
    "    torch.from_numpy(X_dev_pos),\n",
    "    torch.from_numpy(X_dev_prompt),\n",
    "    torch.from_numpy(X_dev_prompt_pos),\n",
    "    torch.from_numpy(X_dev_linguistic_features),\n",
    "    torch.from_numpy(X_dev_readability),\n",
    "    torch.from_numpy(Y_dev)\n",
    ")\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size)\n",
    "\n",
    "dev_features_list = [\n",
    "    torch.from_numpy(X_dev_pos),\n",
    "    torch.from_numpy(X_dev_prompt),\n",
    "    torch.from_numpy(X_dev_prompt_pos),\n",
    "    torch.from_numpy(X_dev_linguistic_features),\n",
    "    torch.from_numpy(X_dev_readability)\n",
    "]\n",
    "test_features_list = [\n",
    "    torch.from_numpy(X_test_pos),\n",
    "    torch.from_numpy(X_test_prompt),\n",
    "    torch.from_numpy(X_test_prompt_pos),\n",
    "    torch.from_numpy(X_test_linguistic_features),\n",
    "    torch.from_numpy(X_test_readability)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.essay_pos_attention TimeDistributed(\n",
      "  (module): Attention()\n",
      ")\n",
      "Layer: attention_module.att_V | Size: torch.Size([100])\n",
      "Layer: attention_module.att_W | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_embedding.weight | Size: torch.Size([36, 50])\n",
      "Layer: essay_pos_conv.weight | Size: torch.Size([100, 50, 5])\n",
      "Layer: essay_pos_conv.bias | Size: torch.Size([100])\n",
      "Layer: essay_linquistic.weight | Size: torch.Size([100, 51])\n",
      "Layer: essay_linquistic.bias | Size: torch.Size([100])\n",
      "Layer: essay_readability.weight | Size: torch.Size([100, 35])\n",
      "Layer: essay_readability.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.0.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.0.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.0.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.0.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.0.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.0.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.0.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.0.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.1.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.1.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.1.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.1.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.1.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.1.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.1.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.1.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.2.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.2.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.2.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.2.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.2.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.2.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.2.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.2.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.3.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.3.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.3.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.3.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.3.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.3.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.3.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.3.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.4.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.4.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.4.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.4.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.4.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.4.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.4.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.4.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.5.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.5.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.5.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.5.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.5.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.5.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.5.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.5.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.6.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.6.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.6.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.6.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.6.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.6.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.6.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.6.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.7.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.7.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.7.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.7.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.7.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.7.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.7.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.7.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.8.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.8.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.8.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.8.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.8.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.8.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.8.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.8.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA_LSTM.0.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.0.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.0.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.0.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.1.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.1.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.1.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.1.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.2.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.2.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.2.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.2.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.3.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.3.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.3.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.3.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.4.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.4.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.4.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.4.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.5.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.5.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.5.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.5.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.6.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.6.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.6.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.6.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.7.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.7.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.7.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.7.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.8.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.8.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.8.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.8.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: easay_pos_avg_MA_LSTM.0.att_V | Size: torch.Size([100])\n",
      "Layer: easay_pos_avg_MA_LSTM.0.att_W | Size: torch.Size([100, 100])\n",
      "Layer: easay_pos_avg_MA_LSTM.1.att_V | Size: torch.Size([100])\n",
      "Layer: easay_pos_avg_MA_LSTM.1.att_W | Size: torch.Size([100, 100])\n",
      "Layer: easay_pos_avg_MA_LSTM.2.att_V | Size: torch.Size([100])\n",
      "Layer: easay_pos_avg_MA_LSTM.2.att_W | Size: torch.Size([100, 100])\n",
      "Layer: easay_pos_avg_MA_LSTM.3.att_V | Size: torch.Size([100])\n",
      "Layer: easay_pos_avg_MA_LSTM.3.att_W | Size: torch.Size([100, 100])\n",
      "Layer: easay_pos_avg_MA_LSTM.4.att_V | Size: torch.Size([100])\n",
      "Layer: easay_pos_avg_MA_LSTM.4.att_W | Size: torch.Size([100, 100])\n",
      "Layer: easay_pos_avg_MA_LSTM.5.att_V | Size: torch.Size([100])\n",
      "Layer: easay_pos_avg_MA_LSTM.5.att_W | Size: torch.Size([100, 100])\n",
      "Layer: easay_pos_avg_MA_LSTM.6.att_V | Size: torch.Size([100])\n",
      "Layer: easay_pos_avg_MA_LSTM.6.att_W | Size: torch.Size([100, 100])\n",
      "Layer: easay_pos_avg_MA_LSTM.7.att_V | Size: torch.Size([100])\n",
      "Layer: easay_pos_avg_MA_LSTM.7.att_W | Size: torch.Size([100, 100])\n",
      "Layer: easay_pos_avg_MA_LSTM.8.att_V | Size: torch.Size([100])\n",
      "Layer: easay_pos_avg_MA_LSTM.8.att_W | Size: torch.Size([100, 100])\n",
      "Layer: prompt_embedding.weight | Size: torch.Size([4000, 50])\n",
      "Layer: prompt_pos_embedding.weight | Size: torch.Size([36, 50])\n",
      "Layer: prompt_cnn.weight | Size: torch.Size([100, 50, 5])\n",
      "Layer: prompt_cnn.bias | Size: torch.Size([100])\n",
      "Layer: prompt_MA.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: prompt_MA.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: prompt_MA.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: prompt_MA.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: prompt_MA.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: prompt_MA.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: prompt_MA.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: prompt_MA.dense.bias | Size: torch.Size([100])\n",
      "Layer: prompt_MA_lstm.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: prompt_MA_lstm.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: prompt_MA_lstm.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: prompt_MA_lstm.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_list.0.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.0.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.0.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.0.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.0.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.0.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.0.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.0.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.1.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.1.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.1.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.1.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.1.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.1.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.1.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.1.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.2.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.2.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.2.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.2.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.2.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.2.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.2.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.2.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.3.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.3.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.3.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.3.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.3.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.3.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.3.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.3.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.4.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.4.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.4.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.4.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.4.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.4.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.4.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.4.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.5.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.5.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.5.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.5.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.5.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.5.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.5.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.5.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.6.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.6.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.6.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.6.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.6.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.6.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.6.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.6.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.7.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.7.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.7.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.7.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.7.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.7.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.7.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.7.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.8.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.8.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.8.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.8.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.8.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.8.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.8.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.8.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_lstm_list.0.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.0.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.0.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.0.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.1.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.1.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.1.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.1.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.2.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.2.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.2.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.2.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.3.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.3.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.3.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.3.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.4.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.4.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.4.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.4.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.5.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.5.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.5.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.5.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.6.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.6.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.6.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.6.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.7.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.7.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.7.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.7.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.8.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.8.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.8.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.8.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_avg_lstm_list.0.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.0.att_W | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_avg_lstm_list.1.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.1.att_W | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_avg_lstm_list.2.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.2.att_W | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_avg_lstm_list.3.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.3.att_W | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_avg_lstm_list.4.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.4.att_W | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_avg_lstm_list.5.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.5.att_W | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_avg_lstm_list.6.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.6.att_W | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_avg_lstm_list.7.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.7.att_W | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_avg_lstm_list.8.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.8.att_W | Size: torch.Size([100, 100])\n",
      "Layer: final_dense_list.0.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.0.bias | Size: torch.Size([1])\n",
      "Layer: final_dense_list.1.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.1.bias | Size: torch.Size([1])\n",
      "Layer: final_dense_list.2.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.2.bias | Size: torch.Size([1])\n",
      "Layer: final_dense_list.3.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.3.bias | Size: torch.Size([1])\n",
      "Layer: final_dense_list.4.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.4.bias | Size: torch.Size([1])\n",
      "Layer: final_dense_list.5.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.5.bias | Size: torch.Size([1])\n",
      "Layer: final_dense_list.6.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.6.bias | Size: torch.Size([1])\n",
      "Layer: final_dense_list.7.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.7.bias | Size: torch.Size([1])\n",
      "Layer: final_dense_list.8.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.8.bias | Size: torch.Size([1])\n",
      "Layer: att_attention.in_proj_weight | Size: torch.Size([558, 186])\n",
      "Layer: att_attention.in_proj_bias | Size: torch.Size([558])\n",
      "Layer: att_attention.out_proj.weight | Size: torch.Size([186, 186])\n",
      "Layer: att_attention.out_proj.bias | Size: torch.Size([186])\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "model = ProTACT(\n",
    "    len(pos_vocab), len(word_vocab), max_sentnum, max_sentlen,\n",
    "    X_train_readability.shape[1], X_train_linguistic_features.shape[1],\n",
    "    configs, Y_train.shape[1], num_heads, embed_table\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# loss function and optimizer\n",
    "criterion = LossFunctions(alpha=0.7)\n",
    "optimizer = torch.optim.RMSprop(\n",
    "    model.parameters(), lr=configs.LEARNING_RATE)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_drop_x  this is timedistribution checking 4:  torch.Size([1680, 4850, 50])\n",
      "pos_resh_W torch.Size([1680, 97, 50, 50])\n",
      "pos_zcnn torch.Size([1680, 97, 100, 46])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16296000x46 and 100x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m AllAttEvaluator(\n\u001b[1;32m      2\u001b[0m     test_prompt_id, dev_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      3\u001b[0m     [x\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m dev_features_list],\n\u001b[1;32m      4\u001b[0m     [x\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m test_features_list], Y_dev, Y_test, seed\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/수업자료/skku4-3/인공지능프로젝트/프로젝트/ProTACT 공부/ProTACT/torch/evaluators/multitask_evaluator_all_attributes.py:58\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[0;34m(self, model, epoch, print_info)\u001b[0m\n\u001b[1;32m     56\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 58\u001b[0m     dev_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdev_features_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     60\u001b[0m     test_pred \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m[torch\u001b[38;5;241m.\u001b[39mfrom_numpy(feat)\n\u001b[1;32m     61\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_features_list])\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     63\u001b[0m dev_pred_int \u001b[38;5;241m=\u001b[39m dev_pred \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/수업자료/skku4-3/인공지능프로젝트/프로젝트/ProTACT 공부/ProTACT/torch/models/ProTACT.py:137\u001b[0m, in \u001b[0;36mProTACT.forward\u001b[0;34m(self, pos_input, prompt_word_input, prompt_pos_input, linguistic_input, readability_input)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos_zcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m, pos_zcnn\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;66;03m# (none, 97, 46, 100)\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# for fitting the attention layer\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# from here...\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# pos_zcnn = pos_zcnn.view(-1, , , self.filters)\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m pos_avg_zcnn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43messay_pos_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_zcnn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos_avg_zcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m, pos_avg_zcnn\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    140\u001b[0m pos_MA_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39messay_pos_MA[i](\n\u001b[1;32m    141\u001b[0m     pos_avg_zcnn) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim)]\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/수업자료/skku4-3/인공지능프로젝트/프로젝트/ProTACT 공부/ProTACT/torch/custom_layers/timedistributed.py:36\u001b[0m, in \u001b[0;36mTimeDistributed.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m x_reshape \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# (samples * timesteps, input_size)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m x_reshape\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_reshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# We have to reshape Y\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first:\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/수업자료/skku4-3/인공지능프로젝트/프로젝트/ProTACT 공부/ProTACT/torch/custom_layers/attention.py:24\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 24\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matt_W\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation:\n\u001b[1;32m     26\u001b[0m         w \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensordot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt_V, w, dims\u001b[38;5;241m=\u001b[39m[[\u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m2\u001b[39m]])\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16296000x46 and 100x100)"
     ]
    }
   ],
   "source": [
    "evaluator = AllAttEvaluator(\n",
    "    test_prompt_id, dev_data['prompt_ids'], test_data['prompt_ids'],\n",
    "    [x.numpy() for x in dev_features_list],\n",
    "    [x.numpy() for x in test_features_list], Y_dev, Y_test, seed\n",
    ")\n",
    "\n",
    "evaluator.evaluate(model, -1, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomHistory:\n",
    "    def __init__(self):\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def update(self, train_loss, val_loss):\n",
    "        self.train_loss.append(train_loss)\n",
    "        self.val_loss.append(val_loss)\n",
    "        \n",
    "        \n",
    "custom_hist = CustomHistory()\n",
    "\n",
    "for epoch in range(epochs): # 50\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    start_time = time.time()\n",
    "\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch_data = [x.to(device) for x in batch_data]\n",
    "        inputs, targets = batch_data[:-1], batch_data[-1]\n",
    "        outputs = model(*inputs)\n",
    "        loss = criterion.loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * batch_data[0].size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # validate\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_data in dev_loader:\n",
    "            batch_data = [x.to(device) for x in batch_data]\n",
    "            inputs, targets = batch_data[:-1], batch_data[-1]\n",
    "            outputs = model(*inputs)\n",
    "            #loss = criterion(outputs, targets)\n",
    "            loss = criterion.loss_function(outputs, targets)\n",
    "            val_loss += loss.item() * batch_data[0].size(0)\n",
    "        val_loss /= len(dev_loader.dataset)\n",
    "\n",
    "    custom_hist.update(train_loss, val_loss)\n",
    "\n",
    "    # evaluate\n",
    "    tt_time = time.time() - start_time\n",
    "    print(f\"Training one epoch in {tt_time:.3f} s\")\n",
    "    evaluator.evaluate(model, epoch + 1)\n",
    "    print(f\"Train Loss: {train_loss:.4f} || Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "evaluator.print_final_info()\n",
    "\n",
    "'''# show the loss as the graph\n",
    "fig, loss_graph = plt.subplots()\n",
    "loss_graph.plot(custom_hist.train_loss,'y',label='train loss')\n",
    "loss_graph.plot(custom_hist.val_loss,'r',label='val loss')\n",
    "loss_graph.set_xlabel('epoch')\n",
    "loss_graph.set_ylabel('loss')\n",
    "plt.savefig(str('images/protact/test_prompt_'+ str(test_prompt_id) + '_seed_' + str(seed) + '_loss.png'))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeDistributed 실험\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, TimeDistributed, Input\n",
    "\n",
    "# Define input data\n",
    "batch_size = 32\n",
    "sentence_num = 7\n",
    "sentence_length = 5\n",
    "input_dim = 4\n",
    "input_data = torch.randn(batch_size,  setence_num,setence_length, input_dim)\n",
    "\n",
    "\n",
    "# Define input shape\n",
    "max_sentence_num = 3\n",
    "max_sentence_length = 5\n",
    "embedding_dim = 4\n",
    "input_shape = (setence_num, setence_length, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 7, 5, 4)]         0         \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDi  (None, 7, 3, 2)           26        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26 (104.00 Byte)\n",
      "Trainable params: 26 (104.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(32, 7, 3, 2)\n",
      "[[[[ 2.22391438e+00  9.05178115e-02]\n",
      "   [ 1.25336432e+00 -2.58172065e-01]\n",
      "   [ 1.45193958e+00  7.70615578e-01]]\n",
      "\n",
      "  [[-9.68962908e-01 -1.24814972e-01]\n",
      "   [-7.32492566e-01 -1.13072920e+00]\n",
      "   [ 9.20946479e-01  3.74002874e-01]]\n",
      "\n",
      "  [[ 6.40787482e-01 -2.10141718e-01]\n",
      "   [ 1.72482824e+00  3.40642035e-01]\n",
      "   [-1.49783850e+00 -8.87199998e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-4.39846031e-02  1.89060360e-01]\n",
      "   [-1.44115436e+00  4.58280116e-01]\n",
      "   [-5.98960400e-01  1.29257860e-02]]\n",
      "\n",
      "  [[-2.79668713e+00 -1.71421781e-01]\n",
      "   [ 1.08940887e+00 -5.68691611e-01]\n",
      "   [-7.21760392e-01  9.90311652e-02]]\n",
      "\n",
      "  [[ 2.74278790e-01  1.68131888e-01]\n",
      "   [ 2.09099913e+00  2.28326857e-01]\n",
      "   [-5.25715798e-02  1.23155832e-01]]]\n",
      "\n",
      "\n",
      " [[[-1.00264466e+00  1.42479455e+00]\n",
      "   [-1.15053475e-01  9.47682142e-01]\n",
      "   [ 1.26550817e+00  1.08807290e+00]]\n",
      "\n",
      "  [[ 2.40113068e+00 -4.65106934e-01]\n",
      "   [ 2.13225961e-01  9.50795114e-02]\n",
      "   [-2.01818562e+00 -1.99327624e+00]]\n",
      "\n",
      "  [[-1.61117578e+00 -6.59347653e-01]\n",
      "   [ 2.23763689e-01 -4.91758317e-01]\n",
      "   [-1.25392604e+00 -3.37300479e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1.00581694e+00  5.50085939e-02]\n",
      "   [ 1.77943456e+00  1.27751970e+00]\n",
      "   [-2.40054345e+00 -1.78182453e-01]]\n",
      "\n",
      "  [[-2.06535026e-01 -4.09875780e-01]\n",
      "   [-9.85682607e-01 -1.15796638e+00]\n",
      "   [-1.67810082e+00 -1.05179405e+00]]\n",
      "\n",
      "  [[-8.56191039e-01 -1.25178486e-01]\n",
      "   [ 9.09423053e-01 -1.91554308e-01]\n",
      "   [-8.26462269e-01 -1.39625287e+00]]]\n",
      "\n",
      "\n",
      " [[[ 4.42987156e+00  1.72809696e+00]\n",
      "   [ 3.44845533e+00  9.81504679e-01]\n",
      "   [ 4.11755610e+00  4.06412899e-01]]\n",
      "\n",
      "  [[-1.11347651e+00 -2.60241121e-01]\n",
      "   [-3.74006581e+00 -6.25247717e-01]\n",
      "   [ 8.66312347e-03  7.35128403e-01]]\n",
      "\n",
      "  [[-1.18091322e-01 -1.97087824e-01]\n",
      "   [-1.02042019e+00 -8.53621185e-01]\n",
      "   [ 1.03193974e+00  7.46893167e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-3.91813129e-01  9.93047655e-01]\n",
      "   [-4.19578880e-01  9.99670208e-01]\n",
      "   [-5.60555041e-01  2.09611833e-01]]\n",
      "\n",
      "  [[ 1.78855205e+00 -3.53173316e-01]\n",
      "   [-1.28284231e-01  4.44199681e-01]\n",
      "   [-1.75630534e+00 -2.92546064e-01]]\n",
      "\n",
      "  [[ 2.11578059e+00  3.13594669e-01]\n",
      "   [ 2.89845228e+00  1.68895280e+00]\n",
      "   [ 5.80740988e-01  3.45007747e-01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-1.91936064e+00  5.03053367e-01]\n",
      "   [-2.59387898e+00 -4.60500628e-01]\n",
      "   [-6.99048519e-01  2.74555922e-01]]\n",
      "\n",
      "  [[-2.49668884e+00 -1.82763350e+00]\n",
      "   [ 6.00603402e-01  8.89284432e-01]\n",
      "   [ 3.07933360e-01  3.75433154e-02]]\n",
      "\n",
      "  [[ 8.99532735e-01  1.18721336e-01]\n",
      "   [ 2.29147029e+00  1.65555441e+00]\n",
      "   [ 1.88798583e+00  1.89550221e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1.55221379e+00 -7.04875112e-01]\n",
      "   [-4.74928260e-01 -3.45904440e-01]\n",
      "   [ 1.89926720e+00  5.36835968e-01]]\n",
      "\n",
      "  [[ 2.12719202e-01  1.21218693e+00]\n",
      "   [-5.41591346e-01  1.01884699e+00]\n",
      "   [ 1.13078439e+00  2.33174038e+00]]\n",
      "\n",
      "  [[-8.80165398e-01 -6.32948101e-01]\n",
      "   [ 3.66398245e-01  6.85028076e-01]\n",
      "   [ 1.24448729e+00  1.30428183e+00]]]\n",
      "\n",
      "\n",
      " [[[-9.04497206e-01 -1.56367171e+00]\n",
      "   [-3.06273580e-01 -5.85537434e-01]\n",
      "   [-1.07659340e-01 -2.31598094e-01]]\n",
      "\n",
      "  [[-1.11383736e+00 -4.75376755e-01]\n",
      "   [-1.65292513e+00 -8.46063733e-01]\n",
      "   [ 1.00505924e+00 -4.18445617e-01]]\n",
      "\n",
      "  [[ 2.89343983e-01 -9.91742015e-01]\n",
      "   [-2.92476797e+00 -5.20955861e-01]\n",
      "   [-2.06210375e+00 -7.95021057e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-9.47124660e-01 -4.73831594e-01]\n",
      "   [ 1.63350284e+00  1.22179341e+00]\n",
      "   [ 1.56115726e-01 -1.12230051e+00]]\n",
      "\n",
      "  [[ 7.49031901e-02  1.55646551e+00]\n",
      "   [ 8.36125433e-01  1.90898490e+00]\n",
      "   [ 9.24737811e-01  4.66018438e-01]]\n",
      "\n",
      "  [[-1.29714161e-01  5.52302599e-01]\n",
      "   [ 1.34882880e-02  1.13159764e+00]\n",
      "   [ 6.50120229e-02  7.95119107e-01]]]\n",
      "\n",
      "\n",
      " [[[ 9.80654001e-01  3.99093866e-01]\n",
      "   [ 1.03369340e-01  1.04601495e-03]\n",
      "   [-2.24971890e+00  8.81149054e-01]]\n",
      "\n",
      "  [[-7.50768006e-01 -1.38073742e+00]\n",
      "   [-6.77059054e-01 -5.42304099e-01]\n",
      "   [-3.95401344e-02 -1.55697048e+00]]\n",
      "\n",
      "  [[ 1.52186549e+00 -1.92607373e-01]\n",
      "   [ 1.06653798e+00  6.10459387e-01]\n",
      "   [-9.24061120e-01 -4.75616753e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 2.57014823e+00  1.57420313e+00]\n",
      "   [ 1.03114998e+00  1.19850449e-02]\n",
      "   [ 1.05402358e-01  5.18499352e-02]]\n",
      "\n",
      "  [[-4.55879010e-02  2.14777574e-01]\n",
      "   [ 7.31237888e-01 -8.99271667e-01]\n",
      "   [ 6.12883270e-01 -8.09013128e-01]]\n",
      "\n",
      "  [[-5.73706388e-01  1.34805155e+00]\n",
      "   [-3.99612069e-01 -8.87259007e-01]\n",
      "   [ 1.79560006e+00  1.34245455e+00]]]]\n"
     ]
    }
   ],
   "source": [
    "# Define input layer\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "# Apply TimeDistributed Conv1D\n",
    "cnn_filters = 2\n",
    "cnn_kernel_size = 3\n",
    "conv1d_output = TimeDistributed(Conv1D(filters=cnn_filters, kernel_size=cnn_kernel_size, padding='valid'))(inputs)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=conv1d_output)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Generate output\n",
    "output = model.predict(tf.constant(input_data))\n",
    "print(output.shape)  # Output shape\n",
    "print(output)  # Output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m outs\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(input_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m---> 12\u001b[0m     outs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m(input_data[:, i, :]\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m     13\u001b[0m outs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcat(outs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(out\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/torch/nn/modules/container.py:295\u001b[0m, in \u001b[0;36mModuleList.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mvalues())[idx])\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_abs_string_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/torch/nn/modules/container.py:285\u001b[0m, in \u001b[0;36mModuleList._get_abs_string_index\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    283\u001b[0m idx \u001b[38;5;241m=\u001b[39m operator\u001b[38;5;241m.\u001b[39mindex(idx)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is out of range\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx))\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    287\u001b[0m     idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5 is out of range"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_data = torch.randn(batch_size, sentence_num, sentence_length, input_dim)\n",
    "\n",
    "# 24 fc timedistributed\n",
    "num = 24\n",
    "fc = nn.ModuleList([nn.Conv1d(embedding_dim, cnn_filters, cnn_kernel_size) for i in range(max_sentence_length)])\n",
    "# forward pass \n",
    "outs=[]\n",
    "for i in range(input_data.shape[1]):\n",
    "    outs.append(fc[i](input_data[:, i, :].transpose(1,2)))\n",
    "outs=torch.cat(outs, axis=1)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
