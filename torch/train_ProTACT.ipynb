{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/joohwan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/joohwan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Load autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload behavior\n",
    "%autoreload 2\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from models.ProTACT import ProTACT\n",
    "from models.Loss import LossFunctions\n",
    "from configs.configs import Configs\n",
    "from utils.read_data_pr import read_pos_vocab, read_word_vocab, read_prompts_we, read_essays_prompts, read_prompts_pos\n",
    "from utils.general_utils import get_scaled_down_scores, pad_hierarchical_text_sequences, get_attribute_masks, load_word_embedding_dict, build_embedd_table\n",
    "from evaluators.multitask_evaluator_all_attributes import Evaluator as AllAttEvaluator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Test prompt id is 1 of type <class 'int'>\n",
      "Seed: 1\n",
      "Numhead :  2  | Features :  ../data/hand_crafted_v3.csv  | Pos_emb :  50\n"
     ]
    }
   ],
   "source": [
    "# print(\"main started\")\n",
    "# parser = argparse.ArgumentParser(description=\"ProTACT model\")\n",
    "# parser.add_argument('--test_prompt_id', type=int,\n",
    "#                     default=1, help='prompt id of test essay set')\n",
    "# parser.add_argument('--seed', type=int, default=12, help='set random seed')\n",
    "# parser.add_argument('--model_name', type=str,\n",
    "#                     choices=['ProTACT'],\n",
    "#                     help='name of model')\n",
    "# parser.add_argument('--num_heads', type=int, default=2,\n",
    "#                     help='set the number of heads in Multihead Attention')\n",
    "# parser.add_argument('--features_path', type=str,\n",
    "#                     default='data/hand_crafted_v3.csv')\n",
    "test_prompt_id = 1\n",
    "seed = 1\n",
    "num_heads = 2\n",
    "features_path = '../data/hand_crafted_v3.csv'\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(\"Test prompt id is {} of type {}\".format(\n",
    "    test_prompt_id, type(test_prompt_id)))\n",
    "print(\"Seed: {}\".format(seed))\n",
    "\n",
    "configs = Configs()\n",
    "\n",
    "data_path = configs.DATA_PATH\n",
    "train_path = data_path + str(test_prompt_id) + '/train.pk'\n",
    "dev_path = data_path + str(test_prompt_id) + '/dev.pk'\n",
    "test_path = data_path + str(test_prompt_id) + '/test.pk'\n",
    "pretrained_embedding = configs.PRETRAINED_EMBEDDING\n",
    "embedding_path = configs.EMBEDDING_PATH\n",
    "readability_path = configs.READABILITY_PATH\n",
    "prompt_path = configs.PROMPT_PATH\n",
    "vocab_size = configs.VOCAB_SIZE\n",
    "epochs = configs.EPOCHS\n",
    "batch_size = configs.BATCH_SIZE\n",
    "print(\"Numhead : \", num_heads, \" | Features : \",\n",
    "      features_path, \" | Pos_emb : \", configs.EMBEDDING_DIM)\n",
    "\n",
    "read_configs = {\n",
    "    'train_path': train_path,\n",
    "    'dev_path': dev_path,\n",
    "    'test_path': test_path,\n",
    "    'features_path': features_path,\n",
    "    'readability_path': readability_path,\n",
    "    'vocab_size': vocab_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " prompt_pos size: 8\n",
      " prompt_words size: 8\n",
      " pos_x size: 9513\n",
      " readability_x size: 9513\n"
     ]
    }
   ],
   "source": [
    "# read POS for prompts\n",
    "pos_vocab = read_pos_vocab(read_configs)\n",
    "prompt_pos_data = read_prompts_pos(\n",
    "    prompt_path, pos_vocab)  # for prompt POS embedding\n",
    "\n",
    "# read words for prompts\n",
    "word_vocab = read_word_vocab(read_configs)\n",
    "# for prompt word embedding\n",
    "prompt_data = read_prompts_we(prompt_path, word_vocab)\n",
    "\n",
    "train_data, dev_data, test_data = read_essays_prompts(\n",
    "    read_configs, prompt_data, prompt_pos_data, pos_vocab)\n",
    "\n",
    "if pretrained_embedding:\n",
    "    embedd_dict, embedd_dim, _ = load_word_embedding_dict(embedding_path)\n",
    "    embedd_matrix = build_embedd_table(\n",
    "        word_vocab, embedd_dict, embedd_dim, caseless=True)\n",
    "    embed_table = embedd_matrix\n",
    "else:\n",
    "    embed_table = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentlen = max(train_data['max_sentlen'],\n",
    "                  dev_data['max_sentlen'], test_data['max_sentlen'])\n",
    "max_sentnum = max(train_data['max_sentnum'],\n",
    "                  dev_data['max_sentnum'], test_data['max_sentnum'])\n",
    "prompt_max_sentlen = prompt_data['max_sentlen']\n",
    "prompt_max_sentnum = prompt_data['max_sentnum']\n",
    "\n",
    "print('max sent length: {}'.format(max_sentlen))\n",
    "print('max sent num: {}'.format(max_sentnum))\n",
    "print('max prompt sent length: {}'.format(prompt_max_sentlen))\n",
    "print('max prompt sent num: {}'.format(prompt_max_sentnum))\n",
    "\n",
    "train_data['y_scaled'] = get_scaled_down_scores(\n",
    "    train_data['data_y'], train_data['prompt_ids'])\n",
    "dev_data['y_scaled'] = get_scaled_down_scores(\n",
    "    dev_data['data_y'], dev_data['prompt_ids'])\n",
    "test_data['y_scaled'] = get_scaled_down_scores(\n",
    "    test_data['data_y'], test_data['prompt_ids'])\n",
    "\n",
    "X_train_pos = pad_hierarchical_text_sequences(\n",
    "    train_data['pos_x'], max_sentnum, max_sentlen)\n",
    "X_dev_pos = pad_hierarchical_text_sequences(\n",
    "    dev_data['pos_x'], max_sentnum, max_sentlen)\n",
    "X_test_pos = pad_hierarchical_text_sequences(\n",
    "    test_data['pos_x'], max_sentnum, max_sentlen)\n",
    "\n",
    "X_train_pos = X_train_pos.reshape(\n",
    "    (X_train_pos.shape[0], X_train_pos.shape[1] * X_train_pos.shape[2]))\n",
    "X_dev_pos = X_dev_pos.reshape(\n",
    "    (X_dev_pos.shape[0], X_dev_pos.shape[1] * X_dev_pos.shape[2]))\n",
    "X_test_pos = X_test_pos.reshape(\n",
    "    (X_test_pos.shape[0], X_test_pos.shape[1] * X_test_pos.shape[2]))\n",
    "\n",
    "X_train_prompt = pad_hierarchical_text_sequences(\n",
    "    train_data['prompt_words'], max_sentnum, max_sentlen)\n",
    "X_dev_prompt = pad_hierarchical_text_sequences(\n",
    "    dev_data['prompt_words'], max_sentnum, max_sentlen)\n",
    "X_test_prompt = pad_hierarchical_text_sequences(\n",
    "    test_data['prompt_words'], max_sentnum, max_sentlen)\n",
    "\n",
    "X_train_prompt = X_train_prompt.reshape(\n",
    "    (X_train_prompt.shape[0], X_train_prompt.shape[1] * X_train_prompt.shape[2]))\n",
    "X_dev_prompt = X_dev_prompt.reshape(\n",
    "    (X_dev_prompt.shape[0], X_dev_prompt.shape[1] * X_dev_prompt.shape[2]))\n",
    "X_test_prompt = X_test_prompt.reshape(\n",
    "    (X_test_prompt.shape[0], X_test_prompt.shape[1] * X_test_prompt.shape[2]))\n",
    "\n",
    "X_train_prompt_pos = pad_hierarchical_text_sequences(\n",
    "    train_data['prompt_pos'], max_sentnum, max_sentlen)\n",
    "X_dev_prompt_pos = pad_hierarchical_text_sequences(\n",
    "    dev_data['prompt_pos'], max_sentnum, max_sentlen)\n",
    "X_test_prompt_pos = pad_hierarchical_text_sequences(\n",
    "    test_data['prompt_pos'], max_sentnum, max_sentlen)\n",
    "\n",
    "X_train_prompt_pos = X_train_prompt_pos.reshape(\n",
    "    (X_train_prompt_pos.shape[0], X_train_prompt_pos.shape[1] * X_train_prompt_pos.shape[2]))\n",
    "X_dev_prompt_pos = X_dev_prompt_pos.reshape(\n",
    "    (X_dev_prompt_pos.shape[0], X_dev_prompt_pos.shape[1] * X_dev_prompt_pos.shape[2]))\n",
    "X_test_prompt_pos = X_test_prompt_pos.reshape(\n",
    "    (X_test_prompt_pos.shape[0], X_test_prompt_pos.shape[1] * X_test_prompt_pos.shape[2]))\n",
    "\n",
    "X_train_linguistic_features = np.array(train_data['features_x'])\n",
    "X_dev_linguistic_features = np.array(dev_data['features_x'])\n",
    "X_test_linguistic_features = np.array(test_data['features_x'])\n",
    "\n",
    "X_train_readability = np.array(train_data['readability_x'])\n",
    "X_dev_readability = np.array(dev_data['readability_x'])\n",
    "X_test_readability = np.array(test_data['readability_x'])\n",
    "\n",
    "Y_train = np.array(train_data['y_scaled'])\n",
    "Y_dev = np.array(dev_data['y_scaled'])\n",
    "Y_test = np.array(test_data['y_scaled'])\n",
    "\n",
    "X_train_attribute_rel = get_attribute_masks(Y_train)\n",
    "X_dev_attribute_rel = get_attribute_masks(Y_dev)\n",
    "X_test_attribute_rel = get_attribute_masks(Y_test)\n",
    "\n",
    "print('================================')\n",
    "print('X_train_pos: ', X_train_pos.shape)\n",
    "print('X_train_prompt_words: ', X_train_prompt.shape)\n",
    "print('X_train_prompt_pos: ', X_train_prompt_pos.shape)\n",
    "print('X_train_readability: ', X_train_readability.shape)\n",
    "print('X_train_ling: ', X_train_linguistic_features.shape)\n",
    "print('X_train_attribute_rel: ', X_train_attribute_rel.shape)\n",
    "print('Y_train: ', Y_train.shape)\n",
    "\n",
    "print('================================')\n",
    "print('X_dev_pos: ', X_dev_pos.shape)\n",
    "print('X_dev_prompt_words: ', X_dev_prompt.shape)\n",
    "print('X_dev_prompt_pos: ', X_dev_prompt_pos.shape)\n",
    "print('X_dev_readability: ', X_dev_readability.shape)\n",
    "print('X_dev_ling: ', X_dev_linguistic_features.shape)\n",
    "print('X_dev_attribute_rel: ', X_dev_attribute_rel.shape)\n",
    "print('Y_dev: ', Y_dev.shape)\n",
    "\n",
    "print('================================')\n",
    "print('X_test_pos: ', X_test_pos.shape)\n",
    "print('X_test_prompt_words: ', X_test_prompt.shape)\n",
    "print('X_test_prompt_pos: ', X_test_prompt_pos.shape)\n",
    "print('X_test_readability: ', X_test_readability.shape)\n",
    "print('X_test_ling: ', X_test_linguistic_features.shape)\n",
    "print('X_test_attribute_rel: ', X_test_attribute_rel.shape)\n",
    "print('Y_test: ', Y_test.shape)\n",
    "print('================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to torch tensor\n",
    "train_dataset = TensorDataset(\n",
    "    torch.from_numpy(X_train_pos),\n",
    "    torch.from_numpy(X_train_prompt),\n",
    "    torch.from_numpy(X_train_prompt_pos),\n",
    "    torch.from_numpy(X_train_linguistic_features),\n",
    "    torch.from_numpy(X_train_readability),\n",
    "    torch.from_numpy(Y_train)\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dev_dataset = TensorDataset(\n",
    "    torch.from_numpy(X_dev_pos),\n",
    "    torch.from_numpy(X_dev_prompt),\n",
    "    torch.from_numpy(X_dev_prompt_pos),\n",
    "    torch.from_numpy(X_dev_linguistic_features),\n",
    "    torch.from_numpy(X_dev_readability),\n",
    "    torch.from_numpy(Y_dev)\n",
    ")\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size)\n",
    "\n",
    "dev_features_list = [\n",
    "    torch.from_numpy(X_dev_pos),\n",
    "    torch.from_numpy(X_dev_prompt),\n",
    "    torch.from_numpy(X_dev_prompt_pos),\n",
    "    torch.from_numpy(X_dev_linguistic_features),\n",
    "    torch.from_numpy(X_dev_readability)\n",
    "]\n",
    "test_features_list = [\n",
    "    torch.from_numpy(X_test_pos),\n",
    "    torch.from_numpy(X_test_prompt),\n",
    "    torch.from_numpy(X_test_prompt_pos),\n",
    "    torch.from_numpy(X_test_linguistic_features),\n",
    "    torch.from_numpy(X_test_readability)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = ProTACT(\n",
    "    len(pos_vocab), len(word_vocab), max_sentnum, max_sentlen,\n",
    "    X_train_readability.shape[1], X_train_linguistic_features.shape[1],\n",
    "    configs, Y_train.shape[1], num_heads, embed_table\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# loss function and optimizer\n",
    "criterion = LossFunctions(alpha=0.7)\n",
    "optimizer = torch.optim.RMSprop(\n",
    "    model.parameters(), lr=configs.LEARNING_RATE)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = AllAttEvaluator(\n",
    "    test_prompt_id, dev_data['prompt_ids'], test_data['prompt_ids'],\n",
    "    [x.numpy() for x in dev_features_list],\n",
    "    [x.numpy() for x in test_features_list], Y_dev, Y_test, seed\n",
    ")\n",
    "\n",
    "evaluator.evaluate(model, -1, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomHistory:\n",
    "    def __init__(self):\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def update(self, train_loss, val_loss):\n",
    "        self.train_loss.append(train_loss)\n",
    "        self.val_loss.append(val_loss)\n",
    "        \n",
    "        \n",
    "custom_hist = CustomHistory()\n",
    "\n",
    "for epoch in range(epochs): # 50\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    start_time = time.time()\n",
    "\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch_data = [x.to(device) for x in batch_data]\n",
    "        inputs, targets = batch_data[:-1], batch_data[-1]\n",
    "        outputs = model(*inputs)\n",
    "        loss = criterion.loss_function(targets.float(),outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * batch_data[0].size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # validate\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_data in dev_loader:\n",
    "            batch_data = [x.to(device) for x in batch_data]\n",
    "            inputs, targets = batch_data[:-1], batch_data[-1]\n",
    "            outputs = model(*inputs)\n",
    "            #loss = criterion(outputs, targets)\n",
    "            loss = criterion.loss_function(targets.float(), outputs)\n",
    "            val_loss += loss.item() * batch_data[0].size(0)\n",
    "        val_loss /= len(dev_loader.dataset)\n",
    "\n",
    "    custom_hist.update(train_loss, val_loss)\n",
    "\n",
    "    # evaluate\n",
    "    tt_time = time.time() - start_time\n",
    "    print(f\"Training one epoch in {tt_time:.3f} s\")\n",
    "    evaluator.evaluate(model, epoch + 1)\n",
    "    print(f\"Train Loss: {train_loss:.4f} || Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "evaluator.print_final_info()\n",
    "\n",
    "'''# show the loss as the graph\n",
    "fig, loss_graph = plt.subplots()\n",
    "loss_graph.plot(custom_hist.train_loss,'y',label='train loss')\n",
    "loss_graph.plot(custom_hist.val_loss,'r',label='val loss')\n",
    "loss_graph.set_xlabel('epoch')\n",
    "loss_graph.set_ylabel('loss')\n",
    "plt.savefig(str('images/protact/test_prompt_'+ str(test_prompt_id) + '_seed_' + str(seed) + '_loss.png'))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
