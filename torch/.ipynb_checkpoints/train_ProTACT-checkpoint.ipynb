{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Load autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload behavior\n",
    "%autoreload 2\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from models.ProTACT import ProTACT\n",
    "from models.Loss import LossFunctions\n",
    "from configs.configs import Configs\n",
    "from utils.read_data_pr import read_pos_vocab, read_word_vocab, read_prompts_we, read_essays_prompts, read_prompts_pos\n",
    "from utils.general_utils import get_scaled_down_scores, pad_hierarchical_text_sequences, get_attribute_masks, load_word_embedding_dict, build_embedd_table\n",
    "from evaluators.multitask_evaluator_all_attributes import Evaluator as AllAttEvaluator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Test prompt id is 1 of type <class 'int'>\n",
      "Seed: 1\n",
      "Numhead :  2  | Features :  ../data/hand_crafted_v3.csv  | Pos_emb :  50\n"
     ]
    }
   ],
   "source": [
    "# print(\"main started\")\n",
    "# parser = argparse.ArgumentParser(description=\"ProTACT model\")\n",
    "# parser.add_argument('--test_prompt_id', type=int,\n",
    "#                     default=1, help='prompt id of test essay set')\n",
    "# parser.add_argument('--seed', type=int, default=12, help='set random seed')\n",
    "# parser.add_argument('--model_name', type=str,\n",
    "#                     choices=['ProTACT'],\n",
    "#                     help='name of model')\n",
    "# parser.add_argument('--num_heads', type=int, default=2,\n",
    "#                     help='set the number of heads in Multihead Attention')\n",
    "# parser.add_argument('--features_path', type=str,\n",
    "#                     default='data/hand_crafted_v3.csv')\n",
    "test_prompt_id = 1\n",
    "seed = 1\n",
    "num_heads = 2\n",
    "features_path = '../data/hand_crafted_v3.csv'\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(\"Test prompt id is {} of type {}\".format(\n",
    "    test_prompt_id, type(test_prompt_id)))\n",
    "print(\"Seed: {}\".format(seed))\n",
    "\n",
    "configs = Configs()\n",
    "\n",
    "data_path = configs.DATA_PATH\n",
    "train_path = data_path + str(test_prompt_id) + '/train.pk'\n",
    "dev_path = data_path + str(test_prompt_id) + '/dev.pk'\n",
    "test_path = data_path + str(test_prompt_id) + '/test.pk'\n",
    "pretrained_embedding = configs.PRETRAINED_EMBEDDING\n",
    "embedding_path = configs.EMBEDDING_PATH\n",
    "readability_path = configs.READABILITY_PATH\n",
    "prompt_path = configs.PROMPT_PATH\n",
    "vocab_size = configs.VOCAB_SIZE\n",
    "epochs = configs.EPOCHS\n",
    "batch_size = configs.BATCH_SIZE\n",
    "print(\"Numhead : \", num_heads, \" | Features : \",\n",
    "      features_path, \" | Pos_emb : \", configs.EMBEDDING_DIM)\n",
    "\n",
    "read_configs = {\n",
    "    'train_path': train_path,\n",
    "    'dev_path': dev_path,\n",
    "    'test_path': test_path,\n",
    "    'features_path': features_path,\n",
    "    'readability_path': readability_path,\n",
    "    'vocab_size': vocab_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " prompt_pos size: 8\n",
      " prompt_words size: 8\n",
      " pos_x size: 9513\n",
      " readability_x size: 9513\n",
      " pos_x size: 1680\n",
      " readability_x size: 1680\n",
      " pos_x size: 1783\n",
      " readability_x size: 1783\n",
      "Loading GloVe ...\n",
      "OOV number =189, OOV ratio = 0.047262\n"
     ]
    }
   ],
   "source": [
    "# read POS for prompts\n",
    "pos_vocab = read_pos_vocab(read_configs)\n",
    "prompt_pos_data = read_prompts_pos(\n",
    "    prompt_path, pos_vocab)  # for prompt POS embedding\n",
    "\n",
    "# read words for prompts\n",
    "word_vocab = read_word_vocab(read_configs)\n",
    "# for prompt word embedding\n",
    "prompt_data = read_prompts_we(prompt_path, word_vocab)\n",
    "\n",
    "train_data, dev_data, test_data = read_essays_prompts(\n",
    "    read_configs, prompt_data, prompt_pos_data, pos_vocab)\n",
    "\n",
    "if pretrained_embedding:\n",
    "    embedd_dict, embedd_dim, _ = load_word_embedding_dict(embedding_path)\n",
    "    embedd_matrix = build_embedd_table(\n",
    "        word_vocab, embedd_dict, embedd_dim, caseless=True)\n",
    "    embed_table = embedd_matrix\n",
    "else:\n",
    "    embed_table = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sent length: 50\n",
      "max sent num: 97\n",
      "max prompt sent length: 18\n",
      "max prompt sent num: 8\n",
      "================================\n",
      "X_train_pos:  (9513, 4850)\n",
      "X_train_prompt_words:  (9513, 4850)\n",
      "X_train_prompt_pos:  (9513, 4850)\n",
      "X_train_readability:  (9513, 35)\n",
      "X_train_ling:  (9513, 51)\n",
      "X_train_attribute_rel:  (9513, 9)\n",
      "Y_train:  (9513, 9)\n",
      "================================\n",
      "X_dev_pos:  (1680, 4850)\n",
      "X_dev_prompt_words:  (1680, 4850)\n",
      "X_dev_prompt_pos:  (1680, 4850)\n",
      "X_dev_readability:  (1680, 35)\n",
      "X_dev_ling:  (1680, 51)\n",
      "X_dev_attribute_rel:  (1680, 9)\n",
      "Y_dev:  (1680, 9)\n",
      "================================\n",
      "X_test_pos:  (1783, 4850)\n",
      "X_test_prompt_words:  (1783, 4850)\n",
      "X_test_prompt_pos:  (1783, 4850)\n",
      "X_test_readability:  (1783, 35)\n",
      "X_test_ling:  (1783, 51)\n",
      "X_test_attribute_rel:  (1783, 9)\n",
      "Y_test:  (1783, 9)\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "max_sentlen = max(train_data['max_sentlen'],\n",
    "                  dev_data['max_sentlen'], test_data['max_sentlen'])\n",
    "max_sentnum = max(train_data['max_sentnum'],\n",
    "                  dev_data['max_sentnum'], test_data['max_sentnum'])\n",
    "prompt_max_sentlen = prompt_data['max_sentlen']\n",
    "prompt_max_sentnum = prompt_data['max_sentnum']\n",
    "\n",
    "print('max sent length: {}'.format(max_sentlen))\n",
    "print('max sent num: {}'.format(max_sentnum))\n",
    "print('max prompt sent length: {}'.format(prompt_max_sentlen))\n",
    "print('max prompt sent num: {}'.format(prompt_max_sentnum))\n",
    "\n",
    "train_data['y_scaled'] = get_scaled_down_scores(\n",
    "    train_data['data_y'], train_data['prompt_ids'])\n",
    "dev_data['y_scaled'] = get_scaled_down_scores(\n",
    "    dev_data['data_y'], dev_data['prompt_ids'])\n",
    "test_data['y_scaled'] = get_scaled_down_scores(\n",
    "    test_data['data_y'], test_data['prompt_ids'])\n",
    "\n",
    "X_train_pos = pad_hierarchical_text_sequences(\n",
    "    train_data['pos_x'], max_sentnum, max_sentlen)\n",
    "X_dev_pos = pad_hierarchical_text_sequences(\n",
    "    dev_data['pos_x'], max_sentnum, max_sentlen)\n",
    "X_test_pos = pad_hierarchical_text_sequences(\n",
    "    test_data['pos_x'], max_sentnum, max_sentlen)\n",
    "\n",
    "X_train_pos = X_train_pos.reshape(\n",
    "    (X_train_pos.shape[0], X_train_pos.shape[1] * X_train_pos.shape[2]))\n",
    "X_dev_pos = X_dev_pos.reshape(\n",
    "    (X_dev_pos.shape[0], X_dev_pos.shape[1] * X_dev_pos.shape[2]))\n",
    "X_test_pos = X_test_pos.reshape(\n",
    "    (X_test_pos.shape[0], X_test_pos.shape[1] * X_test_pos.shape[2]))\n",
    "\n",
    "X_train_prompt = pad_hierarchical_text_sequences(\n",
    "    train_data['prompt_words'], max_sentnum, max_sentlen)\n",
    "X_dev_prompt = pad_hierarchical_text_sequences(\n",
    "    dev_data['prompt_words'], max_sentnum, max_sentlen)\n",
    "X_test_prompt = pad_hierarchical_text_sequences(\n",
    "    test_data['prompt_words'], max_sentnum, max_sentlen)\n",
    "\n",
    "X_train_prompt = X_train_prompt.reshape(\n",
    "    (X_train_prompt.shape[0], X_train_prompt.shape[1] * X_train_prompt.shape[2]))\n",
    "X_dev_prompt = X_dev_prompt.reshape(\n",
    "    (X_dev_prompt.shape[0], X_dev_prompt.shape[1] * X_dev_prompt.shape[2]))\n",
    "X_test_prompt = X_test_prompt.reshape(\n",
    "    (X_test_prompt.shape[0], X_test_prompt.shape[1] * X_test_prompt.shape[2]))\n",
    "\n",
    "X_train_prompt_pos = pad_hierarchical_text_sequences(\n",
    "    train_data['prompt_pos'], max_sentnum, max_sentlen)\n",
    "X_dev_prompt_pos = pad_hierarchical_text_sequences(\n",
    "    dev_data['prompt_pos'], max_sentnum, max_sentlen)\n",
    "X_test_prompt_pos = pad_hierarchical_text_sequences(\n",
    "    test_data['prompt_pos'], max_sentnum, max_sentlen)\n",
    "\n",
    "X_train_prompt_pos = X_train_prompt_pos.reshape(\n",
    "    (X_train_prompt_pos.shape[0], X_train_prompt_pos.shape[1] * X_train_prompt_pos.shape[2]))\n",
    "X_dev_prompt_pos = X_dev_prompt_pos.reshape(\n",
    "    (X_dev_prompt_pos.shape[0], X_dev_prompt_pos.shape[1] * X_dev_prompt_pos.shape[2]))\n",
    "X_test_prompt_pos = X_test_prompt_pos.reshape(\n",
    "    (X_test_prompt_pos.shape[0], X_test_prompt_pos.shape[1] * X_test_prompt_pos.shape[2]))\n",
    "\n",
    "X_train_linguistic_features = np.array(train_data['features_x'])\n",
    "X_dev_linguistic_features = np.array(dev_data['features_x'])\n",
    "X_test_linguistic_features = np.array(test_data['features_x'])\n",
    "\n",
    "X_train_readability = np.array(train_data['readability_x'])\n",
    "X_dev_readability = np.array(dev_data['readability_x'])\n",
    "X_test_readability = np.array(test_data['readability_x'])\n",
    "\n",
    "Y_train = np.array(train_data['y_scaled'])\n",
    "Y_dev = np.array(dev_data['y_scaled'])\n",
    "Y_test = np.array(test_data['y_scaled'])\n",
    "\n",
    "X_train_attribute_rel = get_attribute_masks(Y_train)\n",
    "X_dev_attribute_rel = get_attribute_masks(Y_dev)\n",
    "X_test_attribute_rel = get_attribute_masks(Y_test)\n",
    "\n",
    "print('================================')\n",
    "print('X_train_pos: ', X_train_pos.shape)\n",
    "print('X_train_prompt_words: ', X_train_prompt.shape)\n",
    "print('X_train_prompt_pos: ', X_train_prompt_pos.shape)\n",
    "print('X_train_readability: ', X_train_readability.shape)\n",
    "print('X_train_ling: ', X_train_linguistic_features.shape)\n",
    "print('X_train_attribute_rel: ', X_train_attribute_rel.shape)\n",
    "print('Y_train: ', Y_train.shape)\n",
    "\n",
    "print('================================')\n",
    "print('X_dev_pos: ', X_dev_pos.shape)\n",
    "print('X_dev_prompt_words: ', X_dev_prompt.shape)\n",
    "print('X_dev_prompt_pos: ', X_dev_prompt_pos.shape)\n",
    "print('X_dev_readability: ', X_dev_readability.shape)\n",
    "print('X_dev_ling: ', X_dev_linguistic_features.shape)\n",
    "print('X_dev_attribute_rel: ', X_dev_attribute_rel.shape)\n",
    "print('Y_dev: ', Y_dev.shape)\n",
    "\n",
    "print('================================')\n",
    "print('X_test_pos: ', X_test_pos.shape)\n",
    "print('X_test_prompt_words: ', X_test_prompt.shape)\n",
    "print('X_test_prompt_pos: ', X_test_prompt_pos.shape)\n",
    "print('X_test_readability: ', X_test_readability.shape)\n",
    "print('X_test_ling: ', X_test_linguistic_features.shape)\n",
    "print('X_test_attribute_rel: ', X_test_attribute_rel.shape)\n",
    "print('Y_test: ', Y_test.shape)\n",
    "print('================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to torch tensor\n",
    "train_dataset = TensorDataset(\n",
    "    torch.from_numpy(X_train_pos),\n",
    "    torch.from_numpy(X_train_prompt),\n",
    "    torch.from_numpy(X_train_prompt_pos),\n",
    "    torch.from_numpy(X_train_linguistic_features),\n",
    "    torch.from_numpy(X_train_readability),\n",
    "    torch.from_numpy(Y_train)\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dev_dataset = TensorDataset(\n",
    "    torch.from_numpy(X_dev_pos),\n",
    "    torch.from_numpy(X_dev_prompt),\n",
    "    torch.from_numpy(X_dev_prompt_pos),\n",
    "    torch.from_numpy(X_dev_linguistic_features),\n",
    "    torch.from_numpy(X_dev_readability),\n",
    "    torch.from_numpy(Y_dev)\n",
    ")\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size)\n",
    "\n",
    "dev_features_list = [\n",
    "    torch.from_numpy(X_dev_pos),\n",
    "    torch.from_numpy(X_dev_prompt),\n",
    "    torch.from_numpy(X_dev_prompt_pos),\n",
    "    torch.from_numpy(X_dev_linguistic_features),\n",
    "    torch.from_numpy(X_dev_readability)\n",
    "]\n",
    "test_features_list = [\n",
    "    torch.from_numpy(X_test_pos),\n",
    "    torch.from_numpy(X_test_prompt),\n",
    "    torch.from_numpy(X_test_prompt_pos),\n",
    "    torch.from_numpy(X_test_linguistic_features),\n",
    "    torch.from_numpy(X_test_readability)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.essay_pos_attention_list ModuleList(\n",
      "  (0-96): 97 x Attention()\n",
      ")\n",
      "Layer: attention_module.att_V | Size: torch.Size([100])\n",
      "Layer: attention_module.att_W | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_embedding.weight | Size: torch.Size([36, 50])\n",
      "Layer: essay_pos_conv.weight | Size: torch.Size([100, 50, 5])\n",
      "Layer: essay_pos_conv.bias | Size: torch.Size([100])\n",
      "Layer: essay_linquistic.weight | Size: torch.Size([100, 51])\n",
      "Layer: essay_linquistic.bias | Size: torch.Size([100])\n",
      "Layer: essay_readability.weight | Size: torch.Size([100, 35])\n",
      "Layer: essay_readability.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.0.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.0.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.0.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.0.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.0.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.0.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.0.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.0.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.1.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.1.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.1.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.1.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.1.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.1.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.1.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.1.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.2.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.2.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.2.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.2.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.2.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.2.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.2.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.2.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.3.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.3.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.3.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.3.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.3.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.3.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.3.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.3.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.4.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.4.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.4.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.4.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.4.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.4.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.4.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.4.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.5.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.5.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.5.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.5.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.5.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.5.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.5.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.5.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.6.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.6.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.6.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.6.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.6.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.6.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.6.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.6.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.7.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.7.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.7.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.7.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.7.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.7.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.7.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.7.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.8.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.8.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.8.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.8.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.8.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.8.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA.8.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_MA.8.dense.bias | Size: torch.Size([100])\n",
      "Layer: essay_pos_MA_LSTM.0.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.0.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.0.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.0.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.1.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.1.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.1.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.1.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.2.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.2.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.2.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.2.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.3.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.3.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.3.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.3.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.4.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.4.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.4.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.4.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.5.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.5.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.5.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.5.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.6.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.6.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.6.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.6.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.7.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.7.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.7.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.7.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.8.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.8.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: essay_pos_MA_LSTM.8.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_MA_LSTM.8.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: essay_pos_avg_MA_LSTM.0.att_V | Size: torch.Size([100])\n",
      "Layer: essay_pos_avg_MA_LSTM.0.att_W | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_avg_MA_LSTM.1.att_V | Size: torch.Size([100])\n",
      "Layer: essay_pos_avg_MA_LSTM.1.att_W | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_avg_MA_LSTM.2.att_V | Size: torch.Size([100])\n",
      "Layer: essay_pos_avg_MA_LSTM.2.att_W | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_avg_MA_LSTM.3.att_V | Size: torch.Size([100])\n",
      "Layer: essay_pos_avg_MA_LSTM.3.att_W | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_avg_MA_LSTM.4.att_V | Size: torch.Size([100])\n",
      "Layer: essay_pos_avg_MA_LSTM.4.att_W | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_avg_MA_LSTM.5.att_V | Size: torch.Size([100])\n",
      "Layer: essay_pos_avg_MA_LSTM.5.att_W | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_avg_MA_LSTM.6.att_V | Size: torch.Size([100])\n",
      "Layer: essay_pos_avg_MA_LSTM.6.att_W | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_avg_MA_LSTM.7.att_V | Size: torch.Size([100])\n",
      "Layer: essay_pos_avg_MA_LSTM.7.att_W | Size: torch.Size([100, 100])\n",
      "Layer: essay_pos_avg_MA_LSTM.8.att_V | Size: torch.Size([100])\n",
      "Layer: essay_pos_avg_MA_LSTM.8.att_W | Size: torch.Size([100, 100])\n",
      "Layer: prompt_embedding.weight | Size: torch.Size([4000, 50])\n",
      "Layer: prompt_pos_embedding.weight | Size: torch.Size([36, 50])\n",
      "Layer: prompt_cnn.weight | Size: torch.Size([100, 50, 5])\n",
      "Layer: prompt_cnn.bias | Size: torch.Size([100])\n",
      "Layer: prompt_MA.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: prompt_MA.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: prompt_MA.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: prompt_MA.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: prompt_MA.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: prompt_MA.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: prompt_MA.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: prompt_MA.dense.bias | Size: torch.Size([100])\n",
      "Layer: prompt_MA_lstm.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: prompt_MA_lstm.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: prompt_MA_lstm.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: prompt_MA_lstm.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_list.0.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.0.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.0.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.0.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.0.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.0.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.0.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.0.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.1.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.1.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.1.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.1.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.1.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.1.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.1.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.1.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.2.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.2.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.2.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.2.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.2.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.2.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.2.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.2.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.3.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.3.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.3.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.3.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.3.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.3.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.3.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.3.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.4.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.4.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.4.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.4.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.4.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.4.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.4.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.4.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.5.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.5.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.5.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.5.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.5.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.5.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.5.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.5.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.6.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.6.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.6.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.6.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.6.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.6.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.6.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.6.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.7.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.7.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.7.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.7.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.7.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.7.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.7.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.7.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.8.query_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.8.query_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.8.key_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.8.key_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.8.value_dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.8.value_dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_list.8.dense.weight | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_MA_list.8.dense.bias | Size: torch.Size([100])\n",
      "Layer: es_pr_MA_lstm_list.0.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.0.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.0.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.0.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.1.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.1.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.1.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.1.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.2.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.2.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.2.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.2.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.3.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.3.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.3.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.3.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.4.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.4.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.4.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.4.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.5.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.5.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.5.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.5.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.6.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.6.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.6.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.6.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.7.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.7.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.7.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.7.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.8.weight_ih_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.8.weight_hh_l0 | Size: torch.Size([400, 100])\n",
      "Layer: es_pr_MA_lstm_list.8.bias_ih_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_MA_lstm_list.8.bias_hh_l0 | Size: torch.Size([400])\n",
      "Layer: es_pr_avg_lstm_list.0.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.0.att_W | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_avg_lstm_list.1.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.1.att_W | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_avg_lstm_list.2.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.2.att_W | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_avg_lstm_list.3.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.3.att_W | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_avg_lstm_list.4.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.4.att_W | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_avg_lstm_list.5.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.5.att_W | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_avg_lstm_list.6.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.6.att_W | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_avg_lstm_list.7.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.7.att_W | Size: torch.Size([100, 100])\n",
      "Layer: es_pr_avg_lstm_list.8.att_V | Size: torch.Size([100])\n",
      "Layer: es_pr_avg_lstm_list.8.att_W | Size: torch.Size([100, 100])\n",
      "Layer: final_dense_list.0.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.0.bias | Size: torch.Size([1])\n",
      "Layer: final_dense_list.1.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.1.bias | Size: torch.Size([1])\n",
      "Layer: final_dense_list.2.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.2.bias | Size: torch.Size([1])\n",
      "Layer: final_dense_list.3.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.3.bias | Size: torch.Size([1])\n",
      "Layer: final_dense_list.4.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.4.bias | Size: torch.Size([1])\n",
      "Layer: final_dense_list.5.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.5.bias | Size: torch.Size([1])\n",
      "Layer: final_dense_list.6.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.6.bias | Size: torch.Size([1])\n",
      "Layer: final_dense_list.7.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.7.bias | Size: torch.Size([1])\n",
      "Layer: final_dense_list.8.weight | Size: torch.Size([1, 286])\n",
      "Layer: final_dense_list.8.bias | Size: torch.Size([1])\n",
      "Layer: att_attention.in_proj_weight | Size: torch.Size([558, 186])\n",
      "Layer: att_attention.in_proj_bias | Size: torch.Size([558])\n",
      "Layer: att_attention.out_proj.weight | Size: torch.Size([186, 186])\n",
      "Layer: att_attention.out_proj.bias | Size: torch.Size([186])\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "model = ProTACT(\n",
    "    len(pos_vocab), len(word_vocab), max_sentnum, max_sentlen,\n",
    "    X_train_readability.shape[1], X_train_linguistic_features.shape[1],\n",
    "    configs, Y_train.shape[1], num_heads, embed_table\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# loss function and optimizer\n",
    "criterion = LossFunctions(alpha=0.7)\n",
    "optimizer = torch.optim.RMSprop(\n",
    "    model.parameters(), lr=configs.LEARNING_RATE)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_drop_x:  torch.Size([1680, 4850, 50])\n",
      "pos_resh_W torch.Size([1680, 97, 50, 50])\n",
      "pos_zcnn torch.Size([1680, 97, 46, 100])\n",
      "pos_avg_zcnn torch.Size([1680, 97, 100])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "matmul(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m AllAttEvaluator(\n\u001b[1;32m      2\u001b[0m     test_prompt_id, dev_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      3\u001b[0m     [x\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m dev_features_list],\n\u001b[1;32m      4\u001b[0m     [x\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m test_features_list], Y_dev, Y_test, seed\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/수업자료/skku4-3/인공지능프로젝트/프로젝트/ProTACT 공부/ProTACT/torch/evaluators/multitask_evaluator_all_attributes.py:58\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[0;34m(self, model, epoch, print_info)\u001b[0m\n\u001b[1;32m     56\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 58\u001b[0m     dev_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdev_features_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     60\u001b[0m     test_pred \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m[torch\u001b[38;5;241m.\u001b[39mfrom_numpy(feat)\n\u001b[1;32m     61\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_features_list])\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     63\u001b[0m dev_pred_int \u001b[38;5;241m=\u001b[39m dev_pred \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/수업자료/skku4-3/인공지능프로젝트/프로젝트/ProTACT 공부/ProTACT/torch/models/ProTACT.py:154\u001b[0m, in \u001b[0;36mProTACT.forward\u001b[0;34m(self, pos_input, prompt_word_input, prompt_pos_input, linguistic_input, readability_input)\u001b[0m\n\u001b[1;32m    150\u001b[0m pos_MA_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39messay_pos_MA[i](\n\u001b[1;32m    151\u001b[0m     pos_avg_zcnn) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim)]\n\u001b[1;32m    152\u001b[0m pos_MA_lstm_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39messay_pos_MA_LSTM[i](\n\u001b[1;32m    153\u001b[0m     pos_MA_list[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim)]\n\u001b[0;32m--> 154\u001b[0m pos_avg_MA_lstm_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39messay_pos_avg_MA_LSTM[i](\n\u001b[1;32m    155\u001b[0m     pos_MA_lstm_list[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim)]\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Prompt Representation\u001b[39;00m\n\u001b[1;32m    158\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_embedding(prompt_word_input)\n",
      "File \u001b[0;32m~/Desktop/수업자료/skku4-3/인공지능프로젝트/프로젝트/ProTACT 공부/ProTACT/torch/models/ProTACT.py:154\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    150\u001b[0m pos_MA_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39messay_pos_MA[i](\n\u001b[1;32m    151\u001b[0m     pos_avg_zcnn) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim)]\n\u001b[1;32m    152\u001b[0m pos_MA_lstm_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39messay_pos_MA_LSTM[i](\n\u001b[1;32m    153\u001b[0m     pos_MA_list[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim)]\n\u001b[0;32m--> 154\u001b[0m pos_avg_MA_lstm_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43messay_pos_avg_MA_LSTM\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos_MA_lstm_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim)]\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Prompt Representation\u001b[39;00m\n\u001b[1;32m    158\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_embedding(prompt_word_input)\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/수업자료/skku4-3/인공지능프로젝트/프로젝트/ProTACT 공부/ProTACT/torch/custom_layers/attention.py:24\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 24\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matt_W\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation:\n\u001b[1;32m     26\u001b[0m         w \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensordot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt_V, w, dims\u001b[38;5;241m=\u001b[39m[[\u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m2\u001b[39m]])\n",
      "\u001b[0;31mTypeError\u001b[0m: matmul(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "evaluator = AllAttEvaluator(\n",
    "    test_prompt_id, dev_data['prompt_ids'], test_data['prompt_ids'],\n",
    "    [x.numpy() for x in dev_features_list],\n",
    "    [x.numpy() for x in test_features_list], Y_dev, Y_test, seed\n",
    ")\n",
    "\n",
    "evaluator.evaluate(model, -1, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomHistory:\n",
    "    def __init__(self):\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def update(self, train_loss, val_loss):\n",
    "        self.train_loss.append(train_loss)\n",
    "        self.val_loss.append(val_loss)\n",
    "        \n",
    "        \n",
    "custom_hist = CustomHistory()\n",
    "\n",
    "for epoch in range(epochs): # 50\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    start_time = time.time()\n",
    "\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch_data = [x.to(device) for x in batch_data]\n",
    "        inputs, targets = batch_data[:-1], batch_data[-1]\n",
    "        outputs = model(*inputs)\n",
    "        loss = criterion.loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * batch_data[0].size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # validate\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_data in dev_loader:\n",
    "            batch_data = [x.to(device) for x in batch_data]\n",
    "            inputs, targets = batch_data[:-1], batch_data[-1]\n",
    "            outputs = model(*inputs)\n",
    "            #loss = criterion(outputs, targets)\n",
    "            loss = criterion.loss_function(outputs, targets)\n",
    "            val_loss += loss.item() * batch_data[0].size(0)\n",
    "        val_loss /= len(dev_loader.dataset)\n",
    "\n",
    "    custom_hist.update(train_loss, val_loss)\n",
    "\n",
    "    # evaluate\n",
    "    tt_time = time.time() - start_time\n",
    "    print(f\"Training one epoch in {tt_time:.3f} s\")\n",
    "    evaluator.evaluate(model, epoch + 1)\n",
    "    print(f\"Train Loss: {train_loss:.4f} || Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "evaluator.print_final_info()\n",
    "\n",
    "'''# show the loss as the graph\n",
    "fig, loss_graph = plt.subplots()\n",
    "loss_graph.plot(custom_hist.train_loss,'y',label='train loss')\n",
    "loss_graph.plot(custom_hist.val_loss,'r',label='val loss')\n",
    "loss_graph.set_xlabel('epoch')\n",
    "loss_graph.set_ylabel('loss')\n",
    "plt.savefig(str('images/protact/test_prompt_'+ str(test_prompt_id) + '_seed_' + str(seed) + '_loss.png'))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
