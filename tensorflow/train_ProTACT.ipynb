{"cells":[{"cell_type":"code","execution_count":1,"id":"f7190dd3","metadata":{"id":"f7190dd3","executionInfo":{"status":"ok","timestamp":1717306279444,"user_tz":-540,"elapsed":3994,"user":{"displayName":"나인호","userId":"08373838400323353884"}}},"outputs":[],"source":["# if play the code in CoLab\n","import pandas as pd\n","import seaborn as sns\n","from google.colab import files\n","import io\n","import warnings\n","\n","warnings.filterwarnings(action='ignore')"]},{"cell_type":"code","execution_count":2,"id":"75a7b68b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75a7b68b","executionInfo":{"status":"ok","timestamp":1717306302502,"user_tz":-540,"elapsed":20374,"user":{"displayName":"나인호","userId":"08373838400323353884"}},"outputId":"ac441154-0a69-47aa-db62-60eda00676d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# if play the code in CoLab\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"id":"1048cd7b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1048cd7b","executionInfo":{"status":"ok","timestamp":1717306306492,"user_tz":-540,"elapsed":2167,"user":{"displayName":"나인호","userId":"08373838400323353884"}},"outputId":"649252a8-f50e-468b-cdf6-0f95d9ba9966"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/인지프/프로젝트/ProTACT/tensorflow\n"]}],"source":["# if play the code in CoLab\n","%cd drive/My Drive/Colab Notebooks/인지프/프로젝트/ProTACT/tensorflow"]},{"cell_type":"code","execution_count":4,"id":"ade1964c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ade1964c","executionInfo":{"status":"ok","timestamp":1717306324052,"user_tz":-540,"elapsed":15941,"user":{"displayName":"나인호","userId":"08373838400323353884"}},"outputId":"b5d1353a-1c2e-4f8c-c316-96f69a92af1a"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]}],"source":["# Load autoreload extension\n","%load_ext autoreload\n","\n","# Set autoreload behavior\n","%autoreload 2\n","import pickle\n","import os\n","import time\n","import argparse\n","import random\n","import numpy as np\n","from models.ProTACT import build_ProTACT\n","import tensorflow as tf\n","from configs.configs import Configs\n","from utils.read_data_pr import read_pos_vocab, read_word_vocab, read_prompts_we, read_essays_prompts, read_prompts_pos\n","from utils.general_utils import get_scaled_down_scores, pad_hierarchical_text_sequences, get_attribute_masks, load_word_embedding_dict, build_embedd_table\n","from evaluators.multitask_evaluator_all_attributes import Evaluator as AllAttEvaluator\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":5,"id":"2215898e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2215898e","executionInfo":{"status":"ok","timestamp":1717306327000,"user_tz":-540,"elapsed":3,"user":{"displayName":"나인호","userId":"08373838400323353884"}},"outputId":"fa4ef4b2-802b-4c2c-b757-4dfaffcad63b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test prompt id is 1 of type <class 'int'>\n","Seed: 1\n","Numhead :  2  | Features :  ../data/hand_crafted_v3.csv  | Pos_emb :  50\n","model :  gru  | Load :  False\n"]}],"source":["# parser = argparse.ArgumentParser(description=\"ProTACT model\")\n","# parser.add_argument('--test_prompt_id', type=int, default=1, help='prompt id of test essay set')\n","# parser.add_argument('--seed', type=int, default=12, help='set random seed')\n","# parser.add_argument('--model_name', type=str,\n","#                     choices=['ProTACT'],\n","#                     help='name of model')\n","# parser.add_argument('--num_heads', type=int, default=2, help='set the number of heads in Multihead Attention')\n","# parser.add_argument('--features_path', type=str, default='data/hand_crafted_v3.csv')\n","\n","test_prompt_id = 1\n","seed = 1\n","num_heads = 2\n","features_path = '../data/hand_crafted_v3.csv'\n","\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","\n","print(\"Test prompt id is {} of type {}\".format(test_prompt_id, type(test_prompt_id)))\n","print(\"Seed: {}\".format(seed))\n","\n","configs = Configs()\n","\n","data_path = configs.DATA_PATH\n","train_path = data_path + str(test_prompt_id) + '/train.pk'\n","dev_path = data_path + str(test_prompt_id) + '/dev.pk'\n","test_path = data_path + str(test_prompt_id) + '/test.pk'\n","pretrained_embedding = configs.PRETRAINED_EMBEDDING\n","embedding_path = configs.EMBEDDING_PATH\n","readability_path = configs.READABILITY_PATH\n","prompt_path = configs.PROMPT_PATH\n","vocab_size = configs.VOCAB_SIZE\n","epochs = configs.EPOCHS\n","batch_size = configs.BATCH_SIZE\n","load = configs.LOAD\n","\n","lstm_model = configs.LSTM_MODEL\n","print(\"Numhead : \", num_heads, \" | Features : \", features_path, \" | Pos_emb : \", configs.EMBEDDING_DIM)\n","print(\"model : \", lstm_model, \" | Load : \", load )\n","\n","read_configs = {\n","    'train_path': train_path,\n","    'dev_path': dev_path,\n","    'test_path': test_path,\n","    'features_path': features_path,\n","    'readability_path': readability_path,\n","    'vocab_size': vocab_size\n","}"]},{"cell_type":"code","execution_count":6,"id":"c1c27955","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1c27955","executionInfo":{"status":"ok","timestamp":1717306610624,"user_tz":-540,"elapsed":281618,"user":{"displayName":"나인호","userId":"08373838400323353884"}},"outputId":"bbc47482-29bd-472e-a71d-407c67c1c066"},"outputs":[{"output_type":"stream","name":"stdout","text":[" prompt_pos size: 8\n"," prompt_words size: 8\n"," pos_x size: 9513\n"," readability_x size: 9513\n"," pos_x size: 1680\n"," readability_x size: 1680\n"," pos_x size: 1783\n"," readability_x size: 1783\n","Loading GloVe ...\n","OOV number =190, OOV ratio = 0.047512\n"]}],"source":["# read POS for prompts\n","pos_vocab = read_pos_vocab(read_configs)\n","prompt_pos_data = read_prompts_pos(prompt_path, pos_vocab) # for prompt POS embedding\n","\n","# read words for prompts\n","word_vocab = read_word_vocab(read_configs)\n","prompt_data = read_prompts_we(prompt_path, word_vocab) # for prompt word embedding\n","\n","# read essays and prompts\n","train_data, dev_data, test_data = read_essays_prompts(read_configs, prompt_data, prompt_pos_data, pos_vocab)\n","\n","if pretrained_embedding:\n","    embedd_dict, embedd_dim, _ = load_word_embedding_dict(embedding_path)\n","    embedd_matrix = build_embedd_table(word_vocab, embedd_dict, embedd_dim, caseless=True)\n","    embed_table = [embedd_matrix]\n","else:\n","    embed_table = None"]},{"cell_type":"code","execution_count":7,"id":"1e512e42","metadata":{"id":"1e512e42","executionInfo":{"status":"ok","timestamp":1717306615010,"user_tz":-540,"elapsed":607,"user":{"displayName":"나인호","userId":"08373838400323353884"}}},"outputs":[],"source":["def sample_data_dict(data_dict, sample_ratio=0.1):\n","    keys = list(data_dict.keys())\n","    # 먼저 첫 번째 키에 대한 샘플 크기를 계산합니다.\n","    sample_size = int(len(data_dict[keys[0]]) * sample_ratio)\n","    indices = np.random.choice(len(data_dict[keys[0]]), sample_size, replace=False)\n","\n","    sampled_dict = {}\n","    for key in keys:\n","        if isinstance(data_dict[key], list) or isinstance(data_dict[key], np.ndarray):\n","            sampled_dict[key] = [data_dict[key][i] for i in indices]\n","        else:\n","            sampled_dict[key] = data_dict[key]\n","\n","    return sampled_dict\n","# train data만 10% 사용. 나머지는 비교를 위해 그대로 사용한다.\n","#train_data = sample_data_dict(train_data) # train data를 10%만 사용\n","#dev_data = sample_data_dict(dev_data) # dev data를 10%만 사용\n","#test_data = sample_data_dict(test_data) # test data를 10%만 사용"]},{"cell_type":"code","execution_count":8,"id":"c7e8f956","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c7e8f956","executionInfo":{"status":"ok","timestamp":1717306618899,"user_tz":-540,"elapsed":1758,"user":{"displayName":"나인호","userId":"08373838400323353884"}},"outputId":"ea4a8424-8b3e-4704-c157-d19b716b94e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["max sent length: 50\n","max sent num: 97\n","max prompt sent length: 18\n","max prompt sent num: 8\n","================================\n","X_train_pos:  (9513, 4850)\n","X_train_prompt_words:  (9513, 4850)\n","X_train_prompt_pos:  (9513, 4850)\n","X_train_readability:  (9513, 35)\n","X_train_ling:  (9513, 51)\n","X_train_attribute_rel:  (9513, 9)\n","Y_train:  (9513, 9)\n","================================\n","X_dev_pos:  (1680, 4850)\n","X_dev_prompt_words:  (1680, 4850)\n","X_dev_prompt_pos:  (1680, 4850)\n","X_dev_readability:  (1680, 35)\n","X_dev_ling:  (1680, 51)\n","X_dev_attribute_rel:  (1680, 9)\n","Y_dev:  (1680, 9)\n","================================\n","X_test_pos:  (1783, 4850)\n","X_test_prompt_words:  (1783, 4850)\n","X_test_prompt_pos:  (1783, 4850)\n","X_test_readability:  (1783, 35)\n","X_test_ling:  (1783, 51)\n","X_test_attribute_rel:  (1783, 9)\n","Y_test:  (1783, 9)\n","================================\n"]}],"source":["max_sentlen = max(train_data['max_sentlen'], dev_data['max_sentlen'], test_data['max_sentlen'])\n","max_sentnum = max(train_data['max_sentnum'], dev_data['max_sentnum'], test_data['max_sentnum'])\n","prompt_max_sentlen = prompt_data['max_sentlen']\n","prompt_max_sentnum = prompt_data['max_sentnum']\n","\n","print('max sent length: {}'.format(max_sentlen))\n","print('max sent num: {}'.format(max_sentnum))\n","print('max prompt sent length: {}'.format(prompt_max_sentlen))\n","print('max prompt sent num: {}'.format(prompt_max_sentnum))\n","\n","train_data['y_scaled'] = get_scaled_down_scores(train_data['data_y'], train_data['prompt_ids'])\n","dev_data['y_scaled'] = get_scaled_down_scores(dev_data['data_y'], dev_data['prompt_ids'])\n","test_data['y_scaled'] = get_scaled_down_scores(test_data['data_y'], test_data['prompt_ids'])\n","\n","X_train_pos = pad_hierarchical_text_sequences(train_data['pos_x'], max_sentnum, max_sentlen)\n","X_dev_pos = pad_hierarchical_text_sequences(dev_data['pos_x'], max_sentnum, max_sentlen)\n","X_test_pos = pad_hierarchical_text_sequences(test_data['pos_x'], max_sentnum, max_sentlen)\n","\n","X_train_pos = X_train_pos.reshape((X_train_pos.shape[0], X_train_pos.shape[1] * X_train_pos.shape[2]))\n","X_dev_pos = X_dev_pos.reshape((X_dev_pos.shape[0], X_dev_pos.shape[1] * X_dev_pos.shape[2]))\n","X_test_pos = X_test_pos.reshape((X_test_pos.shape[0], X_test_pos.shape[1] * X_test_pos.shape[2]))\n","\n","X_train_prompt = pad_hierarchical_text_sequences(train_data['prompt_words'], max_sentnum, max_sentlen)\n","X_dev_prompt = pad_hierarchical_text_sequences(dev_data['prompt_words'], max_sentnum, max_sentlen)\n","X_test_prompt = pad_hierarchical_text_sequences(test_data['prompt_words'], max_sentnum, max_sentlen)\n","\n","X_train_prompt = X_train_prompt.reshape((X_train_prompt.shape[0], X_train_prompt.shape[1] * X_train_prompt.shape[2]))\n","X_dev_prompt = X_dev_prompt.reshape((X_dev_prompt.shape[0], X_dev_prompt.shape[1] * X_dev_prompt.shape[2]))\n","X_test_prompt = X_test_prompt.reshape((X_test_prompt.shape[0], X_test_prompt.shape[1] * X_test_prompt.shape[2]))\n","\n","X_train_prompt_pos = pad_hierarchical_text_sequences(train_data['prompt_pos'], max_sentnum, max_sentlen)\n","X_dev_prompt_pos = pad_hierarchical_text_sequences(dev_data['prompt_pos'], max_sentnum, max_sentlen)\n","X_test_prompt_pos = pad_hierarchical_text_sequences(test_data['prompt_pos'], max_sentnum, max_sentlen)\n","\n","X_train_prompt_pos = X_train_prompt_pos.reshape((X_train_prompt_pos.shape[0], X_train_prompt_pos.shape[1] * X_train_prompt_pos.shape[2]))\n","X_dev_prompt_pos = X_dev_prompt_pos.reshape((X_dev_prompt_pos.shape[0], X_dev_prompt_pos.shape[1] * X_dev_prompt_pos.shape[2]))\n","X_test_prompt_pos = X_test_prompt_pos.reshape((X_test_prompt_pos.shape[0], X_test_prompt_pos.shape[1] * X_test_prompt_pos.shape[2]))\n","\n","X_train_linguistic_features = np.array(train_data['features_x'])\n","X_dev_linguistic_features = np.array(dev_data['features_x'])\n","X_test_linguistic_features = np.array(test_data['features_x'])\n","\n","X_train_readability = np.array(train_data['readability_x'])\n","X_dev_readability = np.array(dev_data['readability_x'])\n","X_test_readability = np.array(test_data['readability_x'])\n","\n","Y_train = np.array(train_data['y_scaled'])\n","Y_dev = np.array(dev_data['y_scaled'])\n","Y_test = np.array(test_data['y_scaled'])\n","\n","X_train_attribute_rel = get_attribute_masks(Y_train)\n","X_dev_attribute_rel = get_attribute_masks(Y_dev)\n","X_test_attribute_rel = get_attribute_masks(Y_test)\n","\n","print('================================')\n","print('X_train_pos: ', X_train_pos.shape)\n","print('X_train_prompt_words: ', X_train_prompt.shape)\n","print('X_train_prompt_pos: ', X_train_prompt_pos.shape)\n","print('X_train_readability: ', X_train_readability.shape)\n","print('X_train_ling: ', X_train_linguistic_features.shape)\n","print('X_train_attribute_rel: ', X_train_attribute_rel.shape)\n","print('Y_train: ', Y_train.shape)\n","\n","print('================================')\n","print('X_dev_pos: ', X_dev_pos.shape)\n","print('X_dev_prompt_words: ', X_dev_prompt.shape)\n","print('X_dev_prompt_pos: ', X_dev_prompt_pos.shape)\n","print('X_dev_readability: ', X_dev_readability.shape)\n","print('X_dev_ling: ', X_dev_linguistic_features.shape)\n","print('X_dev_attribute_rel: ', X_dev_attribute_rel.shape)\n","print('Y_dev: ', Y_dev.shape)\n","\n","print('================================')\n","print('X_test_pos: ', X_test_pos.shape)\n","print('X_test_prompt_words: ', X_test_prompt.shape)\n","print('X_test_prompt_pos: ', X_test_prompt_pos.shape)\n","print('X_test_readability: ', X_test_readability.shape)\n","print('X_test_ling: ', X_test_linguistic_features.shape)\n","print('X_test_attribute_rel: ', X_test_attribute_rel.shape)\n","print('Y_test: ', Y_test.shape)\n","print('================================')"]},{"cell_type":"code","execution_count":9,"id":"55cd0505","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"55cd0505","executionInfo":{"status":"ok","timestamp":1717306659832,"user_tz":-540,"elapsed":37597,"user":{"displayName":"나인호","userId":"08373838400323353884"}},"outputId":"73eba6d2-7e00-44a5-d68c-e22b036c0e59"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," prompt_word_input (InputLa  [(None, 4850)]               0         []                            \n"," yer)                                                                                             \n","                                                                                                  \n"," prompt_pos_input (InputLay  [(None, 4850)]               0         []                            \n"," er)                                                                                              \n","                                                                                                  \n"," pos_input (InputLayer)      [(None, 4850)]               0         []                            \n","                                                                                                  \n"," prompt (Embedding)          (None, 4850, 50)             200000    ['prompt_word_input[0][0]']   \n","                                                                                                  \n"," pos_prompt (Embedding)      (None, 4850, 50)             1800      ['prompt_pos_input[0][0]']    \n","                                                                                                  \n"," pos_x (Embedding)           (None, 4850, 50)             1800      ['pos_input[0][0]']           \n","                                                                                                  \n"," prompt_maskedout (ZeroMask  (None, 4850, 50)             0         ['prompt[0][0]']              \n"," edEntries)                                                                                       \n","                                                                                                  \n"," prompt_pos_maskedout (Zero  (None, 4850, 50)             0         ['pos_prompt[0][0]']          \n"," MaskedEntries)                                                                                   \n","                                                                                                  \n"," pos_x_maskedout (ZeroMaske  (None, 4850, 50)             0         ['pos_x[0][0]']               \n"," dEntries)                                                                                        \n","                                                                                                  \n"," add (Add)                   (None, 4850, 50)             0         ['prompt_maskedout[0][0]',    \n","                                                                     'prompt_pos_maskedout[0][0]']\n","                                                                                                  \n"," pos_drop_x (Dropout)        (None, 4850, 50)             0         ['pos_x_maskedout[0][0]']     \n","                                                                                                  \n"," prompt_drop_x (Dropout)     (None, 4850, 50)             0         ['add[0][0]']                 \n","                                                                                                  \n"," pos_resh_W (Reshape)        (None, 97, 50, 50)           0         ['pos_drop_x[0][0]']          \n","                                                                                                  \n"," prompt_resh_W (Reshape)     (None, 97, 50, 50)           0         ['prompt_drop_x[0][0]']       \n","                                                                                                  \n"," pos_zcnn (TimeDistributed)  (None, 97, 46, 100)          25100     ['pos_resh_W[0][0]']          \n","                                                                                                  \n"," prompt_zcnn (TimeDistribut  (None, 97, 46, 100)          25100     ['prompt_resh_W[0][0]']       \n"," ed)                                                                                              \n","                                                                                                  \n"," pos_avg_zcnn (TimeDistribu  (None, 97, 100)              10100     ['pos_zcnn[0][0]']            \n"," ted)                                                                                             \n","                                                                                                  \n"," prompt_avg_zcnn (TimeDistr  (None, 97, 100)              10100     ['prompt_zcnn[0][0]']         \n"," ibuted)                                                                                          \n","                                                                                                  \n"," multi_head_attention (Mult  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n"," iHeadAttention)                                                                                  \n","                                                                                                  \n"," multi_head_attention_9 (Mu  (None, None, 100)            40400     ['prompt_avg_zcnn[0][0]']     \n"," ltiHeadAttention)                                                                                \n","                                                                                                  \n"," multi_head_attention_1 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n"," ltiHeadAttention)                                                                                \n","                                                                                                  \n"," multi_head_attention_2 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n"," ltiHeadAttention)                                                                                \n","                                                                                                  \n"," multi_head_attention_3 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n"," ltiHeadAttention)                                                                                \n","                                                                                                  \n"," multi_head_attention_4 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n"," ltiHeadAttention)                                                                                \n","                                                                                                  \n"," multi_head_attention_5 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n"," ltiHeadAttention)                                                                                \n","                                                                                                  \n"," multi_head_attention_6 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n"," ltiHeadAttention)                                                                                \n","                                                                                                  \n"," multi_head_attention_7 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n"," ltiHeadAttention)                                                                                \n","                                                                                                  \n"," multi_head_attention_8 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n"," ltiHeadAttention)                                                                                \n","                                                                                                  \n"," gru (GRU)                   (None, None, 100)            60600     ['multi_head_attention[0][0]']\n","                                                                                                  \n"," gru_9 (GRU)                 (None, None, 100)            60600     ['multi_head_attention_9[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," gru_1 (GRU)                 (None, None, 100)            60600     ['multi_head_attention_1[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," gru_2 (GRU)                 (None, None, 100)            60600     ['multi_head_attention_2[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," gru_3 (GRU)                 (None, None, 100)            60600     ['multi_head_attention_3[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," gru_4 (GRU)                 (None, None, 100)            60600     ['multi_head_attention_4[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," gru_5 (GRU)                 (None, None, 100)            60600     ['multi_head_attention_5[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," gru_6 (GRU)                 (None, None, 100)            60600     ['multi_head_attention_6[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," gru_7 (GRU)                 (None, None, 100)            60600     ['multi_head_attention_7[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," gru_8 (GRU)                 (None, None, 100)            60600     ['multi_head_attention_8[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," attention_1 (Attention)     (None, 100)                  10100     ['gru[0][0]']                 \n","                                                                                                  \n"," attention_11 (Attention)    (None, 100)                  10100     ['gru_9[0][0]']               \n","                                                                                                  \n"," attention_2 (Attention)     (None, 100)                  10100     ['gru_1[0][0]']               \n","                                                                                                  \n"," attention_3 (Attention)     (None, 100)                  10100     ['gru_2[0][0]']               \n","                                                                                                  \n"," attention_4 (Attention)     (None, 100)                  10100     ['gru_3[0][0]']               \n","                                                                                                  \n"," attention_5 (Attention)     (None, 100)                  10100     ['gru_4[0][0]']               \n","                                                                                                  \n"," attention_6 (Attention)     (None, 100)                  10100     ['gru_5[0][0]']               \n","                                                                                                  \n"," attention_7 (Attention)     (None, 100)                  10100     ['gru_6[0][0]']               \n","                                                                                                  \n"," attention_8 (Attention)     (None, 100)                  10100     ['gru_7[0][0]']               \n","                                                                                                  \n"," attention_9 (Attention)     (None, 100)                  10100     ['gru_8[0][0]']               \n","                                                                                                  \n"," multi_head_attention_pe (M  (None, None, 100)            40400     ['attention_1[0][0]',         \n"," ultiHeadAttention_PE)                                               'attention_11[0][0]']        \n","                                                                                                  \n"," multi_head_attention_pe_1   (None, None, 100)            40400     ['attention_2[0][0]',         \n"," (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n","                                                                                                  \n"," multi_head_attention_pe_2   (None, None, 100)            40400     ['attention_3[0][0]',         \n"," (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n","                                                                                                  \n"," multi_head_attention_pe_3   (None, None, 100)            40400     ['attention_4[0][0]',         \n"," (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n","                                                                                                  \n"," multi_head_attention_pe_4   (None, None, 100)            40400     ['attention_5[0][0]',         \n"," (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n","                                                                                                  \n"," multi_head_attention_pe_5   (None, None, 100)            40400     ['attention_6[0][0]',         \n"," (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n","                                                                                                  \n"," multi_head_attention_pe_6   (None, None, 100)            40400     ['attention_7[0][0]',         \n"," (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n","                                                                                                  \n"," multi_head_attention_pe_7   (None, None, 100)            40400     ['attention_8[0][0]',         \n"," (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n","                                                                                                  \n"," multi_head_attention_pe_8   (None, None, 100)            40400     ['attention_9[0][0]',         \n"," (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n","                                                                                                  \n"," lstm (LSTM)                 (None, None, 100)            80400     ['multi_head_attention_pe[0][0\n","                                                                    ]']                           \n","                                                                                                  \n"," lstm_1 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_pe_1[0]\n","                                                                    [0]']                         \n","                                                                                                  \n"," lstm_2 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_pe_2[0]\n","                                                                    [0]']                         \n","                                                                                                  \n"," lstm_3 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_pe_3[0]\n","                                                                    [0]']                         \n","                                                                                                  \n"," lstm_4 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_pe_4[0]\n","                                                                    [0]']                         \n","                                                                                                  \n"," lstm_5 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_pe_5[0]\n","                                                                    [0]']                         \n","                                                                                                  \n"," lstm_6 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_pe_6[0]\n","                                                                    [0]']                         \n","                                                                                                  \n"," lstm_7 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_pe_7[0]\n","                                                                    [0]']                         \n","                                                                                                  \n"," lstm_8 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_pe_8[0]\n","                                                                    [0]']                         \n","                                                                                                  \n"," attention_12 (Attention)    (None, 100)                  10100     ['lstm[0][0]']                \n","                                                                                                  \n"," linguistic_input (InputLay  [(None, 51)]                 0         []                            \n"," er)                                                                                              \n","                                                                                                  \n"," readability_input (InputLa  [(None, 35)]                 0         []                            \n"," yer)                                                                                             \n","                                                                                                  \n"," attention_13 (Attention)    (None, 100)                  10100     ['lstm_1[0][0]']              \n","                                                                                                  \n"," attention_14 (Attention)    (None, 100)                  10100     ['lstm_2[0][0]']              \n","                                                                                                  \n"," attention_15 (Attention)    (None, 100)                  10100     ['lstm_3[0][0]']              \n","                                                                                                  \n"," attention_16 (Attention)    (None, 100)                  10100     ['lstm_4[0][0]']              \n","                                                                                                  \n"," attention_17 (Attention)    (None, 100)                  10100     ['lstm_5[0][0]']              \n","                                                                                                  \n"," attention_18 (Attention)    (None, 100)                  10100     ['lstm_6[0][0]']              \n","                                                                                                  \n"," attention_19 (Attention)    (None, 100)                  10100     ['lstm_7[0][0]']              \n","                                                                                                  \n"," attention_20 (Attention)    (None, 100)                  10100     ['lstm_8[0][0]']              \n","                                                                                                  \n"," concatenate (Concatenate)   (None, 186)                  0         ['attention_12[0][0]',        \n","                                                                     'linguistic_input[0][0]',    \n","                                                                     'readability_input[0][0]']   \n","                                                                                                  \n"," concatenate_1 (Concatenate  (None, 186)                  0         ['attention_13[0][0]',        \n"," )                                                                   'linguistic_input[0][0]',    \n","                                                                     'readability_input[0][0]']   \n","                                                                                                  \n"," concatenate_2 (Concatenate  (None, 186)                  0         ['attention_14[0][0]',        \n"," )                                                                   'linguistic_input[0][0]',    \n","                                                                     'readability_input[0][0]']   \n","                                                                                                  \n"," concatenate_3 (Concatenate  (None, 186)                  0         ['attention_15[0][0]',        \n"," )                                                                   'linguistic_input[0][0]',    \n","                                                                     'readability_input[0][0]']   \n","                                                                                                  \n"," concatenate_4 (Concatenate  (None, 186)                  0         ['attention_16[0][0]',        \n"," )                                                                   'linguistic_input[0][0]',    \n","                                                                     'readability_input[0][0]']   \n","                                                                                                  \n"," concatenate_5 (Concatenate  (None, 186)                  0         ['attention_17[0][0]',        \n"," )                                                                   'linguistic_input[0][0]',    \n","                                                                     'readability_input[0][0]']   \n","                                                                                                  \n"," concatenate_6 (Concatenate  (None, 186)                  0         ['attention_18[0][0]',        \n"," )                                                                   'linguistic_input[0][0]',    \n","                                                                     'readability_input[0][0]']   \n","                                                                                                  \n"," concatenate_7 (Concatenate  (None, 186)                  0         ['attention_19[0][0]',        \n"," )                                                                   'linguistic_input[0][0]',    \n","                                                                     'readability_input[0][0]']   \n","                                                                                                  \n"," concatenate_8 (Concatenate  (None, 186)                  0         ['attention_20[0][0]',        \n"," )                                                                   'linguistic_input[0][0]',    \n","                                                                     'readability_input[0][0]']   \n","                                                                                                  \n"," reshape (Reshape)           (None, 1, 186)               0         ['concatenate[0][0]']         \n","                                                                                                  \n"," reshape_1 (Reshape)         (None, 1, 186)               0         ['concatenate_1[0][0]']       \n","                                                                                                  \n"," reshape_2 (Reshape)         (None, 1, 186)               0         ['concatenate_2[0][0]']       \n","                                                                                                  \n"," reshape_3 (Reshape)         (None, 1, 186)               0         ['concatenate_3[0][0]']       \n","                                                                                                  \n"," reshape_4 (Reshape)         (None, 1, 186)               0         ['concatenate_4[0][0]']       \n","                                                                                                  \n"," reshape_5 (Reshape)         (None, 1, 186)               0         ['concatenate_5[0][0]']       \n","                                                                                                  \n"," reshape_6 (Reshape)         (None, 1, 186)               0         ['concatenate_6[0][0]']       \n","                                                                                                  \n"," reshape_7 (Reshape)         (None, 1, 186)               0         ['concatenate_7[0][0]']       \n","                                                                                                  \n"," reshape_8 (Reshape)         (None, 1, 186)               0         ['concatenate_8[0][0]']       \n","                                                                                                  \n"," tf.concat (TFOpLambda)      (None, 9, 186)               0         ['reshape[0][0]',             \n","                                                                     'reshape_1[0][0]',           \n","                                                                     'reshape_2[0][0]',           \n","                                                                     'reshape_3[0][0]',           \n","                                                                     'reshape_4[0][0]',           \n","                                                                     'reshape_5[0][0]',           \n","                                                                     'reshape_6[0][0]',           \n","                                                                     'reshape_7[0][0]',           \n","                                                                     'reshape_8[0][0]']           \n","                                                                                                  \n"," tf.__operators__.getitem (  (None, 1, 186)               0         ['tf.concat[0][0]']           \n"," SlicingOpLambda)                                                                                 \n","                                                                                                  \n"," tf.compat.v1.boolean_mask   (None, None, 186)            0         ['tf.concat[0][0]']           \n"," (SlicingOpLambda)                                                                                \n","                                                                                                  \n"," tf.__operators__.getitem_1  (None, 1, 186)               0         ['tf.concat[0][0]']           \n","  (SlicingOpLambda)                                                                               \n","                                                                                                  \n"," tf.compat.v1.boolean_mask_  (None, None, 186)            0         ['tf.concat[0][0]']           \n"," 1 (SlicingOpLambda)                                                                              \n","                                                                                                  \n"," tf.__operators__.getitem_2  (None, 1, 186)               0         ['tf.concat[0][0]']           \n","  (SlicingOpLambda)                                                                               \n","                                                                                                  \n"," tf.compat.v1.boolean_mask_  (None, None, 186)            0         ['tf.concat[0][0]']           \n"," 2 (SlicingOpLambda)                                                                              \n","                                                                                                  \n"," tf.__operators__.getitem_3  (None, 1, 186)               0         ['tf.concat[0][0]']           \n","  (SlicingOpLambda)                                                                               \n","                                                                                                  \n"," tf.compat.v1.boolean_mask_  (None, None, 186)            0         ['tf.concat[0][0]']           \n"," 3 (SlicingOpLambda)                                                                              \n","                                                                                                  \n"," tf.__operators__.getitem_4  (None, 1, 186)               0         ['tf.concat[0][0]']           \n","  (SlicingOpLambda)                                                                               \n","                                                                                                  \n"," tf.compat.v1.boolean_mask_  (None, None, 186)            0         ['tf.concat[0][0]']           \n"," 4 (SlicingOpLambda)                                                                              \n","                                                                                                  \n"," tf.__operators__.getitem_5  (None, 1, 186)               0         ['tf.concat[0][0]']           \n","  (SlicingOpLambda)                                                                               \n","                                                                                                  \n"," tf.compat.v1.boolean_mask_  (None, None, 186)            0         ['tf.concat[0][0]']           \n"," 5 (SlicingOpLambda)                                                                              \n","                                                                                                  \n"," tf.__operators__.getitem_6  (None, 1, 186)               0         ['tf.concat[0][0]']           \n","  (SlicingOpLambda)                                                                               \n","                                                                                                  \n"," tf.compat.v1.boolean_mask_  (None, None, 186)            0         ['tf.concat[0][0]']           \n"," 6 (SlicingOpLambda)                                                                              \n","                                                                                                  \n"," tf.__operators__.getitem_7  (None, 1, 186)               0         ['tf.concat[0][0]']           \n","  (SlicingOpLambda)                                                                               \n","                                                                                                  \n"," tf.compat.v1.boolean_mask_  (None, None, 186)            0         ['tf.concat[0][0]']           \n"," 7 (SlicingOpLambda)                                                                              \n","                                                                                                  \n"," tf.__operators__.getitem_8  (None, 1, 186)               0         ['tf.concat[0][0]']           \n","  (SlicingOpLambda)                                                                               \n","                                                                                                  \n"," tf.compat.v1.boolean_mask_  (None, None, 186)            0         ['tf.concat[0][0]']           \n"," 8 (SlicingOpLambda)                                                                              \n","                                                                                                  \n"," attention_21 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem[0][\n","                                                                    0]',                          \n","                                                                     'tf.compat.v1.boolean_mask[0]\n","                                                                    [0]']                         \n","                                                                                                  \n"," attention_22 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_1[0\n","                                                                    ][0]',                        \n","                                                                     'tf.compat.v1.boolean_mask_1[\n","                                                                    0][0]']                       \n","                                                                                                  \n"," attention_23 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_2[0\n","                                                                    ][0]',                        \n","                                                                     'tf.compat.v1.boolean_mask_2[\n","                                                                    0][0]']                       \n","                                                                                                  \n"," attention_24 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_3[0\n","                                                                    ][0]',                        \n","                                                                     'tf.compat.v1.boolean_mask_3[\n","                                                                    0][0]']                       \n","                                                                                                  \n"," attention_25 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_4[0\n","                                                                    ][0]',                        \n","                                                                     'tf.compat.v1.boolean_mask_4[\n","                                                                    0][0]']                       \n","                                                                                                  \n"," attention_26 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_5[0\n","                                                                    ][0]',                        \n","                                                                     'tf.compat.v1.boolean_mask_5[\n","                                                                    0][0]']                       \n","                                                                                                  \n"," attention_27 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_6[0\n","                                                                    ][0]',                        \n","                                                                     'tf.compat.v1.boolean_mask_6[\n","                                                                    0][0]']                       \n","                                                                                                  \n"," attention_28 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_7[0\n","                                                                    ][0]',                        \n","                                                                     'tf.compat.v1.boolean_mask_7[\n","                                                                    0][0]']                       \n","                                                                                                  \n"," attention_29 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_8[0\n","                                                                    ][0]',                        \n","                                                                     'tf.compat.v1.boolean_mask_8[\n","                                                                    0][0]']                       \n","                                                                                                  \n"," tf.concat_1 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem[0][\n","                                                                    0]',                          \n","                                                                     'attention_21[0][0]']        \n","                                                                                                  \n"," tf.concat_2 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem_1[0\n","                                                                    ][0]',                        \n","                                                                     'attention_22[0][0]']        \n","                                                                                                  \n"," tf.concat_3 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem_2[0\n","                                                                    ][0]',                        \n","                                                                     'attention_23[0][0]']        \n","                                                                                                  \n"," tf.concat_4 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem_3[0\n","                                                                    ][0]',                        \n","                                                                     'attention_24[0][0]']        \n","                                                                                                  \n"," tf.concat_5 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem_4[0\n","                                                                    ][0]',                        \n","                                                                     'attention_25[0][0]']        \n","                                                                                                  \n"," tf.concat_6 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem_5[0\n","                                                                    ][0]',                        \n","                                                                     'attention_26[0][0]']        \n","                                                                                                  \n"," tf.concat_7 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem_6[0\n","                                                                    ][0]',                        \n","                                                                     'attention_27[0][0]']        \n","                                                                                                  \n"," tf.concat_8 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem_7[0\n","                                                                    ][0]',                        \n","                                                                     'attention_28[0][0]']        \n","                                                                                                  \n"," tf.concat_9 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem_8[0\n","                                                                    ][0]',                        \n","                                                                     'attention_29[0][0]']        \n","                                                                                                  \n"," flatten (Flatten)           (None, 372)                  0         ['tf.concat_1[0][0]']         \n","                                                                                                  \n"," flatten_1 (Flatten)         (None, 372)                  0         ['tf.concat_2[0][0]']         \n","                                                                                                  \n"," flatten_2 (Flatten)         (None, 372)                  0         ['tf.concat_3[0][0]']         \n","                                                                                                  \n"," flatten_3 (Flatten)         (None, 372)                  0         ['tf.concat_4[0][0]']         \n","                                                                                                  \n"," flatten_4 (Flatten)         (None, 372)                  0         ['tf.concat_5[0][0]']         \n","                                                                                                  \n"," flatten_5 (Flatten)         (None, 372)                  0         ['tf.concat_6[0][0]']         \n","                                                                                                  \n"," flatten_6 (Flatten)         (None, 372)                  0         ['tf.concat_7[0][0]']         \n","                                                                                                  \n"," flatten_7 (Flatten)         (None, 372)                  0         ['tf.concat_8[0][0]']         \n","                                                                                                  \n"," flatten_8 (Flatten)         (None, 372)                  0         ['tf.concat_9[0][0]']         \n","                                                                                                  \n"," dense_76 (Dense)            (None, 1)                    373       ['flatten[0][0]']             \n","                                                                                                  \n"," dense_77 (Dense)            (None, 1)                    373       ['flatten_1[0][0]']           \n","                                                                                                  \n"," dense_78 (Dense)            (None, 1)                    373       ['flatten_2[0][0]']           \n","                                                                                                  \n"," dense_79 (Dense)            (None, 1)                    373       ['flatten_3[0][0]']           \n","                                                                                                  \n"," dense_80 (Dense)            (None, 1)                    373       ['flatten_4[0][0]']           \n","                                                                                                  \n"," dense_81 (Dense)            (None, 1)                    373       ['flatten_5[0][0]']           \n","                                                                                                  \n"," dense_82 (Dense)            (None, 1)                    373       ['flatten_6[0][0]']           \n","                                                                                                  \n"," dense_83 (Dense)            (None, 1)                    373       ['flatten_7[0][0]']           \n","                                                                                                  \n"," dense_84 (Dense)            (None, 1)                    373       ['flatten_8[0][0]']           \n","                                                                                                  \n"," concatenate_9 (Concatenate  (None, 9)                    0         ['dense_76[0][0]',            \n"," )                                                                   'dense_77[0][0]',            \n","                                                                     'dense_78[0][0]',            \n","                                                                     'dense_79[0][0]',            \n","                                                                     'dense_80[0][0]',            \n","                                                                     'dense_81[0][0]',            \n","                                                                     'dense_82[0][0]',            \n","                                                                     'dense_83[0][0]',            \n","                                                                     'dense_84[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 2566457 (9.79 MB)\n","Trainable params: 2566457 (9.79 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n","53/53 [==============================] - 16s 74ms/step\n","56/56 [==============================] - 3s 61ms/step\n","CURRENT EPOCH: -1\n","[DEV] AVG QWK: -0.007\n","[DEV] score QWK: 0.102\n","[DEV] content QWK: 0.059\n","[DEV] organization QWK: -0.003\n","[DEV] word_choice QWK: -0.078\n","[DEV] sentence_fluency QWK: -0.145\n","[DEV] conventions QWK: -0.005\n","[DEV] prompt_adherence QWK: 0.089\n","[DEV] language QWK: -0.038\n","[DEV] narrativity QWK: -0.046\n","------------------------\n","[TEST] AVG QWK: -0.002\n","[TEST] score QWK: 0.146\n","[TEST] content QWK: 0.06\n","[TEST] organization QWK: 0.007\n","[TEST] word_choice QWK: -0.203\n","[TEST] sentence_fluency QWK: -0.001\n","[TEST] conventions QWK: -0.022\n","------------------------\n","[BEST TEST] AVG QWK: -0.002, {epoch}: -1\n","[BEST TEST] score QWK: 0.146\n","[BEST TEST] content QWK: 0.06\n","[BEST TEST] organization QWK: 0.007\n","[BEST TEST] word_choice QWK: -0.203\n","[BEST TEST] sentence_fluency QWK: -0.001\n","[BEST TEST] conventions QWK: -0.022\n","--------------------------------------------------------------------------------------------------------------------------\n"]}],"source":["train_features_list = [X_train_pos, X_train_prompt, X_train_prompt_pos, X_train_linguistic_features, X_train_readability]\n","dev_features_list = [X_dev_pos, X_dev_prompt, X_dev_prompt_pos, X_dev_linguistic_features, X_dev_readability]\n","test_features_list = [X_test_pos, X_test_prompt, X_test_prompt_pos, X_test_linguistic_features, X_test_readability]\n","\n","model = build_ProTACT(len(pos_vocab), len(word_vocab), max_sentnum, max_sentlen,\n","                  X_train_readability.shape[1],\n","                  X_train_linguistic_features.shape[1],\n","                  configs, Y_train.shape[1], num_heads, embed_table)\n","\n","evaluator = AllAttEvaluator(test_prompt_id, dev_data['prompt_ids'], test_data['prompt_ids'], dev_features_list,\n","                            test_features_list, Y_dev, Y_test, seed)\n","\n","\n","evalutate_results = evaluator.evaluate(model, -1, print_info=True)"]},{"cell_type":"code","execution_count":10,"id":"6f335191","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6f335191","executionInfo":{"status":"ok","timestamp":1717306692532,"user_tz":-540,"elapsed":621,"user":{"displayName":"나인호","userId":"08373838400323353884"}},"outputId":"49225e15-3073-4d21-c0fd-dae4756dd15d"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'dev_kappa_mean': -0.007270405997827233, 'test_kappa_mean': -0.0020892790921283786, 'kappa_dev': {'score': 0.10197013343022854, 'content': 0.05945702421964416, 'organization': -0.003446119541014925, 'word_choice': -0.07809216664909968, 'sentence_fluency': -0.14467374618839557, 'conventions': -0.005219188500368732, 'prompt_adherence': 0.08902207982151655, 'language': -0.03810186811309957, 'narrativity': -0.04634980245985587}, 'kappa_test': {'score': 0.14648868837471785, 'content': 0.06041810426144245, 'organization': 0.007398595455185397, 'word_choice': -0.2034227045185928, 'sentence_fluency': -0.0013011817653225677, 'conventions': -0.022117176360200608}}\n"]}],"source":["print(evalutate_results)"]},{"cell_type":"code","execution_count":null,"id":"0b247461","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"0b247461","executionInfo":{"status":"ok","timestamp":1717142959660,"user_tz":-540,"elapsed":327,"user":{"displayName":"나인호","userId":"08373838400323353884"}},"outputId":"438ee03f-cba1-49fd-8ab7-f0f56615a541"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"# show the loss as the graph\\nfig, loss_graph = plt.subplots()\\nloss_graph.plot(custom_hist.train_loss,'y',label='train loss')\\nloss_graph.plot(custom_hist.val_loss,'r',label='val loss')\\nloss_graph.set_xlabel('epoch')\\nloss_graph.set_ylabel('loss')\\nplt.savefig(str('images/protact/test_prompt_'+ str(test_prompt_id) + '_seed_' + str(seed) + '_loss.png'))\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}],"source":["# class CustomHistory(keras.callbacks.Callback):\n","#     def init(self):\n","#         self.train_loss = []\n","#         self.val_loss = []\n","#         self.train_acc = []\n","#         self.val_acc = []\n","\n","#     def on_epoch_end(self, batch, logs={}):\n","#         self.train_loss.append(logs.get('loss'))\n","#         self.val_loss.append(logs.get('val_loss'))\n","#         self.train_acc.append(logs.get('acc'))\n","#         self.val_acc.append(logs.get('val_acc'))\n","# custom_hist = CustomHistory()\n","# custom_hist.init()\n","\n","#  for ii in range(epochs):\n","#     print('Epoch %s/%s' % (str(ii + 1), epochs))\n","#     start_time = time.time()\n","#     model.fit(\n","#         train_features_list,\n","#         Y_train, batch_size=batch_size, epochs=5, verbose=0, shuffle=True, validation_data=(dev_features_list,Y_dev),callbacks=[custom_hist,checkpoint])\n","#     tt_time = time.time() - start_time\n","#     print(\"Training one epoch in %.3f s\" % tt_time)\n","#     evaluator.evaluate(model, ii + 1)\n","#     print(\"Train Loss: \", custom_hist.train_loss[-1], \"|| Val Loss: \", custom_hist.val_loss[-1])\n","\n","# evaluator.print_final_info()\n","\n","'''# show the loss as the graph\n","fig, loss_graph = plt.subplots()\n","loss_graph.plot(custom_hist.train_loss,'y',label='train loss')\n","loss_graph.plot(custom_hist.val_loss,'r',label='val loss')\n","loss_graph.set_xlabel('epoch')\n","loss_graph.set_ylabel('loss')\n","plt.savefig(str('images/protact/test_prompt_'+ str(test_prompt_id) + '_seed_' + str(seed) + '_loss.png'))'''"]},{"cell_type":"code","execution_count":11,"id":"90c5dd61","metadata":{"id":"90c5dd61","executionInfo":{"status":"ok","timestamp":1717306698400,"user_tz":-540,"elapsed":647,"user":{"displayName":"나인호","userId":"08373838400323353884"}}},"outputs":[],"source":["# 저장한 체크포인트 있다면: 이어서 학습 시작할때\n","# Checkpoint 폴더 안에 있는 .h5 파일 지울것\n","# model.load_weights('Checkpoint/tensor{epoch}')\n","\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","    # epoch 마다 파일명 다르게 저장\n","    filepath='Checkpoint/bestmodel_epoch_{epoch}.h5',\n","\n","    # epoch 마다 weights 들만 저장\n","    save_freq='epoch',\n","    save_weights_only = True,\n","\n","    # validation accruary 가 최대일때만 저장\n","    monitor='val_loss',\n","    mode='min'\n",")"]},{"cell_type":"code","execution_count":12,"id":"9e2cb3de","metadata":{"id":"9e2cb3de","executionInfo":{"status":"ok","timestamp":1717306701868,"user_tz":-540,"elapsed":600,"user":{"displayName":"나인호","userId":"08373838400323353884"}}},"outputs":[],"source":["class CustomHistory(tf.keras.callbacks.Callback):\n","    def __init__(self, test_prompt_id, seed, save_graphs_freq=10, save_dir='training_data'):\n","        super(CustomHistory, self).__init__()\n","        self.test_prompt_id = test_prompt_id\n","        self.seed = seed\n","        self.save_graphs_freq = save_graphs_freq\n","        self.save_dir = save_dir\n","        self.train_loss = []\n","        self.val_loss = []\n","        self.train_acc = []\n","        self.val_acc = []\n","        self.epoch_times = []\n","        self.qwk_dev = []\n","        self.qwk_test = []\n","        self.kappa_dev_history = []\n","        self.kappa_test_history = []\n","\n","        # Create directory if it does not exist\n","        os.makedirs(self.save_dir, exist_ok=True)\n","\n","    def on_train_begin(self, logs=None):\n","        pass\n","\n","    def on_epoch_begin(self, epoch, logs=None):\n","        self.start_time = time.time()\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        self.train_loss.append(logs.get('loss'))\n","        self.val_loss.append(logs.get('val_loss'))\n","        self.train_acc.append(logs.get('acc'))\n","        self.val_acc.append(logs.get('val_acc'))\n","        epoch_time = time.time() - self.start_time\n","        self.epoch_times.append(epoch_time)\n","        print(f\"Epoch {epoch + 1}: Train Loss: {logs.get('loss')} || Val Loss: {logs.get('val_loss')}\")\n","        print(f\"Epoch {epoch + 1} completed in {epoch_time:.3f} seconds\")\n","\n","        # Evaluate the model and get QWK values\n","        evaluation_results = evaluator.evaluate(self.model, epoch + 1)\n","        self.qwk_dev.append(evaluation_results[\"dev_kappa_mean\"])\n","        self.qwk_test.append(evaluation_results[\"test_kappa_mean\"])\n","        self.kappa_dev_history.append(evaluation_results[\"kappa_dev\"])\n","        self.kappa_test_history.append(evaluation_results[\"kappa_test\"])\n","\n","        # Save data to .pkl file\n","        self.save_to_pickle(epoch + 1)\n","\n","        # Save loss graph\n","        if (epoch + 1) % self.save_graphs_freq == 0 or (epoch + 1) == 100:\n","            self.save_loss_graph(epoch + 1)\n","\n","    def save_to_pickle(self, epoch):\n","        data = {\n","            'train_loss': self.train_loss,\n","            'val_loss': self.val_loss,\n","            'train_acc': self.train_acc,\n","            'val_acc': self.val_acc,\n","            'epoch_times': self.epoch_times,\n","            'qwk_dev': self.qwk_dev,\n","            'qwk_test': self.qwk_test,\n","            'kappa_dev_history': self.kappa_dev_history,\n","            'kappa_test_history': self.kappa_test_history\n","        }\n","        filepath = os.path.join(self.save_dir, f'training_data_epoch_{epoch}.pkl')\n","        with open(filepath, 'wb') as f:\n","            pickle.dump(data, f)\n","\n","    def save_loss_graph(self, epoch):\n","        # Plot and save the loss graph\n","        fig, loss_graph = plt.subplots()\n","        loss_graph.plot(self.train_loss, 'y', label='train loss')\n","        loss_graph.plot(self.val_loss, 'r', label='val loss')\n","        loss_graph.set_xlabel('epoch')\n","        loss_graph.set_ylabel('loss')\n","        loss_graph.set_title('Train and Validation Loss')\n","        loss_graph.legend()\n","        filepath = os.path.join(self.save_dir, f'test_prompt_{self.test_prompt_id}_seed_{self.seed}_loss_epoch_{epoch}.png')\n","        plt.savefig(filepath)\n","        plt.close()\n"]},{"cell_type":"code","execution_count":13,"id":"0f48ca2c","metadata":{"id":"0f48ca2c","executionInfo":{"status":"ok","timestamp":1717306706150,"user_tz":-540,"elapsed":538,"user":{"displayName":"나인호","userId":"08373838400323353884"}}},"outputs":[],"source":["custom_hist = CustomHistory(test_prompt_id=test_prompt_id, seed=seed, save_dir='training_data')"]},{"cell_type":"code","execution_count":14,"id":"7ced06bd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ced06bd","executionInfo":{"status":"ok","timestamp":1717306752125,"user_tz":-540,"elapsed":509,"user":{"displayName":"나인호","userId":"08373838400323353884"}},"outputId":"fce3db06-7afd-446d-9e24-13eb4c94ef53"},"outputs":[{"output_type":"stream","name":"stdout","text":["Latest checkpoint: Checkpoint/bestmodel_epoch_50.h5\n"]}],"source":["# checkpoint 파일들 확인\n","\n","import os\n","import glob\n","\n","# Checkpoint directory\n","checkpoint_dir = 'Checkpoint'\n","checkpoint_files = glob.glob(os.path.join(checkpoint_dir, 'bestmodel_epoch_*.h5'))\n","\n","# Sort the checkpoint files by epoch number\n","checkpoint_files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n","\n","# Get the latest checkpoint file\n","latest_checkpoint = checkpoint_files[-1] if checkpoint_files else None\n","print(f'Latest checkpoint: {latest_checkpoint}')"]},{"cell_type":"code","source":["# Check if there is a latest checkpoint\n","initial_epoch = 0\n","load = False # True -> 학습 재개\n","if latest_checkpoint and load:\n","    print(f'Loading weights from {latest_checkpoint}')\n","    model.load_weights(latest_checkpoint)\n","    initial_epoch = int(latest_checkpoint.split('_')[-1].split('.')[0]) if latest_checkpoint else 0\n","else:\n","    print('No latest checkpoint found. Starting from scratch.')\n","\n","# 모델 학습 코드\n","model.fit(\n","    train_features_list,\n","    Y_train,\n","    batch_size=batch_size,\n","    epochs=50, # 적절한 에포크 수로 설정\n","    verbose=1,\n","    shuffle=True,\n","    validation_data=(dev_features_list, Y_dev),\n","    callbacks=[custom_hist, checkpoint],\n","    initial_epoch=initial_epoch  # 학습을 재개할 에포크\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"96jA9LjjbaXm","executionInfo":{"status":"ok","timestamp":1717314908460,"user_tz":-540,"elapsed":8145782,"user":{"displayName":"나인호","userId":"08373838400323353884"}},"outputId":"2019d527-d228-4f24-86a5-953e45388979"},"id":"96jA9LjjbaXm","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["No latest checkpoint found. Starting from scratch.\n","Epoch 1/50\n","trait num:  9\n","trait num:  9\n","952/952 [==============================] - ETA: 0s - loss: 0.0177trait num:  9\n","Epoch 1: Train Loss: 0.017732743173837662 || Val Loss: 0.015233942307531834\n","Epoch 1 completed in 255.603 seconds\n","53/53 [==============================] - 3s 58ms/step\n","56/56 [==============================] - 3s 56ms/step\n","CURRENT EPOCH: 1\n","[DEV] AVG QWK: 0.579\n","[DEV] score QWK: 0.708\n","[DEV] content QWK: 0.554\n","[DEV] organization QWK: 0.599\n","[DEV] word_choice QWK: 0.56\n","[DEV] sentence_fluency QWK: 0.522\n","[DEV] conventions QWK: 0.563\n","[DEV] prompt_adherence QWK: 0.559\n","[DEV] language QWK: 0.568\n","[DEV] narrativity QWK: 0.579\n","------------------------\n","[TEST] AVG QWK: 0.586\n","[TEST] score QWK: 0.813\n","[TEST] content QWK: 0.623\n","[TEST] organization QWK: 0.528\n","[TEST] word_choice QWK: 0.534\n","[TEST] sentence_fluency QWK: 0.527\n","[TEST] conventions QWK: 0.493\n","------------------------\n","[BEST TEST] AVG QWK: 0.586, {epoch}: 1\n","[BEST TEST] score QWK: 0.813\n","[BEST TEST] content QWK: 0.623\n","[BEST TEST] organization QWK: 0.528\n","[BEST TEST] word_choice QWK: 0.534\n","[BEST TEST] sentence_fluency QWK: 0.527\n","[BEST TEST] conventions QWK: 0.493\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 265s 193ms/step - loss: 0.0177 - val_loss: 0.0152\n","Epoch 2/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0148Epoch 2: Train Loss: 0.014776665717363358 || Val Loss: 0.01413858775049448\n","Epoch 2 completed in 152.625 seconds\n","53/53 [==============================] - 3s 62ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 2\n","[DEV] AVG QWK: 0.626\n","[DEV] score QWK: 0.729\n","[DEV] content QWK: 0.602\n","[DEV] organization QWK: 0.661\n","[DEV] word_choice QWK: 0.605\n","[DEV] sentence_fluency QWK: 0.578\n","[DEV] conventions QWK: 0.636\n","[DEV] prompt_adherence QWK: 0.599\n","[DEV] language QWK: 0.605\n","[DEV] narrativity QWK: 0.623\n","------------------------\n","[TEST] AVG QWK: 0.632\n","[TEST] score QWK: 0.789\n","[TEST] content QWK: 0.65\n","[TEST] organization QWK: 0.599\n","[TEST] word_choice QWK: 0.608\n","[TEST] sentence_fluency QWK: 0.581\n","[TEST] conventions QWK: 0.566\n","------------------------\n","[BEST TEST] AVG QWK: 0.632, {epoch}: 2\n","[BEST TEST] score QWK: 0.789\n","[BEST TEST] content QWK: 0.65\n","[BEST TEST] organization QWK: 0.599\n","[BEST TEST] word_choice QWK: 0.608\n","[BEST TEST] sentence_fluency QWK: 0.581\n","[BEST TEST] conventions QWK: 0.566\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 165s 173ms/step - loss: 0.0148 - val_loss: 0.0141\n","Epoch 3/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0142Epoch 3: Train Loss: 0.014216858893632889 || Val Loss: 0.013754816725850105\n","Epoch 3 completed in 155.123 seconds\n","53/53 [==============================] - 3s 64ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 3\n","[DEV] AVG QWK: 0.639\n","[DEV] score QWK: 0.731\n","[DEV] content QWK: 0.618\n","[DEV] organization QWK: 0.685\n","[DEV] word_choice QWK: 0.619\n","[DEV] sentence_fluency QWK: 0.571\n","[DEV] conventions QWK: 0.669\n","[DEV] prompt_adherence QWK: 0.609\n","[DEV] language QWK: 0.615\n","[DEV] narrativity QWK: 0.631\n","------------------------\n","[TEST] AVG QWK: 0.615\n","[TEST] score QWK: 0.749\n","[TEST] content QWK: 0.651\n","[TEST] organization QWK: 0.592\n","[TEST] word_choice QWK: 0.6\n","[TEST] sentence_fluency QWK: 0.523\n","[TEST] conventions QWK: 0.574\n","------------------------\n","[BEST TEST] AVG QWK: 0.615, {epoch}: 3\n","[BEST TEST] score QWK: 0.749\n","[BEST TEST] content QWK: 0.651\n","[BEST TEST] organization QWK: 0.592\n","[BEST TEST] word_choice QWK: 0.6\n","[BEST TEST] sentence_fluency QWK: 0.523\n","[BEST TEST] conventions QWK: 0.574\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 170s 178ms/step - loss: 0.0142 - val_loss: 0.0138\n","Epoch 4/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0139Epoch 4: Train Loss: 0.01391325332224369 || Val Loss: 0.013419419527053833\n","Epoch 4 completed in 153.451 seconds\n","53/53 [==============================] - 3s 59ms/step\n","56/56 [==============================] - 3s 58ms/step\n","CURRENT EPOCH: 4\n","[DEV] AVG QWK: 0.654\n","[DEV] score QWK: 0.738\n","[DEV] content QWK: 0.629\n","[DEV] organization QWK: 0.702\n","[DEV] word_choice QWK: 0.636\n","[DEV] sentence_fluency QWK: 0.61\n","[DEV] conventions QWK: 0.689\n","[DEV] prompt_adherence QWK: 0.62\n","[DEV] language QWK: 0.62\n","[DEV] narrativity QWK: 0.639\n","------------------------\n","[TEST] AVG QWK: 0.639\n","[TEST] score QWK: 0.773\n","[TEST] content QWK: 0.65\n","[TEST] organization QWK: 0.608\n","[TEST] word_choice QWK: 0.626\n","[TEST] sentence_fluency QWK: 0.591\n","[TEST] conventions QWK: 0.583\n","------------------------\n","[BEST TEST] AVG QWK: 0.639, {epoch}: 4\n","[BEST TEST] score QWK: 0.773\n","[BEST TEST] content QWK: 0.65\n","[BEST TEST] organization QWK: 0.608\n","[BEST TEST] word_choice QWK: 0.626\n","[BEST TEST] sentence_fluency QWK: 0.591\n","[BEST TEST] conventions QWK: 0.583\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 166s 174ms/step - loss: 0.0139 - val_loss: 0.0134\n","Epoch 5/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0137Epoch 5: Train Loss: 0.013725382275879383 || Val Loss: 0.01350538432598114\n","Epoch 5 completed in 153.549 seconds\n","53/53 [==============================] - 3s 57ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 5\n","[DEV] AVG QWK: 0.653\n","[DEV] score QWK: 0.739\n","[DEV] content QWK: 0.618\n","[DEV] organization QWK: 0.702\n","[DEV] word_choice QWK: 0.647\n","[DEV] sentence_fluency QWK: 0.617\n","[DEV] conventions QWK: 0.704\n","[DEV] prompt_adherence QWK: 0.61\n","[DEV] language QWK: 0.61\n","[DEV] narrativity QWK: 0.628\n","------------------------\n","[TEST] AVG QWK: 0.636\n","[TEST] score QWK: 0.784\n","[TEST] content QWK: 0.61\n","[TEST] organization QWK: 0.611\n","[TEST] word_choice QWK: 0.63\n","[TEST] sentence_fluency QWK: 0.597\n","[TEST] conventions QWK: 0.585\n","------------------------\n","[BEST TEST] AVG QWK: 0.639, {epoch}: 4\n","[BEST TEST] score QWK: 0.773\n","[BEST TEST] content QWK: 0.65\n","[BEST TEST] organization QWK: 0.608\n","[BEST TEST] word_choice QWK: 0.626\n","[BEST TEST] sentence_fluency QWK: 0.591\n","[BEST TEST] conventions QWK: 0.583\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 165s 173ms/step - loss: 0.0137 - val_loss: 0.0135\n","Epoch 6/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0136Epoch 6: Train Loss: 0.013579324819147587 || Val Loss: 0.013167839497327805\n","Epoch 6 completed in 142.275 seconds\n","53/53 [==============================] - 3s 57ms/step\n","56/56 [==============================] - 3s 58ms/step\n","CURRENT EPOCH: 6\n","[DEV] AVG QWK: 0.663\n","[DEV] score QWK: 0.742\n","[DEV] content QWK: 0.635\n","[DEV] organization QWK: 0.714\n","[DEV] word_choice QWK: 0.647\n","[DEV] sentence_fluency QWK: 0.621\n","[DEV] conventions QWK: 0.709\n","[DEV] prompt_adherence QWK: 0.626\n","[DEV] language QWK: 0.627\n","[DEV] narrativity QWK: 0.644\n","------------------------\n","[TEST] AVG QWK: 0.636\n","[TEST] score QWK: 0.767\n","[TEST] content QWK: 0.65\n","[TEST] organization QWK: 0.608\n","[TEST] word_choice QWK: 0.622\n","[TEST] sentence_fluency QWK: 0.572\n","[TEST] conventions QWK: 0.6\n","------------------------\n","[BEST TEST] AVG QWK: 0.636, {epoch}: 6\n","[BEST TEST] score QWK: 0.767\n","[BEST TEST] content QWK: 0.65\n","[BEST TEST] organization QWK: 0.608\n","[BEST TEST] word_choice QWK: 0.622\n","[BEST TEST] sentence_fluency QWK: 0.572\n","[BEST TEST] conventions QWK: 0.6\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 156s 164ms/step - loss: 0.0136 - val_loss: 0.0132\n","Epoch 7/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0135Epoch 7: Train Loss: 0.013455086387693882 || Val Loss: 0.013263247907161713\n","Epoch 7 completed in 151.388 seconds\n","53/53 [==============================] - 3s 57ms/step\n","56/56 [==============================] - 3s 56ms/step\n","CURRENT EPOCH: 7\n","[DEV] AVG QWK: 0.661\n","[DEV] score QWK: 0.737\n","[DEV] content QWK: 0.64\n","[DEV] organization QWK: 0.699\n","[DEV] word_choice QWK: 0.639\n","[DEV] sentence_fluency QWK: 0.61\n","[DEV] conventions QWK: 0.715\n","[DEV] prompt_adherence QWK: 0.63\n","[DEV] language QWK: 0.635\n","[DEV] narrativity QWK: 0.643\n","------------------------\n","[TEST] AVG QWK: 0.609\n","[TEST] score QWK: 0.722\n","[TEST] content QWK: 0.638\n","[TEST] organization QWK: 0.574\n","[TEST] word_choice QWK: 0.599\n","[TEST] sentence_fluency QWK: 0.55\n","[TEST] conventions QWK: 0.574\n","------------------------\n","[BEST TEST] AVG QWK: 0.636, {epoch}: 6\n","[BEST TEST] score QWK: 0.767\n","[BEST TEST] content QWK: 0.65\n","[BEST TEST] organization QWK: 0.608\n","[BEST TEST] word_choice QWK: 0.622\n","[BEST TEST] sentence_fluency QWK: 0.572\n","[BEST TEST] conventions QWK: 0.6\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 165s 173ms/step - loss: 0.0135 - val_loss: 0.0133\n","Epoch 8/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0134Epoch 8: Train Loss: 0.013362959958612919 || Val Loss: 0.013125601224601269\n","Epoch 8 completed in 151.868 seconds\n","53/53 [==============================] - 3s 58ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 8\n","[DEV] AVG QWK: 0.666\n","[DEV] score QWK: 0.737\n","[DEV] content QWK: 0.644\n","[DEV] organization QWK: 0.711\n","[DEV] word_choice QWK: 0.658\n","[DEV] sentence_fluency QWK: 0.631\n","[DEV] conventions QWK: 0.718\n","[DEV] prompt_adherence QWK: 0.625\n","[DEV] language QWK: 0.622\n","[DEV] narrativity QWK: 0.645\n","------------------------\n","[TEST] AVG QWK: 0.639\n","[TEST] score QWK: 0.727\n","[TEST] content QWK: 0.655\n","[TEST] organization QWK: 0.613\n","[TEST] word_choice QWK: 0.635\n","[TEST] sentence_fluency QWK: 0.617\n","[TEST] conventions QWK: 0.589\n","------------------------\n","[BEST TEST] AVG QWK: 0.639, {epoch}: 8\n","[BEST TEST] score QWK: 0.727\n","[BEST TEST] content QWK: 0.655\n","[BEST TEST] organization QWK: 0.613\n","[BEST TEST] word_choice QWK: 0.635\n","[BEST TEST] sentence_fluency QWK: 0.617\n","[BEST TEST] conventions QWK: 0.589\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 161s 169ms/step - loss: 0.0134 - val_loss: 0.0131\n","Epoch 9/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0133Epoch 9: Train Loss: 0.013292812742292881 || Val Loss: 0.012983106076717377\n","Epoch 9 completed in 143.692 seconds\n","53/53 [==============================] - 3s 64ms/step\n","56/56 [==============================] - 3s 56ms/step\n","CURRENT EPOCH: 9\n","[DEV] AVG QWK: 0.672\n","[DEV] score QWK: 0.742\n","[DEV] content QWK: 0.643\n","[DEV] organization QWK: 0.722\n","[DEV] word_choice QWK: 0.658\n","[DEV] sentence_fluency QWK: 0.634\n","[DEV] conventions QWK: 0.725\n","[DEV] prompt_adherence QWK: 0.634\n","[DEV] language QWK: 0.636\n","[DEV] narrativity QWK: 0.651\n","------------------------\n","[TEST] AVG QWK: 0.645\n","[TEST] score QWK: 0.76\n","[TEST] content QWK: 0.659\n","[TEST] organization QWK: 0.611\n","[TEST] word_choice QWK: 0.636\n","[TEST] sentence_fluency QWK: 0.602\n","[TEST] conventions QWK: 0.602\n","------------------------\n","[BEST TEST] AVG QWK: 0.645, {epoch}: 9\n","[BEST TEST] score QWK: 0.76\n","[BEST TEST] content QWK: 0.659\n","[BEST TEST] organization QWK: 0.611\n","[BEST TEST] word_choice QWK: 0.636\n","[BEST TEST] sentence_fluency QWK: 0.602\n","[BEST TEST] conventions QWK: 0.602\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 155s 163ms/step - loss: 0.0133 - val_loss: 0.0130\n","Epoch 10/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0132Epoch 10: Train Loss: 0.013219798915088177 || Val Loss: 0.013078849762678146\n","Epoch 10 completed in 140.639 seconds\n","53/53 [==============================] - 4s 66ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 10\n","[DEV] AVG QWK: 0.67\n","[DEV] score QWK: 0.749\n","[DEV] content QWK: 0.642\n","[DEV] organization QWK: 0.728\n","[DEV] word_choice QWK: 0.664\n","[DEV] sentence_fluency QWK: 0.637\n","[DEV] conventions QWK: 0.721\n","[DEV] prompt_adherence QWK: 0.622\n","[DEV] language QWK: 0.629\n","[DEV] narrativity QWK: 0.636\n","------------------------\n","[TEST] AVG QWK: 0.649\n","[TEST] score QWK: 0.796\n","[TEST] content QWK: 0.634\n","[TEST] organization QWK: 0.617\n","[TEST] word_choice QWK: 0.646\n","[TEST] sentence_fluency QWK: 0.599\n","[TEST] conventions QWK: 0.602\n","------------------------\n","[BEST TEST] AVG QWK: 0.645, {epoch}: 9\n","[BEST TEST] score QWK: 0.76\n","[BEST TEST] content QWK: 0.659\n","[BEST TEST] organization QWK: 0.611\n","[BEST TEST] word_choice QWK: 0.636\n","[BEST TEST] sentence_fluency QWK: 0.602\n","[BEST TEST] conventions QWK: 0.602\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 154s 162ms/step - loss: 0.0132 - val_loss: 0.0131\n","Epoch 11/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0132Epoch 11: Train Loss: 0.013166598975658417 || Val Loss: 0.013004802167415619\n","Epoch 11 completed in 140.880 seconds\n","53/53 [==============================] - 4s 67ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 11\n","[DEV] AVG QWK: 0.674\n","[DEV] score QWK: 0.749\n","[DEV] content QWK: 0.649\n","[DEV] organization QWK: 0.726\n","[DEV] word_choice QWK: 0.65\n","[DEV] sentence_fluency QWK: 0.627\n","[DEV] conventions QWK: 0.735\n","[DEV] prompt_adherence QWK: 0.632\n","[DEV] language QWK: 0.64\n","[DEV] narrativity QWK: 0.658\n","------------------------\n","[TEST] AVG QWK: 0.636\n","[TEST] score QWK: 0.786\n","[TEST] content QWK: 0.655\n","[TEST] organization QWK: 0.617\n","[TEST] word_choice QWK: 0.606\n","[TEST] sentence_fluency QWK: 0.563\n","[TEST] conventions QWK: 0.589\n","------------------------\n","[BEST TEST] AVG QWK: 0.636, {epoch}: 11\n","[BEST TEST] score QWK: 0.786\n","[BEST TEST] content QWK: 0.655\n","[BEST TEST] organization QWK: 0.617\n","[BEST TEST] word_choice QWK: 0.606\n","[BEST TEST] sentence_fluency QWK: 0.563\n","[BEST TEST] conventions QWK: 0.589\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 150s 158ms/step - loss: 0.0132 - val_loss: 0.0130\n","Epoch 12/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0131Epoch 12: Train Loss: 0.013103049248456955 || Val Loss: 0.012856523506343365\n","Epoch 12 completed in 141.555 seconds\n","53/53 [==============================] - 4s 67ms/step\n","56/56 [==============================] - 4s 66ms/step\n","CURRENT EPOCH: 12\n","[DEV] AVG QWK: 0.677\n","[DEV] score QWK: 0.747\n","[DEV] content QWK: 0.652\n","[DEV] organization QWK: 0.729\n","[DEV] word_choice QWK: 0.665\n","[DEV] sentence_fluency QWK: 0.638\n","[DEV] conventions QWK: 0.732\n","[DEV] prompt_adherence QWK: 0.631\n","[DEV] language QWK: 0.639\n","[DEV] narrativity QWK: 0.657\n","------------------------\n","[TEST] AVG QWK: 0.634\n","[TEST] score QWK: 0.733\n","[TEST] content QWK: 0.647\n","[TEST] organization QWK: 0.604\n","[TEST] word_choice QWK: 0.633\n","[TEST] sentence_fluency QWK: 0.582\n","[TEST] conventions QWK: 0.606\n","------------------------\n","[BEST TEST] AVG QWK: 0.634, {epoch}: 12\n","[BEST TEST] score QWK: 0.733\n","[BEST TEST] content QWK: 0.647\n","[BEST TEST] organization QWK: 0.604\n","[BEST TEST] word_choice QWK: 0.633\n","[BEST TEST] sentence_fluency QWK: 0.582\n","[BEST TEST] conventions QWK: 0.606\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 153s 161ms/step - loss: 0.0131 - val_loss: 0.0129\n","Epoch 13/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0131Epoch 13: Train Loss: 0.013078531250357628 || Val Loss: 0.012861554510891438\n","Epoch 13 completed in 152.810 seconds\n","53/53 [==============================] - 3s 59ms/step\n","56/56 [==============================] - 4s 71ms/step\n","CURRENT EPOCH: 13\n","[DEV] AVG QWK: 0.674\n","[DEV] score QWK: 0.749\n","[DEV] content QWK: 0.646\n","[DEV] organization QWK: 0.729\n","[DEV] word_choice QWK: 0.664\n","[DEV] sentence_fluency QWK: 0.643\n","[DEV] conventions QWK: 0.739\n","[DEV] prompt_adherence QWK: 0.63\n","[DEV] language QWK: 0.625\n","[DEV] narrativity QWK: 0.645\n","------------------------\n","[TEST] AVG QWK: 0.641\n","[TEST] score QWK: 0.789\n","[TEST] content QWK: 0.636\n","[TEST] organization QWK: 0.599\n","[TEST] word_choice QWK: 0.633\n","[TEST] sentence_fluency QWK: 0.608\n","[TEST] conventions QWK: 0.583\n","------------------------\n","[BEST TEST] AVG QWK: 0.634, {epoch}: 12\n","[BEST TEST] score QWK: 0.733\n","[BEST TEST] content QWK: 0.647\n","[BEST TEST] organization QWK: 0.604\n","[BEST TEST] word_choice QWK: 0.633\n","[BEST TEST] sentence_fluency QWK: 0.582\n","[BEST TEST] conventions QWK: 0.606\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 163s 171ms/step - loss: 0.0131 - val_loss: 0.0129\n","Epoch 14/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0130Epoch 14: Train Loss: 0.013022826984524727 || Val Loss: 0.012724506668746471\n","Epoch 14 completed in 143.820 seconds\n","53/53 [==============================] - 3s 58ms/step\n","56/56 [==============================] - 5s 80ms/step\n","CURRENT EPOCH: 14\n","[DEV] AVG QWK: 0.68\n","[DEV] score QWK: 0.751\n","[DEV] content QWK: 0.655\n","[DEV] organization QWK: 0.728\n","[DEV] word_choice QWK: 0.663\n","[DEV] sentence_fluency QWK: 0.645\n","[DEV] conventions QWK: 0.738\n","[DEV] prompt_adherence QWK: 0.639\n","[DEV] language QWK: 0.643\n","[DEV] narrativity QWK: 0.659\n","------------------------\n","[TEST] AVG QWK: 0.65\n","[TEST] score QWK: 0.79\n","[TEST] content QWK: 0.654\n","[TEST] organization QWK: 0.615\n","[TEST] word_choice QWK: 0.647\n","[TEST] sentence_fluency QWK: 0.608\n","[TEST] conventions QWK: 0.584\n","------------------------\n","[BEST TEST] AVG QWK: 0.65, {epoch}: 14\n","[BEST TEST] score QWK: 0.79\n","[BEST TEST] content QWK: 0.654\n","[BEST TEST] organization QWK: 0.615\n","[BEST TEST] word_choice QWK: 0.647\n","[BEST TEST] sentence_fluency QWK: 0.608\n","[BEST TEST] conventions QWK: 0.584\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 158s 166ms/step - loss: 0.0130 - val_loss: 0.0127\n","Epoch 15/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0130Epoch 15: Train Loss: 0.012989860028028488 || Val Loss: 0.012724839150905609\n","Epoch 15 completed in 144.190 seconds\n","53/53 [==============================] - 3s 59ms/step\n","56/56 [==============================] - 3s 60ms/step\n","CURRENT EPOCH: 15\n","[DEV] AVG QWK: 0.683\n","[DEV] score QWK: 0.751\n","[DEV] content QWK: 0.66\n","[DEV] organization QWK: 0.732\n","[DEV] word_choice QWK: 0.668\n","[DEV] sentence_fluency QWK: 0.647\n","[DEV] conventions QWK: 0.743\n","[DEV] prompt_adherence QWK: 0.64\n","[DEV] language QWK: 0.647\n","[DEV] narrativity QWK: 0.662\n","------------------------\n","[TEST] AVG QWK: 0.656\n","[TEST] score QWK: 0.812\n","[TEST] content QWK: 0.654\n","[TEST] organization QWK: 0.608\n","[TEST] word_choice QWK: 0.654\n","[TEST] sentence_fluency QWK: 0.61\n","[TEST] conventions QWK: 0.595\n","------------------------\n","[BEST TEST] AVG QWK: 0.656, {epoch}: 15\n","[BEST TEST] score QWK: 0.812\n","[BEST TEST] content QWK: 0.654\n","[BEST TEST] organization QWK: 0.608\n","[BEST TEST] word_choice QWK: 0.654\n","[BEST TEST] sentence_fluency QWK: 0.61\n","[BEST TEST] conventions QWK: 0.595\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 159s 167ms/step - loss: 0.0130 - val_loss: 0.0127\n","Epoch 16/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0130Epoch 16: Train Loss: 0.012964468449354172 || Val Loss: 0.012652423232793808\n","Epoch 16 completed in 155.174 seconds\n","53/53 [==============================] - 4s 82ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 16\n","[DEV] AVG QWK: 0.685\n","[DEV] score QWK: 0.756\n","[DEV] content QWK: 0.662\n","[DEV] organization QWK: 0.733\n","[DEV] word_choice QWK: 0.674\n","[DEV] sentence_fluency QWK: 0.647\n","[DEV] conventions QWK: 0.739\n","[DEV] prompt_adherence QWK: 0.644\n","[DEV] language QWK: 0.647\n","[DEV] narrativity QWK: 0.659\n","------------------------\n","[TEST] AVG QWK: 0.656\n","[TEST] score QWK: 0.809\n","[TEST] content QWK: 0.652\n","[TEST] organization QWK: 0.615\n","[TEST] word_choice QWK: 0.646\n","[TEST] sentence_fluency QWK: 0.606\n","[TEST] conventions QWK: 0.607\n","------------------------\n","[BEST TEST] AVG QWK: 0.656, {epoch}: 16\n","[BEST TEST] score QWK: 0.809\n","[BEST TEST] content QWK: 0.652\n","[BEST TEST] organization QWK: 0.615\n","[BEST TEST] word_choice QWK: 0.646\n","[BEST TEST] sentence_fluency QWK: 0.606\n","[BEST TEST] conventions QWK: 0.607\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 169s 177ms/step - loss: 0.0130 - val_loss: 0.0127\n","Epoch 17/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0129Epoch 17: Train Loss: 0.01293447706848383 || Val Loss: 0.012708431109786034\n","Epoch 17 completed in 142.776 seconds\n","53/53 [==============================] - 4s 70ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 17\n","[DEV] AVG QWK: 0.685\n","[DEV] score QWK: 0.753\n","[DEV] content QWK: 0.657\n","[DEV] organization QWK: 0.738\n","[DEV] word_choice QWK: 0.677\n","[DEV] sentence_fluency QWK: 0.648\n","[DEV] conventions QWK: 0.745\n","[DEV] prompt_adherence QWK: 0.642\n","[DEV] language QWK: 0.647\n","[DEV] narrativity QWK: 0.655\n","------------------------\n","[TEST] AVG QWK: 0.654\n","[TEST] score QWK: 0.801\n","[TEST] content QWK: 0.646\n","[TEST] organization QWK: 0.606\n","[TEST] word_choice QWK: 0.644\n","[TEST] sentence_fluency QWK: 0.621\n","[TEST] conventions QWK: 0.606\n","------------------------\n","[BEST TEST] AVG QWK: 0.654, {epoch}: 17\n","[BEST TEST] score QWK: 0.801\n","[BEST TEST] content QWK: 0.646\n","[BEST TEST] organization QWK: 0.606\n","[BEST TEST] word_choice QWK: 0.644\n","[BEST TEST] sentence_fluency QWK: 0.621\n","[BEST TEST] conventions QWK: 0.606\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 156s 163ms/step - loss: 0.0129 - val_loss: 0.0127\n","Epoch 18/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0129Epoch 18: Train Loss: 0.012904832139611244 || Val Loss: 0.012590081430971622\n","Epoch 18 completed in 141.043 seconds\n","53/53 [==============================] - 4s 76ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 18\n","[DEV] AVG QWK: 0.684\n","[DEV] score QWK: 0.756\n","[DEV] content QWK: 0.663\n","[DEV] organization QWK: 0.737\n","[DEV] word_choice QWK: 0.666\n","[DEV] sentence_fluency QWK: 0.631\n","[DEV] conventions QWK: 0.744\n","[DEV] prompt_adherence QWK: 0.644\n","[DEV] language QWK: 0.648\n","[DEV] narrativity QWK: 0.662\n","------------------------\n","[TEST] AVG QWK: 0.641\n","[TEST] score QWK: 0.806\n","[TEST] content QWK: 0.646\n","[TEST] organization QWK: 0.606\n","[TEST] word_choice QWK: 0.627\n","[TEST] sentence_fluency QWK: 0.574\n","[TEST] conventions QWK: 0.586\n","------------------------\n","[BEST TEST] AVG QWK: 0.654, {epoch}: 17\n","[BEST TEST] score QWK: 0.801\n","[BEST TEST] content QWK: 0.646\n","[BEST TEST] organization QWK: 0.606\n","[BEST TEST] word_choice QWK: 0.644\n","[BEST TEST] sentence_fluency QWK: 0.621\n","[BEST TEST] conventions QWK: 0.606\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 156s 164ms/step - loss: 0.0129 - val_loss: 0.0126\n","Epoch 19/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0129Epoch 19: Train Loss: 0.01288218330591917 || Val Loss: 0.012590855360031128\n","Epoch 19 completed in 140.874 seconds\n","53/53 [==============================] - 3s 61ms/step\n","56/56 [==============================] - 3s 56ms/step\n","CURRENT EPOCH: 19\n","[DEV] AVG QWK: 0.686\n","[DEV] score QWK: 0.758\n","[DEV] content QWK: 0.661\n","[DEV] organization QWK: 0.739\n","[DEV] word_choice QWK: 0.674\n","[DEV] sentence_fluency QWK: 0.652\n","[DEV] conventions QWK: 0.738\n","[DEV] prompt_adherence QWK: 0.646\n","[DEV] language QWK: 0.648\n","[DEV] narrativity QWK: 0.658\n","------------------------\n","[TEST] AVG QWK: 0.653\n","[TEST] score QWK: 0.81\n","[TEST] content QWK: 0.65\n","[TEST] organization QWK: 0.615\n","[TEST] word_choice QWK: 0.642\n","[TEST] sentence_fluency QWK: 0.602\n","[TEST] conventions QWK: 0.596\n","------------------------\n","[BEST TEST] AVG QWK: 0.653, {epoch}: 19\n","[BEST TEST] score QWK: 0.81\n","[BEST TEST] content QWK: 0.65\n","[BEST TEST] organization QWK: 0.615\n","[BEST TEST] word_choice QWK: 0.642\n","[BEST TEST] sentence_fluency QWK: 0.602\n","[BEST TEST] conventions QWK: 0.596\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 152s 159ms/step - loss: 0.0129 - val_loss: 0.0126\n","Epoch 20/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0129Epoch 20: Train Loss: 0.012878824956715107 || Val Loss: 0.012552144005894661\n","Epoch 20 completed in 140.934 seconds\n","53/53 [==============================] - 4s 72ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 20\n","[DEV] AVG QWK: 0.684\n","[DEV] score QWK: 0.757\n","[DEV] content QWK: 0.662\n","[DEV] organization QWK: 0.735\n","[DEV] word_choice QWK: 0.661\n","[DEV] sentence_fluency QWK: 0.65\n","[DEV] conventions QWK: 0.745\n","[DEV] prompt_adherence QWK: 0.646\n","[DEV] language QWK: 0.645\n","[DEV] narrativity QWK: 0.659\n","------------------------\n","[TEST] AVG QWK: 0.646\n","[TEST] score QWK: 0.809\n","[TEST] content QWK: 0.646\n","[TEST] organization QWK: 0.597\n","[TEST] word_choice QWK: 0.623\n","[TEST] sentence_fluency QWK: 0.605\n","[TEST] conventions QWK: 0.594\n","------------------------\n","[BEST TEST] AVG QWK: 0.653, {epoch}: 19\n","[BEST TEST] score QWK: 0.81\n","[BEST TEST] content QWK: 0.65\n","[BEST TEST] organization QWK: 0.615\n","[BEST TEST] word_choice QWK: 0.642\n","[BEST TEST] sentence_fluency QWK: 0.602\n","[BEST TEST] conventions QWK: 0.596\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 155s 162ms/step - loss: 0.0129 - val_loss: 0.0126\n","Epoch 21/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0129Epoch 21: Train Loss: 0.012865335680544376 || Val Loss: 0.012689868919551373\n","Epoch 21 completed in 140.758 seconds\n","53/53 [==============================] - 4s 66ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 21\n","[DEV] AVG QWK: 0.682\n","[DEV] score QWK: 0.751\n","[DEV] content QWK: 0.659\n","[DEV] organization QWK: 0.738\n","[DEV] word_choice QWK: 0.641\n","[DEV] sentence_fluency QWK: 0.641\n","[DEV] conventions QWK: 0.743\n","[DEV] prompt_adherence QWK: 0.648\n","[DEV] language QWK: 0.652\n","[DEV] narrativity QWK: 0.664\n","------------------------\n","[TEST] AVG QWK: 0.634\n","[TEST] score QWK: 0.781\n","[TEST] content QWK: 0.65\n","[TEST] organization QWK: 0.598\n","[TEST] word_choice QWK: 0.592\n","[TEST] sentence_fluency QWK: 0.594\n","[TEST] conventions QWK: 0.588\n","------------------------\n","[BEST TEST] AVG QWK: 0.653, {epoch}: 19\n","[BEST TEST] score QWK: 0.81\n","[BEST TEST] content QWK: 0.65\n","[BEST TEST] organization QWK: 0.615\n","[BEST TEST] word_choice QWK: 0.642\n","[BEST TEST] sentence_fluency QWK: 0.602\n","[BEST TEST] conventions QWK: 0.596\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 153s 160ms/step - loss: 0.0129 - val_loss: 0.0127\n","Epoch 22/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0128Epoch 22: Train Loss: 0.012817256152629852 || Val Loss: 0.012629478238523006\n","Epoch 22 completed in 140.523 seconds\n","53/53 [==============================] - 4s 79ms/step\n","56/56 [==============================] - 3s 56ms/step\n","CURRENT EPOCH: 22\n","[DEV] AVG QWK: 0.684\n","[DEV] score QWK: 0.755\n","[DEV] content QWK: 0.665\n","[DEV] organization QWK: 0.74\n","[DEV] word_choice QWK: 0.672\n","[DEV] sentence_fluency QWK: 0.635\n","[DEV] conventions QWK: 0.743\n","[DEV] prompt_adherence QWK: 0.635\n","[DEV] language QWK: 0.648\n","[DEV] narrativity QWK: 0.664\n","------------------------\n","[TEST] AVG QWK: 0.656\n","[TEST] score QWK: 0.822\n","[TEST] content QWK: 0.644\n","[TEST] organization QWK: 0.609\n","[TEST] word_choice QWK: 0.654\n","[TEST] sentence_fluency QWK: 0.608\n","[TEST] conventions QWK: 0.598\n","------------------------\n","[BEST TEST] AVG QWK: 0.653, {epoch}: 19\n","[BEST TEST] score QWK: 0.81\n","[BEST TEST] content QWK: 0.65\n","[BEST TEST] organization QWK: 0.615\n","[BEST TEST] word_choice QWK: 0.642\n","[BEST TEST] sentence_fluency QWK: 0.602\n","[BEST TEST] conventions QWK: 0.596\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 152s 160ms/step - loss: 0.0128 - val_loss: 0.0126\n","Epoch 23/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0128Epoch 23: Train Loss: 0.01278762612491846 || Val Loss: 0.012558359652757645\n","Epoch 23 completed in 141.697 seconds\n","53/53 [==============================] - 4s 73ms/step\n","56/56 [==============================] - 3s 61ms/step\n","CURRENT EPOCH: 23\n","[DEV] AVG QWK: 0.689\n","[DEV] score QWK: 0.756\n","[DEV] content QWK: 0.668\n","[DEV] organization QWK: 0.737\n","[DEV] word_choice QWK: 0.671\n","[DEV] sentence_fluency QWK: 0.658\n","[DEV] conventions QWK: 0.751\n","[DEV] prompt_adherence QWK: 0.649\n","[DEV] language QWK: 0.651\n","[DEV] narrativity QWK: 0.664\n","------------------------\n","[TEST] AVG QWK: 0.652\n","[TEST] score QWK: 0.82\n","[TEST] content QWK: 0.65\n","[TEST] organization QWK: 0.599\n","[TEST] word_choice QWK: 0.641\n","[TEST] sentence_fluency QWK: 0.603\n","[TEST] conventions QWK: 0.599\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 23\n","[BEST TEST] score QWK: 0.82\n","[BEST TEST] content QWK: 0.65\n","[BEST TEST] organization QWK: 0.599\n","[BEST TEST] word_choice QWK: 0.641\n","[BEST TEST] sentence_fluency QWK: 0.603\n","[BEST TEST] conventions QWK: 0.599\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 155s 163ms/step - loss: 0.0128 - val_loss: 0.0126\n","Epoch 24/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0128Epoch 24: Train Loss: 0.012774540111422539 || Val Loss: 0.012523497454822063\n","Epoch 24 completed in 151.146 seconds\n","53/53 [==============================] - 3s 58ms/step\n","56/56 [==============================] - 4s 66ms/step\n","CURRENT EPOCH: 24\n","[DEV] AVG QWK: 0.689\n","[DEV] score QWK: 0.755\n","[DEV] content QWK: 0.665\n","[DEV] organization QWK: 0.745\n","[DEV] word_choice QWK: 0.678\n","[DEV] sentence_fluency QWK: 0.648\n","[DEV] conventions QWK: 0.751\n","[DEV] prompt_adherence QWK: 0.647\n","[DEV] language QWK: 0.646\n","[DEV] narrativity QWK: 0.664\n","------------------------\n","[TEST] AVG QWK: 0.652\n","[TEST] score QWK: 0.822\n","[TEST] content QWK: 0.641\n","[TEST] organization QWK: 0.606\n","[TEST] word_choice QWK: 0.638\n","[TEST] sentence_fluency QWK: 0.603\n","[TEST] conventions QWK: 0.6\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 23\n","[BEST TEST] score QWK: 0.82\n","[BEST TEST] content QWK: 0.65\n","[BEST TEST] organization QWK: 0.599\n","[BEST TEST] word_choice QWK: 0.641\n","[BEST TEST] sentence_fluency QWK: 0.603\n","[BEST TEST] conventions QWK: 0.599\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 164s 172ms/step - loss: 0.0128 - val_loss: 0.0125\n","Epoch 25/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0128Epoch 25: Train Loss: 0.012771585956215858 || Val Loss: 0.01255159080028534\n","Epoch 25 completed in 151.066 seconds\n","53/53 [==============================] - 3s 57ms/step\n","56/56 [==============================] - 3s 58ms/step\n","CURRENT EPOCH: 25\n","[DEV] AVG QWK: 0.69\n","[DEV] score QWK: 0.757\n","[DEV] content QWK: 0.667\n","[DEV] organization QWK: 0.74\n","[DEV] word_choice QWK: 0.68\n","[DEV] sentence_fluency QWK: 0.657\n","[DEV] conventions QWK: 0.748\n","[DEV] prompt_adherence QWK: 0.647\n","[DEV] language QWK: 0.649\n","[DEV] narrativity QWK: 0.666\n","------------------------\n","[TEST] AVG QWK: 0.648\n","[TEST] score QWK: 0.821\n","[TEST] content QWK: 0.643\n","[TEST] organization QWK: 0.6\n","[TEST] word_choice QWK: 0.638\n","[TEST] sentence_fluency QWK: 0.599\n","[TEST] conventions QWK: 0.588\n","------------------------\n","[BEST TEST] AVG QWK: 0.648, {epoch}: 25\n","[BEST TEST] score QWK: 0.821\n","[BEST TEST] content QWK: 0.643\n","[BEST TEST] organization QWK: 0.6\n","[BEST TEST] word_choice QWK: 0.638\n","[BEST TEST] sentence_fluency QWK: 0.599\n","[BEST TEST] conventions QWK: 0.588\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 162s 170ms/step - loss: 0.0128 - val_loss: 0.0126\n","Epoch 26/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 26: Train Loss: 0.012746397405862808 || Val Loss: 0.012566793709993362\n","Epoch 26 completed in 141.666 seconds\n","53/53 [==============================] - 3s 57ms/step\n","56/56 [==============================] - 4s 63ms/step\n","CURRENT EPOCH: 26\n","[DEV] AVG QWK: 0.689\n","[DEV] score QWK: 0.754\n","[DEV] content QWK: 0.665\n","[DEV] organization QWK: 0.737\n","[DEV] word_choice QWK: 0.679\n","[DEV] sentence_fluency QWK: 0.661\n","[DEV] conventions QWK: 0.748\n","[DEV] prompt_adherence QWK: 0.647\n","[DEV] language QWK: 0.65\n","[DEV] narrativity QWK: 0.665\n","------------------------\n","[TEST] AVG QWK: 0.648\n","[TEST] score QWK: 0.821\n","[TEST] content QWK: 0.626\n","[TEST] organization QWK: 0.594\n","[TEST] word_choice QWK: 0.633\n","[TEST] sentence_fluency QWK: 0.613\n","[TEST] conventions QWK: 0.599\n","------------------------\n","[BEST TEST] AVG QWK: 0.648, {epoch}: 25\n","[BEST TEST] score QWK: 0.821\n","[BEST TEST] content QWK: 0.643\n","[BEST TEST] organization QWK: 0.6\n","[BEST TEST] word_choice QWK: 0.638\n","[BEST TEST] sentence_fluency QWK: 0.599\n","[BEST TEST] conventions QWK: 0.588\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 156s 164ms/step - loss: 0.0127 - val_loss: 0.0126\n","Epoch 27/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 27: Train Loss: 0.01272888109087944 || Val Loss: 0.01244643609970808\n","Epoch 27 completed in 140.259 seconds\n","53/53 [==============================] - 3s 57ms/step\n","56/56 [==============================] - 4s 79ms/step\n","CURRENT EPOCH: 27\n","[DEV] AVG QWK: 0.691\n","[DEV] score QWK: 0.756\n","[DEV] content QWK: 0.664\n","[DEV] organization QWK: 0.743\n","[DEV] word_choice QWK: 0.678\n","[DEV] sentence_fluency QWK: 0.659\n","[DEV] conventions QWK: 0.755\n","[DEV] prompt_adherence QWK: 0.648\n","[DEV] language QWK: 0.65\n","[DEV] narrativity QWK: 0.665\n","------------------------\n","[TEST] AVG QWK: 0.647\n","[TEST] score QWK: 0.817\n","[TEST] content QWK: 0.639\n","[TEST] organization QWK: 0.599\n","[TEST] word_choice QWK: 0.632\n","[TEST] sentence_fluency QWK: 0.604\n","[TEST] conventions QWK: 0.593\n","------------------------\n","[BEST TEST] AVG QWK: 0.647, {epoch}: 27\n","[BEST TEST] score QWK: 0.817\n","[BEST TEST] content QWK: 0.639\n","[BEST TEST] organization QWK: 0.599\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.604\n","[BEST TEST] conventions QWK: 0.593\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 153s 160ms/step - loss: 0.0127 - val_loss: 0.0124\n","Epoch 28/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 28: Train Loss: 0.012716563418507576 || Val Loss: 0.01245693676173687\n","Epoch 28 completed in 141.721 seconds\n","53/53 [==============================] - 3s 59ms/step\n","56/56 [==============================] - 4s 67ms/step\n","CURRENT EPOCH: 28\n","[DEV] AVG QWK: 0.692\n","[DEV] score QWK: 0.757\n","[DEV] content QWK: 0.665\n","[DEV] organization QWK: 0.741\n","[DEV] word_choice QWK: 0.681\n","[DEV] sentence_fluency QWK: 0.661\n","[DEV] conventions QWK: 0.752\n","[DEV] prompt_adherence QWK: 0.649\n","[DEV] language QWK: 0.653\n","[DEV] narrativity QWK: 0.668\n","------------------------\n","[TEST] AVG QWK: 0.645\n","[TEST] score QWK: 0.817\n","[TEST] content QWK: 0.627\n","[TEST] organization QWK: 0.601\n","[TEST] word_choice QWK: 0.631\n","[TEST] sentence_fluency QWK: 0.602\n","[TEST] conventions QWK: 0.593\n","------------------------\n","[BEST TEST] AVG QWK: 0.645, {epoch}: 28\n","[BEST TEST] score QWK: 0.817\n","[BEST TEST] content QWK: 0.627\n","[BEST TEST] organization QWK: 0.601\n","[BEST TEST] word_choice QWK: 0.631\n","[BEST TEST] sentence_fluency QWK: 0.602\n","[BEST TEST] conventions QWK: 0.593\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 152s 160ms/step - loss: 0.0127 - val_loss: 0.0125\n","Epoch 29/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 29: Train Loss: 0.012710632756352425 || Val Loss: 0.012561117298901081\n","Epoch 29 completed in 150.712 seconds\n","53/53 [==============================] - 3s 62ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 29\n","[DEV] AVG QWK: 0.692\n","[DEV] score QWK: 0.758\n","[DEV] content QWK: 0.671\n","[DEV] organization QWK: 0.743\n","[DEV] word_choice QWK: 0.674\n","[DEV] sentence_fluency QWK: 0.661\n","[DEV] conventions QWK: 0.751\n","[DEV] prompt_adherence QWK: 0.646\n","[DEV] language QWK: 0.651\n","[DEV] narrativity QWK: 0.669\n","------------------------\n","[TEST] AVG QWK: 0.647\n","[TEST] score QWK: 0.819\n","[TEST] content QWK: 0.64\n","[TEST] organization QWK: 0.599\n","[TEST] word_choice QWK: 0.638\n","[TEST] sentence_fluency QWK: 0.594\n","[TEST] conventions QWK: 0.59\n","------------------------\n","[BEST TEST] AVG QWK: 0.645, {epoch}: 28\n","[BEST TEST] score QWK: 0.817\n","[BEST TEST] content QWK: 0.627\n","[BEST TEST] organization QWK: 0.601\n","[BEST TEST] word_choice QWK: 0.631\n","[BEST TEST] sentence_fluency QWK: 0.602\n","[BEST TEST] conventions QWK: 0.593\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 163s 171ms/step - loss: 0.0127 - val_loss: 0.0126\n","Epoch 30/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 30: Train Loss: 0.012696288526058197 || Val Loss: 0.012586318887770176\n","Epoch 30 completed in 152.276 seconds\n","53/53 [==============================] - 4s 81ms/step\n","56/56 [==============================] - 3s 59ms/step\n","CURRENT EPOCH: 30\n","[DEV] AVG QWK: 0.691\n","[DEV] score QWK: 0.755\n","[DEV] content QWK: 0.667\n","[DEV] organization QWK: 0.736\n","[DEV] word_choice QWK: 0.679\n","[DEV] sentence_fluency QWK: 0.657\n","[DEV] conventions QWK: 0.754\n","[DEV] prompt_adherence QWK: 0.651\n","[DEV] language QWK: 0.652\n","[DEV] narrativity QWK: 0.668\n","------------------------\n","[TEST] AVG QWK: 0.642\n","[TEST] score QWK: 0.804\n","[TEST] content QWK: 0.644\n","[TEST] organization QWK: 0.588\n","[TEST] word_choice QWK: 0.636\n","[TEST] sentence_fluency QWK: 0.595\n","[TEST] conventions QWK: 0.587\n","------------------------\n","[BEST TEST] AVG QWK: 0.645, {epoch}: 28\n","[BEST TEST] score QWK: 0.817\n","[BEST TEST] content QWK: 0.627\n","[BEST TEST] organization QWK: 0.601\n","[BEST TEST] word_choice QWK: 0.631\n","[BEST TEST] sentence_fluency QWK: 0.602\n","[BEST TEST] conventions QWK: 0.593\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 167s 176ms/step - loss: 0.0127 - val_loss: 0.0126\n","Epoch 31/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 31: Train Loss: 0.012698848731815815 || Val Loss: 0.012439425103366375\n","Epoch 31 completed in 155.808 seconds\n","53/53 [==============================] - 4s 83ms/step\n","56/56 [==============================] - 3s 59ms/step\n","CURRENT EPOCH: 31\n","[DEV] AVG QWK: 0.693\n","[DEV] score QWK: 0.755\n","[DEV] content QWK: 0.67\n","[DEV] organization QWK: 0.744\n","[DEV] word_choice QWK: 0.682\n","[DEV] sentence_fluency QWK: 0.663\n","[DEV] conventions QWK: 0.748\n","[DEV] prompt_adherence QWK: 0.651\n","[DEV] language QWK: 0.651\n","[DEV] narrativity QWK: 0.67\n","------------------------\n","[TEST] AVG QWK: 0.644\n","[TEST] score QWK: 0.803\n","[TEST] content QWK: 0.629\n","[TEST] organization QWK: 0.605\n","[TEST] word_choice QWK: 0.629\n","[TEST] sentence_fluency QWK: 0.616\n","[TEST] conventions QWK: 0.583\n","------------------------\n","[BEST TEST] AVG QWK: 0.644, {epoch}: 31\n","[BEST TEST] score QWK: 0.803\n","[BEST TEST] content QWK: 0.629\n","[BEST TEST] organization QWK: 0.605\n","[BEST TEST] word_choice QWK: 0.629\n","[BEST TEST] sentence_fluency QWK: 0.616\n","[BEST TEST] conventions QWK: 0.583\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 167s 175ms/step - loss: 0.0127 - val_loss: 0.0124\n","Epoch 32/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 32: Train Loss: 0.012688130140304565 || Val Loss: 0.012370639480650425\n","Epoch 32 completed in 146.307 seconds\n","53/53 [==============================] - 4s 81ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 32\n","[DEV] AVG QWK: 0.695\n","[DEV] score QWK: 0.76\n","[DEV] content QWK: 0.673\n","[DEV] organization QWK: 0.748\n","[DEV] word_choice QWK: 0.686\n","[DEV] sentence_fluency QWK: 0.663\n","[DEV] conventions QWK: 0.752\n","[DEV] prompt_adherence QWK: 0.65\n","[DEV] language QWK: 0.651\n","[DEV] narrativity QWK: 0.669\n","------------------------\n","[TEST] AVG QWK: 0.653\n","[TEST] score QWK: 0.82\n","[TEST] content QWK: 0.641\n","[TEST] organization QWK: 0.609\n","[TEST] word_choice QWK: 0.641\n","[TEST] sentence_fluency QWK: 0.62\n","[TEST] conventions QWK: 0.59\n","------------------------\n","[BEST TEST] AVG QWK: 0.653, {epoch}: 32\n","[BEST TEST] score QWK: 0.82\n","[BEST TEST] content QWK: 0.641\n","[BEST TEST] organization QWK: 0.609\n","[BEST TEST] word_choice QWK: 0.641\n","[BEST TEST] sentence_fluency QWK: 0.62\n","[BEST TEST] conventions QWK: 0.59\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 160s 168ms/step - loss: 0.0127 - val_loss: 0.0124\n","Epoch 33/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 33: Train Loss: 0.012666014023125172 || Val Loss: 0.01242967788130045\n","Epoch 33 completed in 154.502 seconds\n","53/53 [==============================] - 4s 82ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 33\n","[DEV] AVG QWK: 0.695\n","[DEV] score QWK: 0.759\n","[DEV] content QWK: 0.67\n","[DEV] organization QWK: 0.745\n","[DEV] word_choice QWK: 0.685\n","[DEV] sentence_fluency QWK: 0.664\n","[DEV] conventions QWK: 0.752\n","[DEV] prompt_adherence QWK: 0.648\n","[DEV] language QWK: 0.656\n","[DEV] narrativity QWK: 0.67\n","------------------------\n","[TEST] AVG QWK: 0.65\n","[TEST] score QWK: 0.821\n","[TEST] content QWK: 0.645\n","[TEST] organization QWK: 0.597\n","[TEST] word_choice QWK: 0.639\n","[TEST] sentence_fluency QWK: 0.603\n","[TEST] conventions QWK: 0.596\n","------------------------\n","[BEST TEST] AVG QWK: 0.65, {epoch}: 33\n","[BEST TEST] score QWK: 0.821\n","[BEST TEST] content QWK: 0.645\n","[BEST TEST] organization QWK: 0.597\n","[BEST TEST] word_choice QWK: 0.639\n","[BEST TEST] sentence_fluency QWK: 0.603\n","[BEST TEST] conventions QWK: 0.596\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 166s 174ms/step - loss: 0.0127 - val_loss: 0.0124\n","Epoch 34/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 34: Train Loss: 0.012669024057686329 || Val Loss: 0.012551829218864441\n","Epoch 34 completed in 163.996 seconds\n","53/53 [==============================] - 3s 64ms/step\n","56/56 [==============================] - 4s 63ms/step\n","CURRENT EPOCH: 34\n","[DEV] AVG QWK: 0.692\n","[DEV] score QWK: 0.759\n","[DEV] content QWK: 0.67\n","[DEV] organization QWK: 0.735\n","[DEV] word_choice QWK: 0.685\n","[DEV] sentence_fluency QWK: 0.665\n","[DEV] conventions QWK: 0.739\n","[DEV] prompt_adherence QWK: 0.65\n","[DEV] language QWK: 0.654\n","[DEV] narrativity QWK: 0.668\n","------------------------\n","[TEST] AVG QWK: 0.636\n","[TEST] score QWK: 0.819\n","[TEST] content QWK: 0.615\n","[TEST] organization QWK: 0.578\n","[TEST] word_choice QWK: 0.632\n","[TEST] sentence_fluency QWK: 0.614\n","[TEST] conventions QWK: 0.559\n","------------------------\n","[BEST TEST] AVG QWK: 0.65, {epoch}: 33\n","[BEST TEST] score QWK: 0.821\n","[BEST TEST] content QWK: 0.645\n","[BEST TEST] organization QWK: 0.597\n","[BEST TEST] word_choice QWK: 0.639\n","[BEST TEST] sentence_fluency QWK: 0.603\n","[BEST TEST] conventions QWK: 0.596\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 178s 187ms/step - loss: 0.0127 - val_loss: 0.0126\n","Epoch 35/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 35: Train Loss: 0.01264344621449709 || Val Loss: 0.012468069791793823\n","Epoch 35 completed in 149.909 seconds\n","53/53 [==============================] - 4s 79ms/step\n","56/56 [==============================] - 3s 58ms/step\n","CURRENT EPOCH: 35\n","[DEV] AVG QWK: 0.694\n","[DEV] score QWK: 0.758\n","[DEV] content QWK: 0.664\n","[DEV] organization QWK: 0.742\n","[DEV] word_choice QWK: 0.69\n","[DEV] sentence_fluency QWK: 0.667\n","[DEV] conventions QWK: 0.756\n","[DEV] prompt_adherence QWK: 0.647\n","[DEV] language QWK: 0.656\n","[DEV] narrativity QWK: 0.669\n","------------------------\n","[TEST] AVG QWK: 0.65\n","[TEST] score QWK: 0.819\n","[TEST] content QWK: 0.647\n","[TEST] organization QWK: 0.596\n","[TEST] word_choice QWK: 0.634\n","[TEST] sentence_fluency QWK: 0.617\n","[TEST] conventions QWK: 0.586\n","------------------------\n","[BEST TEST] AVG QWK: 0.65, {epoch}: 33\n","[BEST TEST] score QWK: 0.821\n","[BEST TEST] content QWK: 0.645\n","[BEST TEST] organization QWK: 0.597\n","[BEST TEST] word_choice QWK: 0.639\n","[BEST TEST] sentence_fluency QWK: 0.603\n","[BEST TEST] conventions QWK: 0.596\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 163s 171ms/step - loss: 0.0126 - val_loss: 0.0125\n","Epoch 36/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 36: Train Loss: 0.012649763375520706 || Val Loss: 0.012359661981463432\n","Epoch 36 completed in 143.688 seconds\n","53/53 [==============================] - 4s 76ms/step\n","56/56 [==============================] - 3s 56ms/step\n","CURRENT EPOCH: 36\n","[DEV] AVG QWK: 0.693\n","[DEV] score QWK: 0.76\n","[DEV] content QWK: 0.668\n","[DEV] organization QWK: 0.748\n","[DEV] word_choice QWK: 0.688\n","[DEV] sentence_fluency QWK: 0.663\n","[DEV] conventions QWK: 0.757\n","[DEV] prompt_adherence QWK: 0.648\n","[DEV] language QWK: 0.645\n","[DEV] narrativity QWK: 0.664\n","------------------------\n","[TEST] AVG QWK: 0.65\n","[TEST] score QWK: 0.82\n","[TEST] content QWK: 0.639\n","[TEST] organization QWK: 0.602\n","[TEST] word_choice QWK: 0.634\n","[TEST] sentence_fluency QWK: 0.614\n","[TEST] conventions QWK: 0.592\n","------------------------\n","[BEST TEST] AVG QWK: 0.65, {epoch}: 33\n","[BEST TEST] score QWK: 0.821\n","[BEST TEST] content QWK: 0.645\n","[BEST TEST] organization QWK: 0.597\n","[BEST TEST] word_choice QWK: 0.639\n","[BEST TEST] sentence_fluency QWK: 0.603\n","[BEST TEST] conventions QWK: 0.596\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 157s 164ms/step - loss: 0.0126 - val_loss: 0.0124\n","Epoch 37/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 37: Train Loss: 0.01262934971600771 || Val Loss: 0.012368614785373211\n","Epoch 37 completed in 144.695 seconds\n","53/53 [==============================] - 3s 64ms/step\n","56/56 [==============================] - 3s 58ms/step\n","CURRENT EPOCH: 37\n","[DEV] AVG QWK: 0.696\n","[DEV] score QWK: 0.759\n","[DEV] content QWK: 0.669\n","[DEV] organization QWK: 0.747\n","[DEV] word_choice QWK: 0.687\n","[DEV] sentence_fluency QWK: 0.668\n","[DEV] conventions QWK: 0.757\n","[DEV] prompt_adherence QWK: 0.654\n","[DEV] language QWK: 0.656\n","[DEV] narrativity QWK: 0.671\n","------------------------\n","[TEST] AVG QWK: 0.65\n","[TEST] score QWK: 0.818\n","[TEST] content QWK: 0.636\n","[TEST] organization QWK: 0.602\n","[TEST] word_choice QWK: 0.637\n","[TEST] sentence_fluency QWK: 0.617\n","[TEST] conventions QWK: 0.592\n","------------------------\n","[BEST TEST] AVG QWK: 0.65, {epoch}: 37\n","[BEST TEST] score QWK: 0.818\n","[BEST TEST] content QWK: 0.636\n","[BEST TEST] organization QWK: 0.602\n","[BEST TEST] word_choice QWK: 0.637\n","[BEST TEST] sentence_fluency QWK: 0.617\n","[BEST TEST] conventions QWK: 0.592\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 156s 163ms/step - loss: 0.0126 - val_loss: 0.0124\n","Epoch 38/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 38: Train Loss: 0.012633616104722023 || Val Loss: 0.012435932643711567\n","Epoch 38 completed in 143.896 seconds\n","53/53 [==============================] - 3s 65ms/step\n","56/56 [==============================] - 3s 60ms/step\n","CURRENT EPOCH: 38\n","[DEV] AVG QWK: 0.695\n","[DEV] score QWK: 0.754\n","[DEV] content QWK: 0.671\n","[DEV] organization QWK: 0.743\n","[DEV] word_choice QWK: 0.687\n","[DEV] sentence_fluency QWK: 0.668\n","[DEV] conventions QWK: 0.751\n","[DEV] prompt_adherence QWK: 0.657\n","[DEV] language QWK: 0.654\n","[DEV] narrativity QWK: 0.67\n","------------------------\n","[TEST] AVG QWK: 0.637\n","[TEST] score QWK: 0.797\n","[TEST] content QWK: 0.623\n","[TEST] organization QWK: 0.582\n","[TEST] word_choice QWK: 0.632\n","[TEST] sentence_fluency QWK: 0.612\n","[TEST] conventions QWK: 0.575\n","------------------------\n","[BEST TEST] AVG QWK: 0.65, {epoch}: 37\n","[BEST TEST] score QWK: 0.818\n","[BEST TEST] content QWK: 0.636\n","[BEST TEST] organization QWK: 0.602\n","[BEST TEST] word_choice QWK: 0.637\n","[BEST TEST] sentence_fluency QWK: 0.617\n","[BEST TEST] conventions QWK: 0.592\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 156s 164ms/step - loss: 0.0126 - val_loss: 0.0124\n","Epoch 39/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 39: Train Loss: 0.012617560103535652 || Val Loss: 0.012410962022840977\n","Epoch 39 completed in 168.725 seconds\n","53/53 [==============================] - 4s 78ms/step\n","56/56 [==============================] - 4s 63ms/step\n","CURRENT EPOCH: 39\n","[DEV] AVG QWK: 0.696\n","[DEV] score QWK: 0.761\n","[DEV] content QWK: 0.676\n","[DEV] organization QWK: 0.741\n","[DEV] word_choice QWK: 0.685\n","[DEV] sentence_fluency QWK: 0.665\n","[DEV] conventions QWK: 0.746\n","[DEV] prompt_adherence QWK: 0.655\n","[DEV] language QWK: 0.657\n","[DEV] narrativity QWK: 0.675\n","------------------------\n","[TEST] AVG QWK: 0.637\n","[TEST] score QWK: 0.819\n","[TEST] content QWK: 0.632\n","[TEST] organization QWK: 0.578\n","[TEST] word_choice QWK: 0.631\n","[TEST] sentence_fluency QWK: 0.605\n","[TEST] conventions QWK: 0.559\n","------------------------\n","[BEST TEST] AVG QWK: 0.65, {epoch}: 37\n","[BEST TEST] score QWK: 0.818\n","[BEST TEST] content QWK: 0.636\n","[BEST TEST] organization QWK: 0.602\n","[BEST TEST] word_choice QWK: 0.637\n","[BEST TEST] sentence_fluency QWK: 0.617\n","[BEST TEST] conventions QWK: 0.592\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 181s 190ms/step - loss: 0.0126 - val_loss: 0.0124\n","Epoch 40/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 40: Train Loss: 0.012617681175470352 || Val Loss: 0.01244710385799408\n","Epoch 40 completed in 163.650 seconds\n","53/53 [==============================] - 3s 58ms/step\n","56/56 [==============================] - 3s 58ms/step\n","CURRENT EPOCH: 40\n","[DEV] AVG QWK: 0.697\n","[DEV] score QWK: 0.762\n","[DEV] content QWK: 0.678\n","[DEV] organization QWK: 0.749\n","[DEV] word_choice QWK: 0.676\n","[DEV] sentence_fluency QWK: 0.662\n","[DEV] conventions QWK: 0.757\n","[DEV] prompt_adherence QWK: 0.658\n","[DEV] language QWK: 0.658\n","[DEV] narrativity QWK: 0.675\n","------------------------\n","[TEST] AVG QWK: 0.645\n","[TEST] score QWK: 0.819\n","[TEST] content QWK: 0.621\n","[TEST] organization QWK: 0.602\n","[TEST] word_choice QWK: 0.632\n","[TEST] sentence_fluency QWK: 0.605\n","[TEST] conventions QWK: 0.593\n","------------------------\n","[BEST TEST] AVG QWK: 0.645, {epoch}: 40\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.621\n","[BEST TEST] organization QWK: 0.602\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.605\n","[BEST TEST] conventions QWK: 0.593\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 177s 186ms/step - loss: 0.0126 - val_loss: 0.0124\n","Epoch 41/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 41: Train Loss: 0.012612404301762581 || Val Loss: 0.01252742949873209\n","Epoch 41 completed in 154.556 seconds\n","53/53 [==============================] - 3s 59ms/step\n","56/56 [==============================] - 3s 58ms/step\n","CURRENT EPOCH: 41\n","[DEV] AVG QWK: 0.694\n","[DEV] score QWK: 0.74\n","[DEV] content QWK: 0.674\n","[DEV] organization QWK: 0.742\n","[DEV] word_choice QWK: 0.682\n","[DEV] sentence_fluency QWK: 0.665\n","[DEV] conventions QWK: 0.756\n","[DEV] prompt_adherence QWK: 0.657\n","[DEV] language QWK: 0.657\n","[DEV] narrativity QWK: 0.675\n","------------------------\n","[TEST] AVG QWK: 0.637\n","[TEST] score QWK: 0.76\n","[TEST] content QWK: 0.635\n","[TEST] organization QWK: 0.598\n","[TEST] word_choice QWK: 0.63\n","[TEST] sentence_fluency QWK: 0.605\n","[TEST] conventions QWK: 0.594\n","------------------------\n","[BEST TEST] AVG QWK: 0.645, {epoch}: 40\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.621\n","[BEST TEST] organization QWK: 0.602\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.605\n","[BEST TEST] conventions QWK: 0.593\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 168s 176ms/step - loss: 0.0126 - val_loss: 0.0125\n","Epoch 42/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 42: Train Loss: 0.012592500075697899 || Val Loss: 0.012366886250674725\n","Epoch 42 completed in 154.916 seconds\n","53/53 [==============================] - 3s 59ms/step\n","56/56 [==============================] - 4s 79ms/step\n","CURRENT EPOCH: 42\n","[DEV] AVG QWK: 0.694\n","[DEV] score QWK: 0.756\n","[DEV] content QWK: 0.666\n","[DEV] organization QWK: 0.751\n","[DEV] word_choice QWK: 0.673\n","[DEV] sentence_fluency QWK: 0.661\n","[DEV] conventions QWK: 0.759\n","[DEV] prompt_adherence QWK: 0.655\n","[DEV] language QWK: 0.655\n","[DEV] narrativity QWK: 0.673\n","------------------------\n","[TEST] AVG QWK: 0.643\n","[TEST] score QWK: 0.814\n","[TEST] content QWK: 0.635\n","[TEST] organization QWK: 0.59\n","[TEST] word_choice QWK: 0.63\n","[TEST] sentence_fluency QWK: 0.605\n","[TEST] conventions QWK: 0.581\n","------------------------\n","[BEST TEST] AVG QWK: 0.645, {epoch}: 40\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.621\n","[BEST TEST] organization QWK: 0.602\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.605\n","[BEST TEST] conventions QWK: 0.593\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 169s 178ms/step - loss: 0.0126 - val_loss: 0.0124\n","Epoch 43/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 43: Train Loss: 0.012602507136762142 || Val Loss: 0.012359637767076492\n","Epoch 43 completed in 154.651 seconds\n","53/53 [==============================] - 3s 59ms/step\n","56/56 [==============================] - 4s 77ms/step\n","CURRENT EPOCH: 43\n","[DEV] AVG QWK: 0.697\n","[DEV] score QWK: 0.758\n","[DEV] content QWK: 0.673\n","[DEV] organization QWK: 0.749\n","[DEV] word_choice QWK: 0.685\n","[DEV] sentence_fluency QWK: 0.672\n","[DEV] conventions QWK: 0.75\n","[DEV] prompt_adherence QWK: 0.656\n","[DEV] language QWK: 0.655\n","[DEV] narrativity QWK: 0.673\n","------------------------\n","[TEST] AVG QWK: 0.633\n","[TEST] score QWK: 0.813\n","[TEST] content QWK: 0.609\n","[TEST] organization QWK: 0.584\n","[TEST] word_choice QWK: 0.625\n","[TEST] sentence_fluency QWK: 0.605\n","[TEST] conventions QWK: 0.56\n","------------------------\n","[BEST TEST] AVG QWK: 0.645, {epoch}: 40\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.621\n","[BEST TEST] organization QWK: 0.602\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.605\n","[BEST TEST] conventions QWK: 0.593\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 169s 177ms/step - loss: 0.0126 - val_loss: 0.0124\n","Epoch 44/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 44: Train Loss: 0.012581290677189827 || Val Loss: 0.012398960068821907\n","Epoch 44 completed in 144.032 seconds\n","53/53 [==============================] - 3s 57ms/step\n","56/56 [==============================] - 4s 80ms/step\n","CURRENT EPOCH: 44\n","[DEV] AVG QWK: 0.696\n","[DEV] score QWK: 0.758\n","[DEV] content QWK: 0.663\n","[DEV] organization QWK: 0.75\n","[DEV] word_choice QWK: 0.683\n","[DEV] sentence_fluency QWK: 0.671\n","[DEV] conventions QWK: 0.759\n","[DEV] prompt_adherence QWK: 0.655\n","[DEV] language QWK: 0.657\n","[DEV] narrativity QWK: 0.672\n","------------------------\n","[TEST] AVG QWK: 0.649\n","[TEST] score QWK: 0.813\n","[TEST] content QWK: 0.647\n","[TEST] organization QWK: 0.601\n","[TEST] word_choice QWK: 0.633\n","[TEST] sentence_fluency QWK: 0.613\n","[TEST] conventions QWK: 0.586\n","------------------------\n","[BEST TEST] AVG QWK: 0.645, {epoch}: 40\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.621\n","[BEST TEST] organization QWK: 0.602\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.605\n","[BEST TEST] conventions QWK: 0.593\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 154s 162ms/step - loss: 0.0126 - val_loss: 0.0124\n","Epoch 45/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 45: Train Loss: 0.012591337785124779 || Val Loss: 0.012363336980342865\n","Epoch 45 completed in 144.752 seconds\n","53/53 [==============================] - 3s 58ms/step\n","56/56 [==============================] - 4s 70ms/step\n","CURRENT EPOCH: 45\n","[DEV] AVG QWK: 0.693\n","[DEV] score QWK: 0.758\n","[DEV] content QWK: 0.665\n","[DEV] organization QWK: 0.749\n","[DEV] word_choice QWK: 0.687\n","[DEV] sentence_fluency QWK: 0.662\n","[DEV] conventions QWK: 0.758\n","[DEV] prompt_adherence QWK: 0.651\n","[DEV] language QWK: 0.644\n","[DEV] narrativity QWK: 0.667\n","------------------------\n","[TEST] AVG QWK: 0.644\n","[TEST] score QWK: 0.811\n","[TEST] content QWK: 0.639\n","[TEST] organization QWK: 0.596\n","[TEST] word_choice QWK: 0.63\n","[TEST] sentence_fluency QWK: 0.606\n","[TEST] conventions QWK: 0.584\n","------------------------\n","[BEST TEST] AVG QWK: 0.645, {epoch}: 40\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.621\n","[BEST TEST] organization QWK: 0.602\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.605\n","[BEST TEST] conventions QWK: 0.593\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 156s 164ms/step - loss: 0.0126 - val_loss: 0.0124\n","Epoch 46/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 46: Train Loss: 0.012576726265251637 || Val Loss: 0.012334371916949749\n","Epoch 46 completed in 143.114 seconds\n","53/53 [==============================] - 3s 58ms/step\n","56/56 [==============================] - 4s 77ms/step\n","CURRENT EPOCH: 46\n","[DEV] AVG QWK: 0.697\n","[DEV] score QWK: 0.754\n","[DEV] content QWK: 0.674\n","[DEV] organization QWK: 0.747\n","[DEV] word_choice QWK: 0.689\n","[DEV] sentence_fluency QWK: 0.671\n","[DEV] conventions QWK: 0.758\n","[DEV] prompt_adherence QWK: 0.656\n","[DEV] language QWK: 0.655\n","[DEV] narrativity QWK: 0.669\n","------------------------\n","[TEST] AVG QWK: 0.636\n","[TEST] score QWK: 0.8\n","[TEST] content QWK: 0.625\n","[TEST] organization QWK: 0.582\n","[TEST] word_choice QWK: 0.626\n","[TEST] sentence_fluency QWK: 0.606\n","[TEST] conventions QWK: 0.575\n","------------------------\n","[BEST TEST] AVG QWK: 0.645, {epoch}: 40\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.621\n","[BEST TEST] organization QWK: 0.602\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.605\n","[BEST TEST] conventions QWK: 0.593\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 157s 164ms/step - loss: 0.0126 - val_loss: 0.0123\n","Epoch 47/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0125Epoch 47: Train Loss: 0.012541513890028 || Val Loss: 0.012299775145947933\n","Epoch 47 completed in 144.294 seconds\n","53/53 [==============================] - 3s 59ms/step\n","56/56 [==============================] - 4s 79ms/step\n","CURRENT EPOCH: 47\n","[DEV] AVG QWK: 0.697\n","[DEV] score QWK: 0.758\n","[DEV] content QWK: 0.673\n","[DEV] organization QWK: 0.744\n","[DEV] word_choice QWK: 0.69\n","[DEV] sentence_fluency QWK: 0.669\n","[DEV] conventions QWK: 0.757\n","[DEV] prompt_adherence QWK: 0.657\n","[DEV] language QWK: 0.66\n","[DEV] narrativity QWK: 0.669\n","------------------------\n","[TEST] AVG QWK: 0.635\n","[TEST] score QWK: 0.817\n","[TEST] content QWK: 0.633\n","[TEST] organization QWK: 0.564\n","[TEST] word_choice QWK: 0.629\n","[TEST] sentence_fluency QWK: 0.608\n","[TEST] conventions QWK: 0.561\n","------------------------\n","[BEST TEST] AVG QWK: 0.635, {epoch}: 47\n","[BEST TEST] score QWK: 0.817\n","[BEST TEST] content QWK: 0.633\n","[BEST TEST] organization QWK: 0.564\n","[BEST TEST] word_choice QWK: 0.629\n","[BEST TEST] sentence_fluency QWK: 0.608\n","[BEST TEST] conventions QWK: 0.561\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 156s 164ms/step - loss: 0.0125 - val_loss: 0.0123\n","Epoch 48/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 48: Train Loss: 0.01255212351679802 || Val Loss: 0.012654399499297142\n","Epoch 48 completed in 153.431 seconds\n","53/53 [==============================] - 3s 59ms/step\n","56/56 [==============================] - 3s 58ms/step\n","CURRENT EPOCH: 48\n","[DEV] AVG QWK: 0.69\n","[DEV] score QWK: 0.756\n","[DEV] content QWK: 0.656\n","[DEV] organization QWK: 0.738\n","[DEV] word_choice QWK: 0.679\n","[DEV] sentence_fluency QWK: 0.661\n","[DEV] conventions QWK: 0.762\n","[DEV] prompt_adherence QWK: 0.643\n","[DEV] language QWK: 0.648\n","[DEV] narrativity QWK: 0.668\n","------------------------\n","[TEST] AVG QWK: 0.644\n","[TEST] score QWK: 0.804\n","[TEST] content QWK: 0.645\n","[TEST] organization QWK: 0.592\n","[TEST] word_choice QWK: 0.634\n","[TEST] sentence_fluency QWK: 0.609\n","[TEST] conventions QWK: 0.582\n","------------------------\n","[BEST TEST] AVG QWK: 0.635, {epoch}: 47\n","[BEST TEST] score QWK: 0.817\n","[BEST TEST] content QWK: 0.633\n","[BEST TEST] organization QWK: 0.564\n","[BEST TEST] word_choice QWK: 0.629\n","[BEST TEST] sentence_fluency QWK: 0.608\n","[BEST TEST] conventions QWK: 0.561\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 167s 175ms/step - loss: 0.0126 - val_loss: 0.0127\n","Epoch 49/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 49: Train Loss: 0.012550145387649536 || Val Loss: 0.012298996560275555\n","Epoch 49 completed in 152.864 seconds\n","53/53 [==============================] - 3s 58ms/step\n","56/56 [==============================] - 3s 61ms/step\n","CURRENT EPOCH: 49\n","[DEV] AVG QWK: 0.697\n","[DEV] score QWK: 0.759\n","[DEV] content QWK: 0.668\n","[DEV] organization QWK: 0.75\n","[DEV] word_choice QWK: 0.694\n","[DEV] sentence_fluency QWK: 0.667\n","[DEV] conventions QWK: 0.758\n","[DEV] prompt_adherence QWK: 0.653\n","[DEV] language QWK: 0.654\n","[DEV] narrativity QWK: 0.671\n","------------------------\n","[TEST] AVG QWK: 0.642\n","[TEST] score QWK: 0.815\n","[TEST] content QWK: 0.629\n","[TEST] organization QWK: 0.596\n","[TEST] word_choice QWK: 0.631\n","[TEST] sentence_fluency QWK: 0.608\n","[TEST] conventions QWK: 0.57\n","------------------------\n","[BEST TEST] AVG QWK: 0.635, {epoch}: 47\n","[BEST TEST] score QWK: 0.817\n","[BEST TEST] content QWK: 0.633\n","[BEST TEST] organization QWK: 0.564\n","[BEST TEST] word_choice QWK: 0.629\n","[BEST TEST] sentence_fluency QWK: 0.608\n","[BEST TEST] conventions QWK: 0.561\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 163s 171ms/step - loss: 0.0126 - val_loss: 0.0123\n","Epoch 50/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 50: Train Loss: 0.012554475106298923 || Val Loss: 0.012316600419580936\n","Epoch 50 completed in 143.518 seconds\n","53/53 [==============================] - 3s 58ms/step\n","56/56 [==============================] - 3s 59ms/step\n","CURRENT EPOCH: 50\n","[DEV] AVG QWK: 0.699\n","[DEV] score QWK: 0.761\n","[DEV] content QWK: 0.674\n","[DEV] organization QWK: 0.75\n","[DEV] word_choice QWK: 0.691\n","[DEV] sentence_fluency QWK: 0.671\n","[DEV] conventions QWK: 0.761\n","[DEV] prompt_adherence QWK: 0.656\n","[DEV] language QWK: 0.657\n","[DEV] narrativity QWK: 0.674\n","------------------------\n","[TEST] AVG QWK: 0.634\n","[TEST] score QWK: 0.815\n","[TEST] content QWK: 0.616\n","[TEST] organization QWK: 0.579\n","[TEST] word_choice QWK: 0.63\n","[TEST] sentence_fluency QWK: 0.601\n","[TEST] conventions QWK: 0.561\n","------------------------\n","[BEST TEST] AVG QWK: 0.634, {epoch}: 50\n","[BEST TEST] score QWK: 0.815\n","[BEST TEST] content QWK: 0.616\n","[BEST TEST] organization QWK: 0.579\n","[BEST TEST] word_choice QWK: 0.63\n","[BEST TEST] sentence_fluency QWK: 0.601\n","[BEST TEST] conventions QWK: 0.561\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 157s 165ms/step - loss: 0.0126 - val_loss: 0.0123\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7fee0072dea0>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# T4로 재개된 에포크(27~)\n","# Check if there is a latest checkpoint\n","initial_epoch = 0\n","load = True\n","if latest_checkpoint and load:\n","    print(f'Loading weights from {latest_checkpoint}')\n","    model.load_weights(latest_checkpoint)\n","    initial_epoch = int(latest_checkpoint.split('_')[-1].split('.')[0]) if latest_checkpoint else 0\n","else:\n","    print('No latest checkpoint found. Starting from scratch.')\n","\n","# 모델 학습 코드\n","model.fit(\n","    train_features_list,\n","    Y_train,\n","    batch_size=batch_size,\n","    epochs=50, # 적절한 에포크 수로 설정\n","    verbose=1,\n","    shuffle=True,\n","    validation_data=(dev_features_list, Y_dev),\n","    callbacks=[custom_hist, checkpoint],\n","    initial_epoch=initial_epoch  # 학습을 재개할 에포크\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWlYW8lCOoEA","executionInfo":{"status":"ok","timestamp":1717146654579,"user_tz":-540,"elapsed":3676488,"user":{"displayName":"나인호","userId":"08373838400323353884"}},"outputId":"d21c91e9-3fd7-4807-ba41-3340b95a0115"},"id":"rWlYW8lCOoEA","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading weights from Checkpoint/bestmodel_epoch_26.h5\n","Epoch 27/50\n","trait num:  9\n","trait num:  9\n","952/952 [==============================] - ETA: 0s - loss: 0.0127trait num:  9\n","Epoch 27: Train Loss: 0.012731757946312428 || Val Loss: 0.012677364982664585\n","Epoch 27 completed in 260.352 seconds\n","53/53 [==============================] - 4s 66ms/step\n","56/56 [==============================] - 3s 53ms/step\n","CURRENT EPOCH: 27\n","[DEV] AVG QWK: 0.689\n","[DEV] score QWK: 0.756\n","[DEV] content QWK: 0.665\n","[DEV] organization QWK: 0.736\n","[DEV] word_choice QWK: 0.677\n","[DEV] sentence_fluency QWK: 0.658\n","[DEV] conventions QWK: 0.745\n","[DEV] prompt_adherence QWK: 0.648\n","[DEV] language QWK: 0.653\n","[DEV] narrativity QWK: 0.664\n","------------------------\n","[TEST] AVG QWK: 0.649\n","[TEST] score QWK: 0.821\n","[TEST] content QWK: 0.627\n","[TEST] organization QWK: 0.596\n","[TEST] word_choice QWK: 0.641\n","[TEST] sentence_fluency QWK: 0.618\n","[TEST] conventions QWK: 0.591\n","------------------------\n","[BEST TEST] AVG QWK: 0.649, {epoch}: 27\n","[BEST TEST] score QWK: 0.821\n","[BEST TEST] content QWK: 0.627\n","[BEST TEST] organization QWK: 0.596\n","[BEST TEST] word_choice QWK: 0.641\n","[BEST TEST] sentence_fluency QWK: 0.618\n","[BEST TEST] conventions QWK: 0.591\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 268s 178ms/step - loss: 0.0127 - val_loss: 0.0127\n","Epoch 28/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 28: Train Loss: 0.012729078531265259 || Val Loss: 0.012512481771409512\n","Epoch 28 completed in 135.843 seconds\n","53/53 [==============================] - 3s 54ms/step\n","56/56 [==============================] - 4s 64ms/step\n","CURRENT EPOCH: 28\n","[DEV] AVG QWK: 0.693\n","[DEV] score QWK: 0.761\n","[DEV] content QWK: 0.672\n","[DEV] organization QWK: 0.742\n","[DEV] word_choice QWK: 0.677\n","[DEV] sentence_fluency QWK: 0.661\n","[DEV] conventions QWK: 0.748\n","[DEV] prompt_adherence QWK: 0.652\n","[DEV] language QWK: 0.657\n","[DEV] narrativity QWK: 0.671\n","------------------------\n","[TEST] AVG QWK: 0.654\n","[TEST] score QWK: 0.823\n","[TEST] content QWK: 0.634\n","[TEST] organization QWK: 0.61\n","[TEST] word_choice QWK: 0.642\n","[TEST] sentence_fluency QWK: 0.62\n","[TEST] conventions QWK: 0.596\n","------------------------\n","[BEST TEST] AVG QWK: 0.654, {epoch}: 28\n","[BEST TEST] score QWK: 0.823\n","[BEST TEST] content QWK: 0.634\n","[BEST TEST] organization QWK: 0.61\n","[BEST TEST] word_choice QWK: 0.642\n","[BEST TEST] sentence_fluency QWK: 0.62\n","[BEST TEST] conventions QWK: 0.596\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 147s 155ms/step - loss: 0.0127 - val_loss: 0.0125\n","Epoch 29/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 29: Train Loss: 0.012711144983768463 || Val Loss: 0.0124755147844553\n","Epoch 29 completed in 140.198 seconds\n","53/53 [==============================] - 3s 55ms/step\n","56/56 [==============================] - 3s 56ms/step\n","CURRENT EPOCH: 29\n","[DEV] AVG QWK: 0.693\n","[DEV] score QWK: 0.759\n","[DEV] content QWK: 0.671\n","[DEV] organization QWK: 0.746\n","[DEV] word_choice QWK: 0.683\n","[DEV] sentence_fluency QWK: 0.653\n","[DEV] conventions QWK: 0.752\n","[DEV] prompt_adherence QWK: 0.65\n","[DEV] language QWK: 0.656\n","[DEV] narrativity QWK: 0.67\n","------------------------\n","[TEST] AVG QWK: 0.646\n","[TEST] score QWK: 0.815\n","[TEST] content QWK: 0.632\n","[TEST] organization QWK: 0.607\n","[TEST] word_choice QWK: 0.631\n","[TEST] sentence_fluency QWK: 0.597\n","[TEST] conventions QWK: 0.598\n","------------------------\n","[BEST TEST] AVG QWK: 0.654, {epoch}: 28\n","[BEST TEST] score QWK: 0.823\n","[BEST TEST] content QWK: 0.634\n","[BEST TEST] organization QWK: 0.61\n","[BEST TEST] word_choice QWK: 0.642\n","[BEST TEST] sentence_fluency QWK: 0.62\n","[BEST TEST] conventions QWK: 0.596\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 149s 157ms/step - loss: 0.0127 - val_loss: 0.0125\n","Epoch 30/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 30: Train Loss: 0.012696368619799614 || Val Loss: 0.012386327609419823\n","Epoch 30 completed in 138.111 seconds\n","53/53 [==============================] - 3s 61ms/step\n","56/56 [==============================] - 3s 55ms/step\n","CURRENT EPOCH: 30\n","[DEV] AVG QWK: 0.695\n","[DEV] score QWK: 0.76\n","[DEV] content QWK: 0.673\n","[DEV] organization QWK: 0.746\n","[DEV] word_choice QWK: 0.684\n","[DEV] sentence_fluency QWK: 0.663\n","[DEV] conventions QWK: 0.753\n","[DEV] prompt_adherence QWK: 0.652\n","[DEV] language QWK: 0.653\n","[DEV] narrativity QWK: 0.67\n","------------------------\n","[TEST] AVG QWK: 0.652\n","[TEST] score QWK: 0.819\n","[TEST] content QWK: 0.641\n","[TEST] organization QWK: 0.604\n","[TEST] word_choice QWK: 0.632\n","[TEST] sentence_fluency QWK: 0.618\n","[TEST] conventions QWK: 0.598\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 30\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.641\n","[BEST TEST] organization QWK: 0.604\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.618\n","[BEST TEST] conventions QWK: 0.598\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 150s 157ms/step - loss: 0.0127 - val_loss: 0.0124\n","Epoch 31/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 31: Train Loss: 0.012702166102826595 || Val Loss: 0.012644442729651928\n","Epoch 31 completed in 138.404 seconds\n","53/53 [==============================] - 3s 55ms/step\n","56/56 [==============================] - 3s 54ms/step\n","CURRENT EPOCH: 31\n","[DEV] AVG QWK: 0.687\n","[DEV] score QWK: 0.758\n","[DEV] content QWK: 0.658\n","[DEV] organization QWK: 0.743\n","[DEV] word_choice QWK: 0.686\n","[DEV] sentence_fluency QWK: 0.664\n","[DEV] conventions QWK: 0.754\n","[DEV] prompt_adherence QWK: 0.634\n","[DEV] language QWK: 0.636\n","[DEV] narrativity QWK: 0.652\n","------------------------\n","[TEST] AVG QWK: 0.649\n","[TEST] score QWK: 0.821\n","[TEST] content QWK: 0.635\n","[TEST] organization QWK: 0.586\n","[TEST] word_choice QWK: 0.638\n","[TEST] sentence_fluency QWK: 0.62\n","[TEST] conventions QWK: 0.592\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 30\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.641\n","[BEST TEST] organization QWK: 0.604\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.618\n","[BEST TEST] conventions QWK: 0.598\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 148s 155ms/step - loss: 0.0127 - val_loss: 0.0126\n","Epoch 32/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 32: Train Loss: 0.01268288679420948 || Val Loss: 0.01239586528390646\n","Epoch 32 completed in 137.078 seconds\n","53/53 [==============================] - 3s 64ms/step\n","56/56 [==============================] - 4s 73ms/step\n","CURRENT EPOCH: 32\n","[DEV] AVG QWK: 0.693\n","[DEV] score QWK: 0.759\n","[DEV] content QWK: 0.666\n","[DEV] organization QWK: 0.746\n","[DEV] word_choice QWK: 0.681\n","[DEV] sentence_fluency QWK: 0.658\n","[DEV] conventions QWK: 0.754\n","[DEV] prompt_adherence QWK: 0.651\n","[DEV] language QWK: 0.653\n","[DEV] narrativity QWK: 0.668\n","------------------------\n","[TEST] AVG QWK: 0.645\n","[TEST] score QWK: 0.819\n","[TEST] content QWK: 0.634\n","[TEST] organization QWK: 0.602\n","[TEST] word_choice QWK: 0.634\n","[TEST] sentence_fluency QWK: 0.593\n","[TEST] conventions QWK: 0.588\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 30\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.641\n","[BEST TEST] organization QWK: 0.604\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.618\n","[BEST TEST] conventions QWK: 0.598\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 147s 154ms/step - loss: 0.0127 - val_loss: 0.0124\n","Epoch 33/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 33: Train Loss: 0.012663931585848331 || Val Loss: 0.01259099505841732\n","Epoch 33 completed in 137.515 seconds\n","53/53 [==============================] - 3s 55ms/step\n","56/56 [==============================] - 3s 55ms/step\n","CURRENT EPOCH: 33\n","[DEV] AVG QWK: 0.687\n","[DEV] score QWK: 0.753\n","[DEV] content QWK: 0.667\n","[DEV] organization QWK: 0.726\n","[DEV] word_choice QWK: 0.67\n","[DEV] sentence_fluency QWK: 0.642\n","[DEV] conventions QWK: 0.75\n","[DEV] prompt_adherence QWK: 0.653\n","[DEV] language QWK: 0.657\n","[DEV] narrativity QWK: 0.665\n","------------------------\n","[TEST] AVG QWK: 0.643\n","[TEST] score QWK: 0.791\n","[TEST] content QWK: 0.65\n","[TEST] organization QWK: 0.589\n","[TEST] word_choice QWK: 0.635\n","[TEST] sentence_fluency QWK: 0.601\n","[TEST] conventions QWK: 0.594\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 30\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.641\n","[BEST TEST] organization QWK: 0.604\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.618\n","[BEST TEST] conventions QWK: 0.598\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 147s 154ms/step - loss: 0.0127 - val_loss: 0.0126\n","Epoch 34/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 34: Train Loss: 0.012655995786190033 || Val Loss: 0.01251653116196394\n","Epoch 34 completed in 137.756 seconds\n","53/53 [==============================] - 3s 55ms/step\n","56/56 [==============================] - 4s 75ms/step\n","CURRENT EPOCH: 34\n","[DEV] AVG QWK: 0.69\n","[DEV] score QWK: 0.751\n","[DEV] content QWK: 0.67\n","[DEV] organization QWK: 0.736\n","[DEV] word_choice QWK: 0.685\n","[DEV] sentence_fluency QWK: 0.66\n","[DEV] conventions QWK: 0.752\n","[DEV] prompt_adherence QWK: 0.644\n","[DEV] language QWK: 0.643\n","[DEV] narrativity QWK: 0.665\n","------------------------\n","[TEST] AVG QWK: 0.64\n","[TEST] score QWK: 0.797\n","[TEST] content QWK: 0.639\n","[TEST] organization QWK: 0.576\n","[TEST] word_choice QWK: 0.628\n","[TEST] sentence_fluency QWK: 0.602\n","[TEST] conventions QWK: 0.595\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 30\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.641\n","[BEST TEST] organization QWK: 0.604\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.618\n","[BEST TEST] conventions QWK: 0.598\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 146s 153ms/step - loss: 0.0127 - val_loss: 0.0125\n","Epoch 35/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0127Epoch 35: Train Loss: 0.01265672966837883 || Val Loss: 0.012409080751240253\n","Epoch 35 completed in 135.230 seconds\n","53/53 [==============================] - 4s 77ms/step\n","56/56 [==============================] - 3s 55ms/step\n","CURRENT EPOCH: 35\n","[DEV] AVG QWK: 0.694\n","[DEV] score QWK: 0.756\n","[DEV] content QWK: 0.666\n","[DEV] organization QWK: 0.744\n","[DEV] word_choice QWK: 0.685\n","[DEV] sentence_fluency QWK: 0.663\n","[DEV] conventions QWK: 0.753\n","[DEV] prompt_adherence QWK: 0.652\n","[DEV] language QWK: 0.655\n","[DEV] narrativity QWK: 0.669\n","------------------------\n","[TEST] AVG QWK: 0.639\n","[TEST] score QWK: 0.813\n","[TEST] content QWK: 0.622\n","[TEST] organization QWK: 0.586\n","[TEST] word_choice QWK: 0.627\n","[TEST] sentence_fluency QWK: 0.613\n","[TEST] conventions QWK: 0.574\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 30\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.641\n","[BEST TEST] organization QWK: 0.604\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.618\n","[BEST TEST] conventions QWK: 0.598\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 145s 153ms/step - loss: 0.0127 - val_loss: 0.0124\n","Epoch 36/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 36: Train Loss: 0.012635990045964718 || Val Loss: 0.012560262344777584\n","Epoch 36 completed in 138.124 seconds\n","53/53 [==============================] - 3s 54ms/step\n","56/56 [==============================] - 4s 68ms/step\n","CURRENT EPOCH: 36\n","[DEV] AVG QWK: 0.69\n","[DEV] score QWK: 0.761\n","[DEV] content QWK: 0.663\n","[DEV] organization QWK: 0.748\n","[DEV] word_choice QWK: 0.689\n","[DEV] sentence_fluency QWK: 0.664\n","[DEV] conventions QWK: 0.747\n","[DEV] prompt_adherence QWK: 0.639\n","[DEV] language QWK: 0.647\n","[DEV] narrativity QWK: 0.653\n","------------------------\n","[TEST] AVG QWK: 0.647\n","[TEST] score QWK: 0.82\n","[TEST] content QWK: 0.648\n","[TEST] organization QWK: 0.603\n","[TEST] word_choice QWK: 0.633\n","[TEST] sentence_fluency QWK: 0.605\n","[TEST] conventions QWK: 0.571\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 30\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.641\n","[BEST TEST] organization QWK: 0.604\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.618\n","[BEST TEST] conventions QWK: 0.598\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 148s 156ms/step - loss: 0.0126 - val_loss: 0.0126\n","Epoch 37/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 37: Train Loss: 0.012627776712179184 || Val Loss: 0.012506559491157532\n","Epoch 37 completed in 135.148 seconds\n","53/53 [==============================] - 4s 74ms/step\n","56/56 [==============================] - 3s 54ms/step\n","CURRENT EPOCH: 37\n","[DEV] AVG QWK: 0.692\n","[DEV] score QWK: 0.759\n","[DEV] content QWK: 0.669\n","[DEV] organization QWK: 0.746\n","[DEV] word_choice QWK: 0.674\n","[DEV] sentence_fluency QWK: 0.649\n","[DEV] conventions QWK: 0.757\n","[DEV] prompt_adherence QWK: 0.648\n","[DEV] language QWK: 0.656\n","[DEV] narrativity QWK: 0.673\n","------------------------\n","[TEST] AVG QWK: 0.643\n","[TEST] score QWK: 0.819\n","[TEST] content QWK: 0.626\n","[TEST] organization QWK: 0.597\n","[TEST] word_choice QWK: 0.632\n","[TEST] sentence_fluency QWK: 0.593\n","[TEST] conventions QWK: 0.593\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 30\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.641\n","[BEST TEST] organization QWK: 0.604\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.618\n","[BEST TEST] conventions QWK: 0.598\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 143s 150ms/step - loss: 0.0126 - val_loss: 0.0125\n","Epoch 38/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 38: Train Loss: 0.012611594051122665 || Val Loss: 0.012441029772162437\n","Epoch 38 completed in 137.021 seconds\n","53/53 [==============================] - 3s 54ms/step\n","56/56 [==============================] - 3s 54ms/step\n","CURRENT EPOCH: 38\n","[DEV] AVG QWK: 0.693\n","[DEV] score QWK: 0.754\n","[DEV] content QWK: 0.668\n","[DEV] organization QWK: 0.745\n","[DEV] word_choice QWK: 0.687\n","[DEV] sentence_fluency QWK: 0.663\n","[DEV] conventions QWK: 0.755\n","[DEV] prompt_adherence QWK: 0.644\n","[DEV] language QWK: 0.653\n","[DEV] narrativity QWK: 0.671\n","------------------------\n","[TEST] AVG QWK: 0.642\n","[TEST] score QWK: 0.791\n","[TEST] content QWK: 0.647\n","[TEST] organization QWK: 0.598\n","[TEST] word_choice QWK: 0.633\n","[TEST] sentence_fluency QWK: 0.604\n","[TEST] conventions QWK: 0.58\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 30\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.641\n","[BEST TEST] organization QWK: 0.604\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.618\n","[BEST TEST] conventions QWK: 0.598\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 144s 151ms/step - loss: 0.0126 - val_loss: 0.0124\n","Epoch 39/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 39: Train Loss: 0.012620989233255386 || Val Loss: 0.012449374422430992\n","Epoch 39 completed in 135.747 seconds\n","53/53 [==============================] - 3s 53ms/step\n","56/56 [==============================] - 4s 76ms/step\n","CURRENT EPOCH: 39\n","[DEV] AVG QWK: 0.691\n","[DEV] score QWK: 0.758\n","[DEV] content QWK: 0.662\n","[DEV] organization QWK: 0.746\n","[DEV] word_choice QWK: 0.686\n","[DEV] sentence_fluency QWK: 0.668\n","[DEV] conventions QWK: 0.759\n","[DEV] prompt_adherence QWK: 0.644\n","[DEV] language QWK: 0.639\n","[DEV] narrativity QWK: 0.658\n","------------------------\n","[TEST] AVG QWK: 0.648\n","[TEST] score QWK: 0.818\n","[TEST] content QWK: 0.638\n","[TEST] organization QWK: 0.598\n","[TEST] word_choice QWK: 0.629\n","[TEST] sentence_fluency QWK: 0.617\n","[TEST] conventions QWK: 0.589\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 30\n","[BEST TEST] score QWK: 0.819\n","[BEST TEST] content QWK: 0.641\n","[BEST TEST] organization QWK: 0.604\n","[BEST TEST] word_choice QWK: 0.632\n","[BEST TEST] sentence_fluency QWK: 0.618\n","[BEST TEST] conventions QWK: 0.598\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 146s 154ms/step - loss: 0.0126 - val_loss: 0.0124\n","Epoch 40/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 40: Train Loss: 0.012597678229212761 || Val Loss: 0.01235263142734766\n","Epoch 40 completed in 137.738 seconds\n","53/53 [==============================] - 3s 61ms/step\n","56/56 [==============================] - 3s 56ms/step\n","CURRENT EPOCH: 40\n","[DEV] AVG QWK: 0.695\n","[DEV] score QWK: 0.759\n","[DEV] content QWK: 0.669\n","[DEV] organization QWK: 0.743\n","[DEV] word_choice QWK: 0.683\n","[DEV] sentence_fluency QWK: 0.669\n","[DEV] conventions QWK: 0.756\n","[DEV] prompt_adherence QWK: 0.651\n","[DEV] language QWK: 0.655\n","[DEV] narrativity QWK: 0.671\n","------------------------\n","[TEST] AVG QWK: 0.641\n","[TEST] score QWK: 0.816\n","[TEST] content QWK: 0.617\n","[TEST] organization QWK: 0.58\n","[TEST] word_choice QWK: 0.634\n","[TEST] sentence_fluency QWK: 0.605\n","[TEST] conventions QWK: 0.594\n","------------------------\n","[BEST TEST] AVG QWK: 0.641, {epoch}: 40\n","[BEST TEST] score QWK: 0.816\n","[BEST TEST] content QWK: 0.617\n","[BEST TEST] organization QWK: 0.58\n","[BEST TEST] word_choice QWK: 0.634\n","[BEST TEST] sentence_fluency QWK: 0.605\n","[BEST TEST] conventions QWK: 0.594\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 147s 155ms/step - loss: 0.0126 - val_loss: 0.0124\n","Epoch 41/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 41: Train Loss: 0.012594164349138737 || Val Loss: 0.012364414520561695\n","Epoch 41 completed in 138.976 seconds\n","53/53 [==============================] - 3s 56ms/step\n","56/56 [==============================] - 3s 56ms/step\n","CURRENT EPOCH: 41\n","[DEV] AVG QWK: 0.697\n","[DEV] score QWK: 0.759\n","[DEV] content QWK: 0.673\n","[DEV] organization QWK: 0.746\n","[DEV] word_choice QWK: 0.686\n","[DEV] sentence_fluency QWK: 0.667\n","[DEV] conventions QWK: 0.759\n","[DEV] prompt_adherence QWK: 0.653\n","[DEV] language QWK: 0.658\n","[DEV] narrativity QWK: 0.674\n","------------------------\n","[TEST] AVG QWK: 0.643\n","[TEST] score QWK: 0.818\n","[TEST] content QWK: 0.62\n","[TEST] organization QWK: 0.595\n","[TEST] word_choice QWK: 0.635\n","[TEST] sentence_fluency QWK: 0.613\n","[TEST] conventions QWK: 0.58\n","------------------------\n","[BEST TEST] AVG QWK: 0.643, {epoch}: 41\n","[BEST TEST] score QWK: 0.818\n","[BEST TEST] content QWK: 0.62\n","[BEST TEST] organization QWK: 0.595\n","[BEST TEST] word_choice QWK: 0.635\n","[BEST TEST] sentence_fluency QWK: 0.613\n","[BEST TEST] conventions QWK: 0.58\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 148s 156ms/step - loss: 0.0126 - val_loss: 0.0124\n","Epoch 42/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 42: Train Loss: 0.012592384591698647 || Val Loss: 0.012322120368480682\n","Epoch 42 completed in 138.827 seconds\n","53/53 [==============================] - 4s 66ms/step\n","56/56 [==============================] - 3s 58ms/step\n","CURRENT EPOCH: 42\n","[DEV] AVG QWK: 0.698\n","[DEV] score QWK: 0.763\n","[DEV] content QWK: 0.675\n","[DEV] organization QWK: 0.746\n","[DEV] word_choice QWK: 0.691\n","[DEV] sentence_fluency QWK: 0.668\n","[DEV] conventions QWK: 0.755\n","[DEV] prompt_adherence QWK: 0.655\n","[DEV] language QWK: 0.659\n","[DEV] narrativity QWK: 0.671\n","------------------------\n","[TEST] AVG QWK: 0.64\n","[TEST] score QWK: 0.82\n","[TEST] content QWK: 0.621\n","[TEST] organization QWK: 0.573\n","[TEST] word_choice QWK: 0.637\n","[TEST] sentence_fluency QWK: 0.614\n","[TEST] conventions QWK: 0.572\n","------------------------\n","[BEST TEST] AVG QWK: 0.64, {epoch}: 42\n","[BEST TEST] score QWK: 0.82\n","[BEST TEST] content QWK: 0.621\n","[BEST TEST] organization QWK: 0.573\n","[BEST TEST] word_choice QWK: 0.637\n","[BEST TEST] sentence_fluency QWK: 0.614\n","[BEST TEST] conventions QWK: 0.572\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 150s 158ms/step - loss: 0.0126 - val_loss: 0.0123\n","Epoch 43/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 43: Train Loss: 0.012587657198309898 || Val Loss: 0.012391049414873123\n","Epoch 43 completed in 141.038 seconds\n","53/53 [==============================] - 4s 71ms/step\n","56/56 [==============================] - 3s 55ms/step\n","CURRENT EPOCH: 43\n","[DEV] AVG QWK: 0.697\n","[DEV] score QWK: 0.759\n","[DEV] content QWK: 0.669\n","[DEV] organization QWK: 0.751\n","[DEV] word_choice QWK: 0.692\n","[DEV] sentence_fluency QWK: 0.667\n","[DEV] conventions QWK: 0.759\n","[DEV] prompt_adherence QWK: 0.652\n","[DEV] language QWK: 0.658\n","[DEV] narrativity QWK: 0.665\n","------------------------\n","[TEST] AVG QWK: 0.639\n","[TEST] score QWK: 0.818\n","[TEST] content QWK: 0.632\n","[TEST] organization QWK: 0.579\n","[TEST] word_choice QWK: 0.631\n","[TEST] sentence_fluency QWK: 0.603\n","[TEST] conventions QWK: 0.569\n","------------------------\n","[BEST TEST] AVG QWK: 0.64, {epoch}: 42\n","[BEST TEST] score QWK: 0.82\n","[BEST TEST] content QWK: 0.621\n","[BEST TEST] organization QWK: 0.573\n","[BEST TEST] word_choice QWK: 0.637\n","[BEST TEST] sentence_fluency QWK: 0.614\n","[BEST TEST] conventions QWK: 0.572\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 150s 158ms/step - loss: 0.0126 - val_loss: 0.0124\n","Epoch 44/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 44: Train Loss: 0.01257595419883728 || Val Loss: 0.01230329554527998\n","Epoch 44 completed in 136.559 seconds\n","53/53 [==============================] - 3s 53ms/step\n","56/56 [==============================] - 3s 56ms/step\n","CURRENT EPOCH: 44\n","[DEV] AVG QWK: 0.695\n","[DEV] score QWK: 0.762\n","[DEV] content QWK: 0.673\n","[DEV] organization QWK: 0.749\n","[DEV] word_choice QWK: 0.683\n","[DEV] sentence_fluency QWK: 0.65\n","[DEV] conventions QWK: 0.758\n","[DEV] prompt_adherence QWK: 0.654\n","[DEV] language QWK: 0.658\n","[DEV] narrativity QWK: 0.673\n","------------------------\n","[TEST] AVG QWK: 0.638\n","[TEST] score QWK: 0.818\n","[TEST] content QWK: 0.622\n","[TEST] organization QWK: 0.586\n","[TEST] word_choice QWK: 0.623\n","[TEST] sentence_fluency QWK: 0.594\n","[TEST] conventions QWK: 0.587\n","------------------------\n","[BEST TEST] AVG QWK: 0.64, {epoch}: 42\n","[BEST TEST] score QWK: 0.82\n","[BEST TEST] content QWK: 0.621\n","[BEST TEST] organization QWK: 0.573\n","[BEST TEST] word_choice QWK: 0.637\n","[BEST TEST] sentence_fluency QWK: 0.614\n","[BEST TEST] conventions QWK: 0.572\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 146s 153ms/step - loss: 0.0126 - val_loss: 0.0123\n","Epoch 45/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 45: Train Loss: 0.012575704604387283 || Val Loss: 0.012306617572903633\n","Epoch 45 completed in 139.570 seconds\n","53/53 [==============================] - 4s 67ms/step\n","56/56 [==============================] - 4s 67ms/step\n","CURRENT EPOCH: 45\n","[DEV] AVG QWK: 0.698\n","[DEV] score QWK: 0.763\n","[DEV] content QWK: 0.671\n","[DEV] organization QWK: 0.75\n","[DEV] word_choice QWK: 0.692\n","[DEV] sentence_fluency QWK: 0.67\n","[DEV] conventions QWK: 0.753\n","[DEV] prompt_adherence QWK: 0.655\n","[DEV] language QWK: 0.657\n","[DEV] narrativity QWK: 0.669\n","------------------------\n","[TEST] AVG QWK: 0.643\n","[TEST] score QWK: 0.82\n","[TEST] content QWK: 0.638\n","[TEST] organization QWK: 0.592\n","[TEST] word_choice QWK: 0.632\n","[TEST] sentence_fluency QWK: 0.61\n","[TEST] conventions QWK: 0.564\n","------------------------\n","[BEST TEST] AVG QWK: 0.64, {epoch}: 42\n","[BEST TEST] score QWK: 0.82\n","[BEST TEST] content QWK: 0.621\n","[BEST TEST] organization QWK: 0.573\n","[BEST TEST] word_choice QWK: 0.637\n","[BEST TEST] sentence_fluency QWK: 0.614\n","[BEST TEST] conventions QWK: 0.572\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 148s 155ms/step - loss: 0.0126 - val_loss: 0.0123\n","Epoch 46/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 46: Train Loss: 0.012588136829435825 || Val Loss: 0.012301243841648102\n","Epoch 46 completed in 141.187 seconds\n","53/53 [==============================] - 3s 55ms/step\n","56/56 [==============================] - 3s 55ms/step\n","CURRENT EPOCH: 46\n","[DEV] AVG QWK: 0.695\n","[DEV] score QWK: 0.762\n","[DEV] content QWK: 0.672\n","[DEV] organization QWK: 0.745\n","[DEV] word_choice QWK: 0.677\n","[DEV] sentence_fluency QWK: 0.665\n","[DEV] conventions QWK: 0.758\n","[DEV] prompt_adherence QWK: 0.654\n","[DEV] language QWK: 0.654\n","[DEV] narrativity QWK: 0.668\n","------------------------\n","[TEST] AVG QWK: 0.643\n","[TEST] score QWK: 0.819\n","[TEST] content QWK: 0.62\n","[TEST] organization QWK: 0.595\n","[TEST] word_choice QWK: 0.629\n","[TEST] sentence_fluency QWK: 0.61\n","[TEST] conventions QWK: 0.586\n","------------------------\n","[BEST TEST] AVG QWK: 0.64, {epoch}: 42\n","[BEST TEST] score QWK: 0.82\n","[BEST TEST] content QWK: 0.621\n","[BEST TEST] organization QWK: 0.573\n","[BEST TEST] word_choice QWK: 0.637\n","[BEST TEST] sentence_fluency QWK: 0.614\n","[BEST TEST] conventions QWK: 0.572\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 148s 156ms/step - loss: 0.0126 - val_loss: 0.0123\n","Epoch 47/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 47: Train Loss: 0.012588674202561378 || Val Loss: 0.01244405098259449\n","Epoch 47 completed in 141.689 seconds\n","53/53 [==============================] - 4s 78ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 47\n","[DEV] AVG QWK: 0.691\n","[DEV] score QWK: 0.757\n","[DEV] content QWK: 0.669\n","[DEV] organization QWK: 0.747\n","[DEV] word_choice QWK: 0.653\n","[DEV] sentence_fluency QWK: 0.655\n","[DEV] conventions QWK: 0.754\n","[DEV] prompt_adherence QWK: 0.656\n","[DEV] language QWK: 0.661\n","[DEV] narrativity QWK: 0.672\n","------------------------\n","[TEST] AVG QWK: 0.641\n","[TEST] score QWK: 0.812\n","[TEST] content QWK: 0.634\n","[TEST] organization QWK: 0.594\n","[TEST] word_choice QWK: 0.614\n","[TEST] sentence_fluency QWK: 0.601\n","[TEST] conventions QWK: 0.588\n","------------------------\n","[BEST TEST] AVG QWK: 0.64, {epoch}: 42\n","[BEST TEST] score QWK: 0.82\n","[BEST TEST] content QWK: 0.621\n","[BEST TEST] organization QWK: 0.573\n","[BEST TEST] word_choice QWK: 0.637\n","[BEST TEST] sentence_fluency QWK: 0.614\n","[BEST TEST] conventions QWK: 0.572\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 153s 161ms/step - loss: 0.0126 - val_loss: 0.0124\n","Epoch 48/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0126Epoch 48: Train Loss: 0.01255748700350523 || Val Loss: 0.012387380003929138\n","Epoch 48 completed in 141.407 seconds\n","53/53 [==============================] - 3s 62ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 48\n","[DEV] AVG QWK: 0.694\n","[DEV] score QWK: 0.76\n","[DEV] content QWK: 0.674\n","[DEV] organization QWK: 0.749\n","[DEV] word_choice QWK: 0.688\n","[DEV] sentence_fluency QWK: 0.653\n","[DEV] conventions QWK: 0.754\n","[DEV] prompt_adherence QWK: 0.643\n","[DEV] language QWK: 0.657\n","[DEV] narrativity QWK: 0.673\n","------------------------\n","[TEST] AVG QWK: 0.629\n","[TEST] score QWK: 0.813\n","[TEST] content QWK: 0.617\n","[TEST] organization QWK: 0.583\n","[TEST] word_choice QWK: 0.623\n","[TEST] sentence_fluency QWK: 0.576\n","[TEST] conventions QWK: 0.561\n","------------------------\n","[BEST TEST] AVG QWK: 0.64, {epoch}: 42\n","[BEST TEST] score QWK: 0.82\n","[BEST TEST] content QWK: 0.621\n","[BEST TEST] organization QWK: 0.573\n","[BEST TEST] word_choice QWK: 0.637\n","[BEST TEST] sentence_fluency QWK: 0.614\n","[BEST TEST] conventions QWK: 0.572\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 151s 158ms/step - loss: 0.0126 - val_loss: 0.0124\n","Epoch 49/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0125Epoch 49: Train Loss: 0.012540975585579872 || Val Loss: 0.012346414849162102\n","Epoch 49 completed in 138.519 seconds\n","53/53 [==============================] - 3s 60ms/step\n","56/56 [==============================] - 4s 66ms/step\n","CURRENT EPOCH: 49\n","[DEV] AVG QWK: 0.699\n","[DEV] score QWK: 0.76\n","[DEV] content QWK: 0.676\n","[DEV] organization QWK: 0.745\n","[DEV] word_choice QWK: 0.685\n","[DEV] sentence_fluency QWK: 0.673\n","[DEV] conventions QWK: 0.76\n","[DEV] prompt_adherence QWK: 0.656\n","[DEV] language QWK: 0.659\n","[DEV] narrativity QWK: 0.673\n","------------------------\n","[TEST] AVG QWK: 0.64\n","[TEST] score QWK: 0.816\n","[TEST] content QWK: 0.625\n","[TEST] organization QWK: 0.589\n","[TEST] word_choice QWK: 0.628\n","[TEST] sentence_fluency QWK: 0.609\n","[TEST] conventions QWK: 0.575\n","------------------------\n","[BEST TEST] AVG QWK: 0.64, {epoch}: 49\n","[BEST TEST] score QWK: 0.816\n","[BEST TEST] content QWK: 0.625\n","[BEST TEST] organization QWK: 0.589\n","[BEST TEST] word_choice QWK: 0.628\n","[BEST TEST] sentence_fluency QWK: 0.609\n","[BEST TEST] conventions QWK: 0.575\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 150s 158ms/step - loss: 0.0125 - val_loss: 0.0123\n","Epoch 50/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0125Epoch 50: Train Loss: 0.012543356977403164 || Val Loss: 0.012316559441387653\n","Epoch 50 completed in 145.728 seconds\n","53/53 [==============================] - 3s 57ms/step\n","56/56 [==============================] - 3s 57ms/step\n","CURRENT EPOCH: 50\n","[DEV] AVG QWK: 0.698\n","[DEV] score QWK: 0.759\n","[DEV] content QWK: 0.673\n","[DEV] organization QWK: 0.752\n","[DEV] word_choice QWK: 0.691\n","[DEV] sentence_fluency QWK: 0.662\n","[DEV] conventions QWK: 0.761\n","[DEV] prompt_adherence QWK: 0.654\n","[DEV] language QWK: 0.653\n","[DEV] narrativity QWK: 0.672\n","------------------------\n","[TEST] AVG QWK: 0.638\n","[TEST] score QWK: 0.81\n","[TEST] content QWK: 0.617\n","[TEST] organization QWK: 0.589\n","[TEST] word_choice QWK: 0.627\n","[TEST] sentence_fluency QWK: 0.608\n","[TEST] conventions QWK: 0.577\n","------------------------\n","[BEST TEST] AVG QWK: 0.64, {epoch}: 49\n","[BEST TEST] score QWK: 0.816\n","[BEST TEST] content QWK: 0.625\n","[BEST TEST] organization QWK: 0.589\n","[BEST TEST] word_choice QWK: 0.628\n","[BEST TEST] sentence_fluency QWK: 0.609\n","[BEST TEST] conventions QWK: 0.575\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 153s 161ms/step - loss: 0.0125 - val_loss: 0.0123\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7c7d5b9456f0>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# CPU로 재개된 에포크(14~26)\n","# 일부러 학습이 완료됐던 14epoch이지만 비교를 위해 진행해보았으나,\n","# 값이 일부 다르게 나옴.\n","# Check if there is a latest checkpoint\n","initial_epoch = 0\n","load = True\n","if latest_checkpoint and load:\n","    print(f'Loading weights from {latest_checkpoint}')\n","    model.load_weights(latest_checkpoint)\n","    initial_epoch = int(latest_checkpoint.split('_')[-1].split('.')[0]) if latest_checkpoint else 0\n","else:\n","    print('No latest checkpoint found. Starting from scratch.')\n","\n","# 모델 학습 코드\n","model.fit(\n","    train_features_list,\n","    Y_train,\n","    batch_size=batch_size,\n","    epochs=50, # 적절한 에포크 수로 설정\n","    verbose=1,\n","    shuffle=True,\n","    validation_data=(dev_features_list, Y_dev),\n","    callbacks=[custom_hist, checkpoint],\n","    initial_epoch=initial_epoch  # 학습을 재개할 에포크\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RnM5kKW01qGc","outputId":"4979c615-a0e7-4a95-d536-32348d2ac07e"},"id":"RnM5kKW01qGc","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading weights from Checkpoint/bestmodel_epoch_13.h5\n","Epoch 14/50\n","trait num:  9\n","trait num:  9\n","952/952 [==============================] - ETA: 0s - loss: 0.0130trait num:  9\n","Epoch 14: Train Loss: 0.013030195608735085 || Val Loss: 0.012961349450051785\n","Epoch 14 completed in 1676.925 seconds\n","53/53 [==============================] - 92s 1s/step\n","56/56 [==============================] - 81s 1s/step\n","CURRENT EPOCH: 14\n","[DEV] AVG QWK: 0.679\n","[DEV] score QWK: 0.749\n","[DEV] content QWK: 0.654\n","[DEV] organization QWK: 0.725\n","[DEV] word_choice QWK: 0.664\n","[DEV] sentence_fluency QWK: 0.644\n","[DEV] conventions QWK: 0.733\n","[DEV] prompt_adherence QWK: 0.639\n","[DEV] language QWK: 0.644\n","[DEV] narrativity QWK: 0.655\n","------------------------\n","[TEST] AVG QWK: 0.656\n","[TEST] score QWK: 0.817\n","[TEST] content QWK: 0.645\n","[TEST] organization QWK: 0.618\n","[TEST] word_choice QWK: 0.64\n","[TEST] sentence_fluency QWK: 0.611\n","[TEST] conventions QWK: 0.606\n","------------------------\n","[BEST TEST] AVG QWK: 0.656, {epoch}: 14\n","[BEST TEST] score QWK: 0.817\n","[BEST TEST] content QWK: 0.645\n","[BEST TEST] organization QWK: 0.618\n","[BEST TEST] word_choice QWK: 0.64\n","[BEST TEST] sentence_fluency QWK: 0.611\n","[BEST TEST] conventions QWK: 0.606\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1852s 2s/step - loss: 0.0130 - val_loss: 0.0130\n","Epoch 15/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0130Epoch 15: Train Loss: 0.01300480030477047 || Val Loss: 0.012764033861458302\n","Epoch 15 completed in 1620.898 seconds\n","53/53 [==============================] - 80s 1s/step\n","56/56 [==============================] - 85s 2s/step\n","CURRENT EPOCH: 15\n","[DEV] AVG QWK: 0.683\n","[DEV] score QWK: 0.756\n","[DEV] content QWK: 0.664\n","[DEV] organization QWK: 0.732\n","[DEV] word_choice QWK: 0.663\n","[DEV] sentence_fluency QWK: 0.645\n","[DEV] conventions QWK: 0.736\n","[DEV] prompt_adherence QWK: 0.644\n","[DEV] language QWK: 0.648\n","[DEV] narrativity QWK: 0.663\n","------------------------\n","[TEST] AVG QWK: 0.658\n","[TEST] score QWK: 0.816\n","[TEST] content QWK: 0.655\n","[TEST] organization QWK: 0.617\n","[TEST] word_choice QWK: 0.644\n","[TEST] sentence_fluency QWK: 0.613\n","[TEST] conventions QWK: 0.602\n","------------------------\n","[BEST TEST] AVG QWK: 0.658, {epoch}: 15\n","[BEST TEST] score QWK: 0.816\n","[BEST TEST] content QWK: 0.655\n","[BEST TEST] organization QWK: 0.617\n","[BEST TEST] word_choice QWK: 0.644\n","[BEST TEST] sentence_fluency QWK: 0.613\n","[BEST TEST] conventions QWK: 0.602\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1847s 2s/step - loss: 0.0130 - val_loss: 0.0128\n","Epoch 16/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0130Epoch 16: Train Loss: 0.012964775785803795 || Val Loss: 0.012698311358690262\n","Epoch 16 completed in 1607.712 seconds\n","53/53 [==============================] - 79s 1s/step\n","56/56 [==============================] - 89s 2s/step\n","CURRENT EPOCH: 16\n","[DEV] AVG QWK: 0.684\n","[DEV] score QWK: 0.753\n","[DEV] content QWK: 0.662\n","[DEV] organization QWK: 0.737\n","[DEV] word_choice QWK: 0.67\n","[DEV] sentence_fluency QWK: 0.636\n","[DEV] conventions QWK: 0.742\n","[DEV] prompt_adherence QWK: 0.644\n","[DEV] language QWK: 0.649\n","[DEV] narrativity QWK: 0.662\n","------------------------\n","[TEST] AVG QWK: 0.647\n","[TEST] score QWK: 0.794\n","[TEST] content QWK: 0.652\n","[TEST] organization QWK: 0.606\n","[TEST] word_choice QWK: 0.641\n","[TEST] sentence_fluency QWK: 0.589\n","[TEST] conventions QWK: 0.598\n","------------------------\n","[BEST TEST] AVG QWK: 0.647, {epoch}: 16\n","[BEST TEST] score QWK: 0.794\n","[BEST TEST] content QWK: 0.652\n","[BEST TEST] organization QWK: 0.606\n","[BEST TEST] word_choice QWK: 0.641\n","[BEST TEST] sentence_fluency QWK: 0.589\n","[BEST TEST] conventions QWK: 0.598\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1833s 2s/step - loss: 0.0130 - val_loss: 0.0127\n","Epoch 17/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0129Epoch 17: Train Loss: 0.01293492317199707 || Val Loss: 0.012594752013683319\n","Epoch 17 completed in 1611.551 seconds\n","53/53 [==============================] - 77s 1s/step\n","56/56 [==============================] - 84s 1s/step\n","CURRENT EPOCH: 17\n","[DEV] AVG QWK: 0.687\n","[DEV] score QWK: 0.756\n","[DEV] content QWK: 0.665\n","[DEV] organization QWK: 0.738\n","[DEV] word_choice QWK: 0.672\n","[DEV] sentence_fluency QWK: 0.651\n","[DEV] conventions QWK: 0.742\n","[DEV] prompt_adherence QWK: 0.646\n","[DEV] language QWK: 0.646\n","[DEV] narrativity QWK: 0.663\n","------------------------\n","[TEST] AVG QWK: 0.652\n","[TEST] score QWK: 0.806\n","[TEST] content QWK: 0.652\n","[TEST] organization QWK: 0.607\n","[TEST] word_choice QWK: 0.644\n","[TEST] sentence_fluency QWK: 0.608\n","[TEST] conventions QWK: 0.595\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 17\n","[BEST TEST] score QWK: 0.806\n","[BEST TEST] content QWK: 0.652\n","[BEST TEST] organization QWK: 0.607\n","[BEST TEST] word_choice QWK: 0.644\n","[BEST TEST] sentence_fluency QWK: 0.608\n","[BEST TEST] conventions QWK: 0.595\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1832s 2s/step - loss: 0.0129 - val_loss: 0.0126\n","Epoch 18/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0129Epoch 18: Train Loss: 0.012923108413815498 || Val Loss: 0.01283105369657278\n","Epoch 18 completed in 1547.035 seconds\n","53/53 [==============================] - 80s 2s/step\n","56/56 [==============================] - 85s 2s/step\n","CURRENT EPOCH: 18\n","[DEV] AVG QWK: 0.68\n","[DEV] score QWK: 0.754\n","[DEV] content QWK: 0.651\n","[DEV] organization QWK: 0.735\n","[DEV] word_choice QWK: 0.677\n","[DEV] sentence_fluency QWK: 0.651\n","[DEV] conventions QWK: 0.745\n","[DEV] prompt_adherence QWK: 0.629\n","[DEV] language QWK: 0.63\n","[DEV] narrativity QWK: 0.646\n","------------------------\n","[TEST] AVG QWK: 0.65\n","[TEST] score QWK: 0.812\n","[TEST] content QWK: 0.633\n","[TEST] organization QWK: 0.608\n","[TEST] word_choice QWK: 0.642\n","[TEST] sentence_fluency QWK: 0.605\n","[TEST] conventions QWK: 0.601\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 17\n","[BEST TEST] score QWK: 0.806\n","[BEST TEST] content QWK: 0.652\n","[BEST TEST] organization QWK: 0.607\n","[BEST TEST] word_choice QWK: 0.644\n","[BEST TEST] sentence_fluency QWK: 0.608\n","[BEST TEST] conventions QWK: 0.595\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1772s 2s/step - loss: 0.0129 - val_loss: 0.0128\n","Epoch 19/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0129Epoch 19: Train Loss: 0.012892371043562889 || Val Loss: 0.012576543726027012\n","Epoch 19 completed in 1596.895 seconds\n","53/53 [==============================] - 72s 1s/step\n","56/56 [==============================] - 79s 1s/step\n","CURRENT EPOCH: 19\n","[DEV] AVG QWK: 0.686\n","[DEV] score QWK: 0.755\n","[DEV] content QWK: 0.659\n","[DEV] organization QWK: 0.74\n","[DEV] word_choice QWK: 0.671\n","[DEV] sentence_fluency QWK: 0.648\n","[DEV] conventions QWK: 0.745\n","[DEV] prompt_adherence QWK: 0.645\n","[DEV] language QWK: 0.647\n","[DEV] narrativity QWK: 0.662\n","------------------------\n","[TEST] AVG QWK: 0.652\n","[TEST] score QWK: 0.808\n","[TEST] content QWK: 0.648\n","[TEST] organization QWK: 0.61\n","[TEST] word_choice QWK: 0.64\n","[TEST] sentence_fluency QWK: 0.604\n","[TEST] conventions QWK: 0.602\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 17\n","[BEST TEST] score QWK: 0.806\n","[BEST TEST] content QWK: 0.652\n","[BEST TEST] organization QWK: 0.607\n","[BEST TEST] word_choice QWK: 0.644\n","[BEST TEST] sentence_fluency QWK: 0.608\n","[BEST TEST] conventions QWK: 0.595\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1762s 2s/step - loss: 0.0129 - val_loss: 0.0126\n","Epoch 20/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0129Epoch 20: Train Loss: 0.0128587381914258 || Val Loss: 0.012761292979121208\n","Epoch 20 completed in 1506.760 seconds\n","53/53 [==============================] - 72s 1s/step\n","56/56 [==============================] - 82s 1s/step\n","CURRENT EPOCH: 20\n","[DEV] AVG QWK: 0.679\n","[DEV] score QWK: 0.749\n","[DEV] content QWK: 0.66\n","[DEV] organization QWK: 0.718\n","[DEV] word_choice QWK: 0.659\n","[DEV] sentence_fluency QWK: 0.63\n","[DEV] conventions QWK: 0.741\n","[DEV] prompt_adherence QWK: 0.647\n","[DEV] language QWK: 0.651\n","[DEV] narrativity QWK: 0.659\n","------------------------\n","[TEST] AVG QWK: 0.63\n","[TEST] score QWK: 0.763\n","[TEST] content QWK: 0.651\n","[TEST] organization QWK: 0.58\n","[TEST] word_choice QWK: 0.614\n","[TEST] sentence_fluency QWK: 0.584\n","[TEST] conventions QWK: 0.585\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 17\n","[BEST TEST] score QWK: 0.806\n","[BEST TEST] content QWK: 0.652\n","[BEST TEST] organization QWK: 0.607\n","[BEST TEST] word_choice QWK: 0.644\n","[BEST TEST] sentence_fluency QWK: 0.608\n","[BEST TEST] conventions QWK: 0.595\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1723s 2s/step - loss: 0.0129 - val_loss: 0.0128\n","Epoch 21/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0128Epoch 21: Train Loss: 0.012839611619710922 || Val Loss: 0.012677808292210102\n","Epoch 21 completed in 1495.197 seconds\n","53/53 [==============================] - 74s 1s/step\n","56/56 [==============================] - 79s 1s/step\n","CURRENT EPOCH: 21\n","[DEV] AVG QWK: 0.683\n","[DEV] score QWK: 0.747\n","[DEV] content QWK: 0.664\n","[DEV] organization QWK: 0.729\n","[DEV] word_choice QWK: 0.675\n","[DEV] sentence_fluency QWK: 0.648\n","[DEV] conventions QWK: 0.744\n","[DEV] prompt_adherence QWK: 0.64\n","[DEV] language QWK: 0.637\n","[DEV] narrativity QWK: 0.661\n","------------------------\n","[TEST] AVG QWK: 0.647\n","[TEST] score QWK: 0.77\n","[TEST] content QWK: 0.654\n","[TEST] organization QWK: 0.595\n","[TEST] word_choice QWK: 0.644\n","[TEST] sentence_fluency QWK: 0.619\n","[TEST] conventions QWK: 0.598\n","------------------------\n","[BEST TEST] AVG QWK: 0.652, {epoch}: 17\n","[BEST TEST] score QWK: 0.806\n","[BEST TEST] content QWK: 0.652\n","[BEST TEST] organization QWK: 0.607\n","[BEST TEST] word_choice QWK: 0.644\n","[BEST TEST] sentence_fluency QWK: 0.608\n","[BEST TEST] conventions QWK: 0.595\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1657s 2s/step - loss: 0.0128 - val_loss: 0.0127\n","Epoch 22/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0128Epoch 22: Train Loss: 0.012828774750232697 || Val Loss: 0.01256744097918272\n","Epoch 22 completed in 1554.724 seconds\n","53/53 [==============================] - 78s 1s/step\n","56/56 [==============================] - 74s 1s/step\n","CURRENT EPOCH: 22\n","[DEV] AVG QWK: 0.687\n","[DEV] score QWK: 0.752\n","[DEV] content QWK: 0.66\n","[DEV] organization QWK: 0.738\n","[DEV] word_choice QWK: 0.676\n","[DEV] sentence_fluency QWK: 0.655\n","[DEV] conventions QWK: 0.745\n","[DEV] prompt_adherence QWK: 0.647\n","[DEV] language QWK: 0.65\n","[DEV] narrativity QWK: 0.664\n","------------------------\n","[TEST] AVG QWK: 0.646\n","[TEST] score QWK: 0.804\n","[TEST] content QWK: 0.637\n","[TEST] organization QWK: 0.603\n","[TEST] word_choice QWK: 0.633\n","[TEST] sentence_fluency QWK: 0.602\n","[TEST] conventions QWK: 0.596\n","------------------------\n","[BEST TEST] AVG QWK: 0.646, {epoch}: 22\n","[BEST TEST] score QWK: 0.804\n","[BEST TEST] content QWK: 0.637\n","[BEST TEST] organization QWK: 0.603\n","[BEST TEST] word_choice QWK: 0.633\n","[BEST TEST] sentence_fluency QWK: 0.602\n","[BEST TEST] conventions QWK: 0.596\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1712s 2s/step - loss: 0.0128 - val_loss: 0.0126\n","Epoch 23/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0128Epoch 23: Train Loss: 0.012798194773495197 || Val Loss: 0.012712100520730019\n","Epoch 23 completed in 1553.708 seconds\n","53/53 [==============================] - 72s 1s/step\n","56/56 [==============================] - 82s 1s/step\n","CURRENT EPOCH: 23\n","[DEV] AVG QWK: 0.684\n","[DEV] score QWK: 0.757\n","[DEV] content QWK: 0.657\n","[DEV] organization QWK: 0.743\n","[DEV] word_choice QWK: 0.68\n","[DEV] sentence_fluency QWK: 0.654\n","[DEV] conventions QWK: 0.74\n","[DEV] prompt_adherence QWK: 0.633\n","[DEV] language QWK: 0.641\n","[DEV] narrativity QWK: 0.647\n","------------------------\n","[TEST] AVG QWK: 0.649\n","[TEST] score QWK: 0.822\n","[TEST] content QWK: 0.641\n","[TEST] organization QWK: 0.611\n","[TEST] word_choice QWK: 0.632\n","[TEST] sentence_fluency QWK: 0.597\n","[TEST] conventions QWK: 0.588\n","------------------------\n","[BEST TEST] AVG QWK: 0.646, {epoch}: 22\n","[BEST TEST] score QWK: 0.804\n","[BEST TEST] content QWK: 0.637\n","[BEST TEST] organization QWK: 0.603\n","[BEST TEST] word_choice QWK: 0.633\n","[BEST TEST] sentence_fluency QWK: 0.602\n","[BEST TEST] conventions QWK: 0.596\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1709s 2s/step - loss: 0.0128 - val_loss: 0.0127\n","Epoch 24/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0128Epoch 24: Train Loss: 0.012782074511051178 || Val Loss: 0.012650721706449986\n","Epoch 24 completed in 1570.388 seconds\n","53/53 [==============================] - 78s 1s/step\n","56/56 [==============================] - 94s 2s/step\n","CURRENT EPOCH: 24\n","[DEV] AVG QWK: 0.687\n","[DEV] score QWK: 0.756\n","[DEV] content QWK: 0.664\n","[DEV] organization QWK: 0.741\n","[DEV] word_choice QWK: 0.666\n","[DEV] sentence_fluency QWK: 0.642\n","[DEV] conventions QWK: 0.751\n","[DEV] prompt_adherence QWK: 0.643\n","[DEV] language QWK: 0.651\n","[DEV] narrativity QWK: 0.668\n","------------------------\n","[TEST] AVG QWK: 0.647\n","[TEST] score QWK: 0.811\n","[TEST] content QWK: 0.641\n","[TEST] organization QWK: 0.611\n","[TEST] word_choice QWK: 0.629\n","[TEST] sentence_fluency QWK: 0.593\n","[TEST] conventions QWK: 0.596\n","------------------------\n","[BEST TEST] AVG QWK: 0.646, {epoch}: 22\n","[BEST TEST] score QWK: 0.804\n","[BEST TEST] content QWK: 0.637\n","[BEST TEST] organization QWK: 0.603\n","[BEST TEST] word_choice QWK: 0.633\n","[BEST TEST] sentence_fluency QWK: 0.602\n","[BEST TEST] conventions QWK: 0.596\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1792s 2s/step - loss: 0.0128 - val_loss: 0.0127\n","Epoch 25/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0128Epoch 25: Train Loss: 0.012755820527672768 || Val Loss: 0.012562737800180912\n","Epoch 25 completed in 1567.003 seconds\n","53/53 [==============================] - 78s 1s/step\n","56/56 [==============================] - 82s 1s/step\n","CURRENT EPOCH: 25\n","[DEV] AVG QWK: 0.688\n","[DEV] score QWK: 0.752\n","[DEV] content QWK: 0.663\n","[DEV] organization QWK: 0.74\n","[DEV] word_choice QWK: 0.679\n","[DEV] sentence_fluency QWK: 0.654\n","[DEV] conventions QWK: 0.748\n","[DEV] prompt_adherence QWK: 0.64\n","[DEV] language QWK: 0.648\n","[DEV] narrativity QWK: 0.666\n","------------------------\n","[TEST] AVG QWK: 0.643\n","[TEST] score QWK: 0.765\n","[TEST] content QWK: 0.649\n","[TEST] organization QWK: 0.604\n","[TEST] word_choice QWK: 0.638\n","[TEST] sentence_fluency QWK: 0.6\n","[TEST] conventions QWK: 0.603\n","------------------------\n","[BEST TEST] AVG QWK: 0.643, {epoch}: 25\n","[BEST TEST] score QWK: 0.765\n","[BEST TEST] content QWK: 0.649\n","[BEST TEST] organization QWK: 0.604\n","[BEST TEST] word_choice QWK: 0.638\n","[BEST TEST] sentence_fluency QWK: 0.6\n","[BEST TEST] conventions QWK: 0.603\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1733s 2s/step - loss: 0.0128 - val_loss: 0.0126\n","Epoch 26/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0128Epoch 26: Train Loss: 0.012757825665175915 || Val Loss: 0.012574116699397564\n","Epoch 26 completed in 1532.867 seconds\n","53/53 [==============================] - 70s 1s/step\n","56/56 [==============================] - 79s 1s/step\n","CURRENT EPOCH: 26\n","[DEV] AVG QWK: 0.686\n","[DEV] score QWK: 0.755\n","[DEV] content QWK: 0.657\n","[DEV] organization QWK: 0.741\n","[DEV] word_choice QWK: 0.678\n","[DEV] sentence_fluency QWK: 0.658\n","[DEV] conventions QWK: 0.753\n","[DEV] prompt_adherence QWK: 0.64\n","[DEV] language QWK: 0.635\n","[DEV] narrativity QWK: 0.653\n","------------------------\n","[TEST] AVG QWK: 0.649\n","[TEST] score QWK: 0.814\n","[TEST] content QWK: 0.64\n","[TEST] organization QWK: 0.607\n","[TEST] word_choice QWK: 0.635\n","[TEST] sentence_fluency QWK: 0.607\n","[TEST] conventions QWK: 0.589\n","------------------------\n","[BEST TEST] AVG QWK: 0.643, {epoch}: 25\n","[BEST TEST] score QWK: 0.765\n","[BEST TEST] content QWK: 0.649\n","[BEST TEST] organization QWK: 0.604\n","[BEST TEST] word_choice QWK: 0.638\n","[BEST TEST] sentence_fluency QWK: 0.6\n","[BEST TEST] conventions QWK: 0.603\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1698s 2s/step - loss: 0.0128 - val_loss: 0.0126\n","Epoch 27/50\n","337/952 [=========>....................] - ETA: 15:10 - loss: 0.0124"]}]},{"cell_type":"code","execution_count":null,"id":"62cd9098","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"62cd9098","outputId":"d8628b11-7464-4c72-f841-59c2e5ee6095"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","Attention x: (None, 46, 100)\n","Attention x: (None, 46, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","trait num:  9\n","Attention x: (None, 46, 100)\n","Attention x: (None, 46, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","Attention x: (None, None, 100)\n","trait num:  9\n","952/952 [==============================] - ETA: 0s - loss: 0.0177Attention x: (10, 46, 100)\n","Attention x: (10, 46, 100)\n","Attention x: (10, 46, 100)\n","Attention x: (10, 46, 100)\n","Attention x: (10, 97, 100)\n","Attention x: (10, 97, 100)\n","Attention x: (10, 97, 100)\n","Attention x: (10, 97, 100)\n","Attention x: (10, 97, 100)\n","Attention x: (10, 97, 100)\n","Attention x: (10, 97, 100)\n","Attention x: (10, 97, 100)\n","Attention x: (10, 97, 100)\n","Attention x: (10, 97, 100)\n","Attention x: (10, 1, 100)\n","Attention x: (10, 1, 100)\n","Attention x: (10, 1, 100)\n","Attention x: (10, 1, 100)\n","Attention x: (10, 1, 100)\n","Attention x: (10, 1, 100)\n","Attention x: (10, 1, 100)\n","Attention x: (10, 1, 100)\n","Attention x: (10, 1, 100)\n","trait num:  9\n","Epoch 1: Train Loss: 0.017732741311192513 || Val Loss: 0.015233941376209259\n","Epoch 1 completed in 1510.176 seconds\n","53/53 [==============================] - 72s 1s/step\n","56/56 [==============================] - 78s 1s/step\n","CURRENT EPOCH: 1\n","[DEV] AVG QWK: 0.579\n","[DEV] score QWK: 0.708\n","[DEV] content QWK: 0.554\n","[DEV] organization QWK: 0.599\n","[DEV] word_choice QWK: 0.56\n","[DEV] sentence_fluency QWK: 0.522\n","[DEV] conventions QWK: 0.563\n","[DEV] prompt_adherence QWK: 0.559\n","[DEV] language QWK: 0.568\n","[DEV] narrativity QWK: 0.579\n","------------------------\n","[TEST] AVG QWK: 0.586\n","[TEST] score QWK: 0.813\n","[TEST] content QWK: 0.623\n","[TEST] organization QWK: 0.528\n","[TEST] word_choice QWK: 0.534\n","[TEST] sentence_fluency QWK: 0.527\n","[TEST] conventions QWK: 0.493\n","------------------------\n","[BEST TEST] AVG QWK: 0.586, {epoch}: 1\n","[BEST TEST] score QWK: 0.813\n","[BEST TEST] content QWK: 0.623\n","[BEST TEST] organization QWK: 0.528\n","[BEST TEST] word_choice QWK: 0.534\n","[BEST TEST] sentence_fluency QWK: 0.527\n","[BEST TEST] conventions QWK: 0.493\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1676s 2s/step - loss: 0.0177 - val_loss: 0.0152\n","Epoch 2/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0148Epoch 2: Train Loss: 0.014776601456105709 || Val Loss: 0.014138598926365376\n","Epoch 2 completed in 1396.083 seconds\n","53/53 [==============================] - 68s 1s/step\n","56/56 [==============================] - 76s 1s/step\n","CURRENT EPOCH: 2\n","[DEV] AVG QWK: 0.626\n","[DEV] score QWK: 0.729\n","[DEV] content QWK: 0.602\n","[DEV] organization QWK: 0.661\n","[DEV] word_choice QWK: 0.605\n","[DEV] sentence_fluency QWK: 0.578\n","[DEV] conventions QWK: 0.636\n","[DEV] prompt_adherence QWK: 0.599\n","[DEV] language QWK: 0.605\n","[DEV] narrativity QWK: 0.623\n","------------------------\n","[TEST] AVG QWK: 0.632\n","[TEST] score QWK: 0.789\n","[TEST] content QWK: 0.65\n","[TEST] organization QWK: 0.599\n","[TEST] word_choice QWK: 0.608\n","[TEST] sentence_fluency QWK: 0.581\n","[TEST] conventions QWK: 0.566\n","------------------------\n","[BEST TEST] AVG QWK: 0.632, {epoch}: 2\n","[BEST TEST] score QWK: 0.789\n","[BEST TEST] content QWK: 0.65\n","[BEST TEST] organization QWK: 0.599\n","[BEST TEST] word_choice QWK: 0.608\n","[BEST TEST] sentence_fluency QWK: 0.581\n","[BEST TEST] conventions QWK: 0.566\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1562s 2s/step - loss: 0.0148 - val_loss: 0.0141\n","Epoch 3/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0142Epoch 3: Train Loss: 0.01421686727553606 || Val Loss: 0.013754827901721\n","Epoch 3 completed in 1405.894 seconds\n","53/53 [==============================] - 71s 1s/step\n","56/56 [==============================] - 78s 1s/step\n","CURRENT EPOCH: 3\n","[DEV] AVG QWK: 0.639\n","[DEV] score QWK: 0.731\n","[DEV] content QWK: 0.618\n","[DEV] organization QWK: 0.685\n","[DEV] word_choice QWK: 0.619\n","[DEV] sentence_fluency QWK: 0.571\n","[DEV] conventions QWK: 0.669\n","[DEV] prompt_adherence QWK: 0.609\n","[DEV] language QWK: 0.615\n","[DEV] narrativity QWK: 0.631\n","------------------------\n","[TEST] AVG QWK: 0.615\n","[TEST] score QWK: 0.749\n","[TEST] content QWK: 0.651\n","[TEST] organization QWK: 0.593\n","[TEST] word_choice QWK: 0.6\n","[TEST] sentence_fluency QWK: 0.523\n","[TEST] conventions QWK: 0.574\n","------------------------\n","[BEST TEST] AVG QWK: 0.615, {epoch}: 3\n","[BEST TEST] score QWK: 0.749\n","[BEST TEST] content QWK: 0.651\n","[BEST TEST] organization QWK: 0.593\n","[BEST TEST] word_choice QWK: 0.6\n","[BEST TEST] sentence_fluency QWK: 0.523\n","[BEST TEST] conventions QWK: 0.574\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1560s 2s/step - loss: 0.0142 - val_loss: 0.0138\n","Epoch 4/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0139Epoch 4: Train Loss: 0.013913282193243504 || Val Loss: 0.01341936830431223\n","Epoch 4 completed in 1388.248 seconds\n","53/53 [==============================] - 72s 1s/step\n","56/56 [==============================] - 75s 1s/step\n","CURRENT EPOCH: 4\n","[DEV] AVG QWK: 0.654\n","[DEV] score QWK: 0.738\n","[DEV] content QWK: 0.629\n","[DEV] organization QWK: 0.702\n","[DEV] word_choice QWK: 0.636\n","[DEV] sentence_fluency QWK: 0.61\n","[DEV] conventions QWK: 0.689\n","[DEV] prompt_adherence QWK: 0.62\n","[DEV] language QWK: 0.62\n","[DEV] narrativity QWK: 0.639\n","------------------------\n","[TEST] AVG QWK: 0.639\n","[TEST] score QWK: 0.773\n","[TEST] content QWK: 0.65\n","[TEST] organization QWK: 0.608\n","[TEST] word_choice QWK: 0.626\n","[TEST] sentence_fluency QWK: 0.591\n","[TEST] conventions QWK: 0.583\n","------------------------\n","[BEST TEST] AVG QWK: 0.639, {epoch}: 4\n","[BEST TEST] score QWK: 0.773\n","[BEST TEST] content QWK: 0.65\n","[BEST TEST] organization QWK: 0.608\n","[BEST TEST] word_choice QWK: 0.626\n","[BEST TEST] sentence_fluency QWK: 0.591\n","[BEST TEST] conventions QWK: 0.583\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1537s 2s/step - loss: 0.0139 - val_loss: 0.0134\n","Epoch 5/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0137Epoch 5: Train Loss: 0.01372537948191166 || Val Loss: 0.013505345210433006\n","Epoch 5 completed in 1390.414 seconds\n","53/53 [==============================] - 64s 1s/step\n","56/56 [==============================] - 68s 1s/step\n","CURRENT EPOCH: 5\n","[DEV] AVG QWK: 0.653\n","[DEV] score QWK: 0.739\n","[DEV] content QWK: 0.618\n","[DEV] organization QWK: 0.702\n","[DEV] word_choice QWK: 0.647\n","[DEV] sentence_fluency QWK: 0.617\n","[DEV] conventions QWK: 0.704\n","[DEV] prompt_adherence QWK: 0.61\n","[DEV] language QWK: 0.61\n","[DEV] narrativity QWK: 0.628\n","------------------------\n","[TEST] AVG QWK: 0.636\n","[TEST] score QWK: 0.784\n","[TEST] content QWK: 0.61\n","[TEST] organization QWK: 0.611\n","[TEST] word_choice QWK: 0.63\n","[TEST] sentence_fluency QWK: 0.597\n","[TEST] conventions QWK: 0.585\n","------------------------\n","[BEST TEST] AVG QWK: 0.639, {epoch}: 4\n","[BEST TEST] score QWK: 0.773\n","[BEST TEST] content QWK: 0.65\n","[BEST TEST] organization QWK: 0.608\n","[BEST TEST] word_choice QWK: 0.626\n","[BEST TEST] sentence_fluency QWK: 0.591\n","[BEST TEST] conventions QWK: 0.583\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1555s 2s/step - loss: 0.0137 - val_loss: 0.0135\n","Epoch 6/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0136Epoch 6: Train Loss: 0.013579321093857288 || Val Loss: 0.013167822733521461\n","Epoch 6 completed in 1376.777 seconds\n","53/53 [==============================] - 66s 1s/step\n","56/56 [==============================] - 78s 1s/step\n","CURRENT EPOCH: 6\n","[DEV] AVG QWK: 0.663\n","[DEV] score QWK: 0.742\n","[DEV] content QWK: 0.635\n","[DEV] organization QWK: 0.714\n","[DEV] word_choice QWK: 0.647\n","[DEV] sentence_fluency QWK: 0.621\n","[DEV] conventions QWK: 0.709\n","[DEV] prompt_adherence QWK: 0.626\n","[DEV] language QWK: 0.627\n","[DEV] narrativity QWK: 0.644\n","------------------------\n","[TEST] AVG QWK: 0.636\n","[TEST] score QWK: 0.767\n","[TEST] content QWK: 0.65\n","[TEST] organization QWK: 0.608\n","[TEST] word_choice QWK: 0.622\n","[TEST] sentence_fluency QWK: 0.572\n","[TEST] conventions QWK: 0.6\n","------------------------\n","[BEST TEST] AVG QWK: 0.636, {epoch}: 6\n","[BEST TEST] score QWK: 0.767\n","[BEST TEST] content QWK: 0.65\n","[BEST TEST] organization QWK: 0.608\n","[BEST TEST] word_choice QWK: 0.622\n","[BEST TEST] sentence_fluency QWK: 0.572\n","[BEST TEST] conventions QWK: 0.6\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1526s 2s/step - loss: 0.0136 - val_loss: 0.0132\n","Epoch 7/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0135Epoch 7: Train Loss: 0.013455085456371307 || Val Loss: 0.013263244181871414\n","Epoch 7 completed in 1393.250 seconds\n","53/53 [==============================] - 71s 1s/step\n","56/56 [==============================] - 76s 1s/step\n","CURRENT EPOCH: 7\n","[DEV] AVG QWK: 0.661\n","[DEV] score QWK: 0.737\n","[DEV] content QWK: 0.64\n","[DEV] organization QWK: 0.699\n","[DEV] word_choice QWK: 0.639\n","[DEV] sentence_fluency QWK: 0.61\n","[DEV] conventions QWK: 0.715\n","[DEV] prompt_adherence QWK: 0.63\n","[DEV] language QWK: 0.635\n","[DEV] narrativity QWK: 0.643\n","------------------------\n","[TEST] AVG QWK: 0.609\n","[TEST] score QWK: 0.722\n","[TEST] content QWK: 0.638\n","[TEST] organization QWK: 0.574\n","[TEST] word_choice QWK: 0.599\n","[TEST] sentence_fluency QWK: 0.55\n","[TEST] conventions QWK: 0.574\n","------------------------\n","[BEST TEST] AVG QWK: 0.636, {epoch}: 6\n","[BEST TEST] score QWK: 0.767\n","[BEST TEST] content QWK: 0.65\n","[BEST TEST] organization QWK: 0.608\n","[BEST TEST] word_choice QWK: 0.622\n","[BEST TEST] sentence_fluency QWK: 0.572\n","[BEST TEST] conventions QWK: 0.6\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1548s 2s/step - loss: 0.0135 - val_loss: 0.0133\n","Epoch 8/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0134Epoch 8: Train Loss: 0.013362962752580643 || Val Loss: 0.013125586323440075\n","Epoch 8 completed in 1393.647 seconds\n","53/53 [==============================] - 64s 1s/step\n","56/56 [==============================] - 67s 1s/step\n","CURRENT EPOCH: 8\n","[DEV] AVG QWK: 0.666\n","[DEV] score QWK: 0.737\n","[DEV] content QWK: 0.644\n","[DEV] organization QWK: 0.711\n","[DEV] word_choice QWK: 0.658\n","[DEV] sentence_fluency QWK: 0.631\n","[DEV] conventions QWK: 0.718\n","[DEV] prompt_adherence QWK: 0.625\n","[DEV] language QWK: 0.622\n","[DEV] narrativity QWK: 0.645\n","------------------------\n","[TEST] AVG QWK: 0.639\n","[TEST] score QWK: 0.727\n","[TEST] content QWK: 0.655\n","[TEST] organization QWK: 0.613\n","[TEST] word_choice QWK: 0.635\n","[TEST] sentence_fluency QWK: 0.617\n","[TEST] conventions QWK: 0.589\n","------------------------\n","[BEST TEST] AVG QWK: 0.639, {epoch}: 8\n","[BEST TEST] score QWK: 0.727\n","[BEST TEST] content QWK: 0.655\n","[BEST TEST] organization QWK: 0.613\n","[BEST TEST] word_choice QWK: 0.635\n","[BEST TEST] sentence_fluency QWK: 0.617\n","[BEST TEST] conventions QWK: 0.589\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1543s 2s/step - loss: 0.0134 - val_loss: 0.0131\n","Epoch 9/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0133Epoch 9: Train Loss: 0.013292805291712284 || Val Loss: 0.012983104214072227\n","Epoch 9 completed in 1375.363 seconds\n","53/53 [==============================] - 64s 1s/step\n","56/56 [==============================] - 70s 1s/step\n","CURRENT EPOCH: 9\n","[DEV] AVG QWK: 0.672\n","[DEV] score QWK: 0.742\n","[DEV] content QWK: 0.643\n","[DEV] organization QWK: 0.722\n","[DEV] word_choice QWK: 0.658\n","[DEV] sentence_fluency QWK: 0.634\n","[DEV] conventions QWK: 0.725\n","[DEV] prompt_adherence QWK: 0.634\n","[DEV] language QWK: 0.636\n","[DEV] narrativity QWK: 0.651\n","------------------------\n","[TEST] AVG QWK: 0.645\n","[TEST] score QWK: 0.76\n","[TEST] content QWK: 0.659\n","[TEST] organization QWK: 0.611\n","[TEST] word_choice QWK: 0.636\n","[TEST] sentence_fluency QWK: 0.602\n","[TEST] conventions QWK: 0.602\n","------------------------\n","[BEST TEST] AVG QWK: 0.645, {epoch}: 9\n","[BEST TEST] score QWK: 0.76\n","[BEST TEST] content QWK: 0.659\n","[BEST TEST] organization QWK: 0.611\n","[BEST TEST] word_choice QWK: 0.636\n","[BEST TEST] sentence_fluency QWK: 0.602\n","[BEST TEST] conventions QWK: 0.602\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1511s 2s/step - loss: 0.0133 - val_loss: 0.0130\n","Epoch 10/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0132Epoch 10: Train Loss: 0.013219797052443027 || Val Loss: 0.013078846037387848\n","Epoch 10 completed in 1366.826 seconds\n","53/53 [==============================] - 70s 1s/step\n","56/56 [==============================] - 78s 1s/step\n","CURRENT EPOCH: 10\n","[DEV] AVG QWK: 0.67\n","[DEV] score QWK: 0.749\n","[DEV] content QWK: 0.642\n","[DEV] organization QWK: 0.728\n","[DEV] word_choice QWK: 0.664\n","[DEV] sentence_fluency QWK: 0.637\n","[DEV] conventions QWK: 0.721\n","[DEV] prompt_adherence QWK: 0.622\n","[DEV] language QWK: 0.629\n","[DEV] narrativity QWK: 0.636\n","------------------------\n","[TEST] AVG QWK: 0.649\n","[TEST] score QWK: 0.796\n","[TEST] content QWK: 0.634\n","[TEST] organization QWK: 0.617\n","[TEST] word_choice QWK: 0.646\n","[TEST] sentence_fluency QWK: 0.599\n","[TEST] conventions QWK: 0.602\n","------------------------\n","[BEST TEST] AVG QWK: 0.645, {epoch}: 9\n","[BEST TEST] score QWK: 0.76\n","[BEST TEST] content QWK: 0.659\n","[BEST TEST] organization QWK: 0.611\n","[BEST TEST] word_choice QWK: 0.636\n","[BEST TEST] sentence_fluency QWK: 0.602\n","[BEST TEST] conventions QWK: 0.602\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1532s 2s/step - loss: 0.0132 - val_loss: 0.0131\n","Epoch 11/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0132Epoch 11: Train Loss: 0.013166611082851887 || Val Loss: 0.013004799373447895\n","Epoch 11 completed in 1362.100 seconds\n","53/53 [==============================] - 63s 1s/step\n","56/56 [==============================] - 68s 1s/step\n","CURRENT EPOCH: 11\n","[DEV] AVG QWK: 0.674\n","[DEV] score QWK: 0.749\n","[DEV] content QWK: 0.649\n","[DEV] organization QWK: 0.726\n","[DEV] word_choice QWK: 0.65\n","[DEV] sentence_fluency QWK: 0.627\n","[DEV] conventions QWK: 0.735\n","[DEV] prompt_adherence QWK: 0.632\n","[DEV] language QWK: 0.64\n","[DEV] narrativity QWK: 0.658\n","------------------------\n","[TEST] AVG QWK: 0.636\n","[TEST] score QWK: 0.786\n","[TEST] content QWK: 0.655\n","[TEST] organization QWK: 0.617\n","[TEST] word_choice QWK: 0.606\n","[TEST] sentence_fluency QWK: 0.563\n","[TEST] conventions QWK: 0.589\n","------------------------\n","[BEST TEST] AVG QWK: 0.636, {epoch}: 11\n","[BEST TEST] score QWK: 0.786\n","[BEST TEST] content QWK: 0.655\n","[BEST TEST] organization QWK: 0.617\n","[BEST TEST] word_choice QWK: 0.606\n","[BEST TEST] sentence_fluency QWK: 0.563\n","[BEST TEST] conventions QWK: 0.589\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1495s 2s/step - loss: 0.0132 - val_loss: 0.0130\n","Epoch 12/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0131Epoch 12: Train Loss: 0.013103044591844082 || Val Loss: 0.012856515124440193\n","Epoch 12 completed in 1358.270 seconds\n","53/53 [==============================] - 65s 1s/step\n","56/56 [==============================] - 72s 1s/step\n","CURRENT EPOCH: 12\n","[DEV] AVG QWK: 0.677\n","[DEV] score QWK: 0.747\n","[DEV] content QWK: 0.652\n","[DEV] organization QWK: 0.729\n","[DEV] word_choice QWK: 0.665\n","[DEV] sentence_fluency QWK: 0.638\n","[DEV] conventions QWK: 0.732\n","[DEV] prompt_adherence QWK: 0.632\n","[DEV] language QWK: 0.639\n","[DEV] narrativity QWK: 0.657\n","------------------------\n","[TEST] AVG QWK: 0.634\n","[TEST] score QWK: 0.733\n","[TEST] content QWK: 0.647\n","[TEST] organization QWK: 0.604\n","[TEST] word_choice QWK: 0.633\n","[TEST] sentence_fluency QWK: 0.582\n","[TEST] conventions QWK: 0.606\n","------------------------\n","[BEST TEST] AVG QWK: 0.634, {epoch}: 12\n","[BEST TEST] score QWK: 0.733\n","[BEST TEST] content QWK: 0.647\n","[BEST TEST] organization QWK: 0.604\n","[BEST TEST] word_choice QWK: 0.633\n","[BEST TEST] sentence_fluency QWK: 0.582\n","[BEST TEST] conventions QWK: 0.606\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1513s 2s/step - loss: 0.0131 - val_loss: 0.0129\n","Epoch 13/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0131Epoch 13: Train Loss: 0.01307852752506733 || Val Loss: 0.012861546128988266\n","Epoch 13 completed in 1347.164 seconds\n","53/53 [==============================] - 70s 1s/step\n","56/56 [==============================] - 76s 1s/step\n","CURRENT EPOCH: 13\n","[DEV] AVG QWK: 0.674\n","[DEV] score QWK: 0.749\n","[DEV] content QWK: 0.646\n","[DEV] organization QWK: 0.729\n","[DEV] word_choice QWK: 0.664\n","[DEV] sentence_fluency QWK: 0.643\n","[DEV] conventions QWK: 0.739\n","[DEV] prompt_adherence QWK: 0.63\n","[DEV] language QWK: 0.625\n","[DEV] narrativity QWK: 0.645\n","------------------------\n","[TEST] AVG QWK: 0.641\n","[TEST] score QWK: 0.789\n","[TEST] content QWK: 0.636\n","[TEST] organization QWK: 0.599\n","[TEST] word_choice QWK: 0.633\n","[TEST] sentence_fluency QWK: 0.608\n","[TEST] conventions QWK: 0.583\n","------------------------\n","[BEST TEST] AVG QWK: 0.634, {epoch}: 12\n","[BEST TEST] score QWK: 0.733\n","[BEST TEST] content QWK: 0.647\n","[BEST TEST] organization QWK: 0.604\n","[BEST TEST] word_choice QWK: 0.633\n","[BEST TEST] sentence_fluency QWK: 0.582\n","[BEST TEST] conventions QWK: 0.606\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1495s 2s/step - loss: 0.0131 - val_loss: 0.0129\n","Epoch 14/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0130Epoch 14: Train Loss: 0.013022704049944878 || Val Loss: 0.01272450853139162\n","Epoch 14 completed in 1395.694 seconds\n","53/53 [==============================] - 77s 1s/step\n","56/56 [==============================] - 82s 1s/step\n","CURRENT EPOCH: 14\n","[DEV] AVG QWK: 0.68\n","[DEV] score QWK: 0.751\n","[DEV] content QWK: 0.655\n","[DEV] organization QWK: 0.728\n","[DEV] word_choice QWK: 0.663\n","[DEV] sentence_fluency QWK: 0.645\n","[DEV] conventions QWK: 0.738\n","[DEV] prompt_adherence QWK: 0.639\n","[DEV] language QWK: 0.643\n","[DEV] narrativity QWK: 0.659\n","------------------------\n","[TEST] AVG QWK: 0.65\n","[TEST] score QWK: 0.79\n","[TEST] content QWK: 0.654\n","[TEST] organization QWK: 0.615\n","[TEST] word_choice QWK: 0.647\n","[TEST] sentence_fluency QWK: 0.608\n","[TEST] conventions QWK: 0.584\n","------------------------\n","[BEST TEST] AVG QWK: 0.65, {epoch}: 14\n","[BEST TEST] score QWK: 0.79\n","[BEST TEST] content QWK: 0.654\n","[BEST TEST] organization QWK: 0.615\n","[BEST TEST] word_choice QWK: 0.647\n","[BEST TEST] sentence_fluency QWK: 0.608\n","[BEST TEST] conventions QWK: 0.584\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 1556s 2s/step - loss: 0.0130 - val_loss: 0.0127\n","Epoch 15/50\n","952/952 [==============================] - ETA: 0s - loss: 0.0130Epoch 15: Train Loss: 0.012989871203899384 || Val Loss: 0.012724844738841057\n","Epoch 15 completed in 1490.790 seconds\n","20/53 [==========>...................] - ETA: 48s"]}],"source":["# CPU로 시작된 첫 번째 학습(~14)\n","# Check if there is a latest checkpoint\n","initial_epoch = 0\n","if latest_checkpoint and load:\n","    print(f'Loading weights from {latest_checkpoint}')\n","    model.load_weights(latest_checkpoint)\n","    initial_epoch = int(latest_checkpoint.split('_')[-1].split('.')[0]) if latest_checkpoint else 0\n","else:\n","    print('No latest checkpoint found. Starting from scratch.')\n","\n","# 모델 학습 코드\n","model.fit(\n","    train_features_list,\n","    Y_train,\n","    batch_size=batch_size,\n","    epochs=50, # 적절한 에포크 수로 설정\n","    verbose=1,\n","    shuffle=True,\n","    validation_data=(dev_features_list, Y_dev),\n","    callbacks=[custom_hist, checkpoint],\n","    initial_epoch=initial_epoch  # 학습을 재개할 에포크\n",")"]},{"cell_type":"code","execution_count":null,"id":"10c561ac","metadata":{"id":"10c561ac"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"eb7f3c27","metadata":{"id":"eb7f3c27","outputId":"5a61a984-3938-4091-9b95-be44974c3475"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","trait num:  9\n","trait num:  9\n","952/952 [==============================] - ETA: 0s - loss: 0.0163trait num:  9\n","Epoch 1: Train Loss: 0.016327474266290665 || Val Loss: 0.013890832662582397\n","Epoch 1 completed in 262.809 seconds\n","53/53 [==============================] - 10s 182ms/step\n","56/56 [==============================] - 10s 183ms/step\n","CURRENT EPOCH: 1\n","[DEV] AVG QWK: 0.626\n","[DEV] score QWK: 0.733\n","[DEV] content QWK: 0.616\n","[DEV] organization QWK: 0.639\n","[DEV] word_choice QWK: 0.541\n","[DEV] sentence_fluency QWK: 0.554\n","[DEV] conventions QWK: 0.617\n","[DEV] prompt_adherence QWK: 0.645\n","[DEV] language QWK: 0.647\n","[DEV] narrativity QWK: 0.641\n","------------------------\n","[TEST] AVG QWK: 0.593\n","[TEST] score QWK: 0.818\n","[TEST] content QWK: 0.6\n","[TEST] organization QWK: 0.536\n","[TEST] word_choice QWK: 0.523\n","[TEST] sentence_fluency QWK: 0.563\n","[TEST] conventions QWK: 0.517\n","------------------------\n","[BEST TEST] AVG QWK: 0.593, {epoch}: 1\n","[BEST TEST] score QWK: 0.818\n","[BEST TEST] content QWK: 0.6\n","[BEST TEST] organization QWK: 0.536\n","[BEST TEST] word_choice QWK: 0.523\n","[BEST TEST] sentence_fluency QWK: 0.563\n","[BEST TEST] conventions QWK: 0.517\n","--------------------------------------------------------------------------------------------------------------------------\n","952/952 [==============================] - 283s 268ms/step - loss: 0.0163 - val_loss: 0.0139\n","Epoch 2/50\n"," 23/952 [..............................] - ETA: 3:26 - loss: 0.0131"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m         evaluator\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     25\u001b[0m custom_hist \u001b[38;5;241m=\u001b[39m CustomHistory()\n\u001b[0;32m---> 26\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_features_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdev_features_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_dev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcustom_hist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n","File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n","File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# class CustomHistory(tf.keras.callbacks.Callback):\n","#     def on_train_begin(self, logs=None):\n","#         self.train_loss = []\n","#         self.val_loss = []\n","#         self.train_acc = []\n","#         self.val_acc = []\n","#         self.epoch_times = []\n","\n","#     def on_epoch_begin(self, epoch, logs=None):\n","#         self.start_time = time.time()\n","\n","#     def on_epoch_end(self, epoch, logs=None):\n","#         self.train_loss.append(logs.get('loss'))\n","#         self.val_loss.append(logs.get('val_loss'))\n","#         self.train_acc.append(logs.get('acc'))\n","#         self.val_acc.append(logs.get('val_acc'))\n","#         epoch_time = time.time() - self.start_time\n","#         self.epoch_times.append(epoch_time)\n","#         print(f\"Epoch {epoch + 1}: Train Loss: {logs.get('loss')} || Val Loss: {logs.get('val_loss')}\")\n","#         print(f\"Epoch {epoch + 1} completed in {epoch_time:.3f} seconds\")\n","\n","#         # Evaluate the model (you might need to adjust this to your specific evaluation function)\n","#         evaluator.evaluate(self.model, epoch + 1)\n","\n","# custom_hist = CustomHistory()\n","# model.fit(\n","#     train_features_list,\n","#     Y_train,\n","#     batch_size=batch_size,\n","#     epochs=epochs,\n","#     verbose=1,\n","#     shuffle=True,\n","#     validation_data=(dev_features_list, Y_dev),\n","#     callbacks=[custom_hist, checkpoint]\n","# )"]},{"cell_type":"code","execution_count":null,"id":"01487fa8","metadata":{"id":"01487fa8","outputId":"9e7d6f78-9279-4e9b-bdbc-7bb2a818ed86"},"outputs":[{"name":"stdout","output_type":"stream","text":["53/53 [==============================] - 10s 188ms/step\n","56/56 [==============================] - 10s 185ms/step\n","CURRENT EPOCH: 1\n","[DEV] AVG QWK: 0.626\n","[DEV] score QWK: 0.733\n","[DEV] content QWK: 0.616\n","[DEV] organization QWK: 0.639\n","[DEV] word_choice QWK: 0.541\n","[DEV] sentence_fluency QWK: 0.554\n","[DEV] conventions QWK: 0.617\n","[DEV] prompt_adherence QWK: 0.645\n","[DEV] language QWK: 0.647\n","[DEV] narrativity QWK: 0.641\n","------------------------\n","[TEST] AVG QWK: 0.593\n","[TEST] score QWK: 0.818\n","[TEST] content QWK: 0.6\n","[TEST] organization QWK: 0.536\n","[TEST] word_choice QWK: 0.523\n","[TEST] sentence_fluency QWK: 0.563\n","[TEST] conventions QWK: 0.517\n","------------------------\n","[BEST TEST] AVG QWK: 0.593, {epoch}: 1\n","[BEST TEST] score QWK: 0.818\n","[BEST TEST] content QWK: 0.6\n","[BEST TEST] organization QWK: 0.536\n","[BEST TEST] word_choice QWK: 0.523\n","[BEST TEST] sentence_fluency QWK: 0.563\n","[BEST TEST] conventions QWK: 0.517\n","--------------------------------------------------------------------------------------------------------------------------\n"]}],"source":["# 실행 X\n","# TEST: 위에서 진행된곳 까지 결과가 같다.\n","model.load_weights('Checkpoint/bestmodel1.h5')\n","evaluator.evaluate(model,1)"]},{"cell_type":"code","execution_count":null,"id":"86de4013","metadata":{"id":"86de4013"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}