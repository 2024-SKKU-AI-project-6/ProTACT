{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade1964c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/joohwan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/joohwan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Load autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload behavior\n",
    "%autoreload 2\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "from models.ProTACT import build_ProTACT\n",
    "import tensorflow as tf\n",
    "from configs.configs import Configs\n",
    "from utils.read_data_pr import read_pos_vocab, read_word_vocab, read_prompts_we, read_essays_prompts, read_prompts_pos\n",
    "from utils.general_utils import get_scaled_down_scores, pad_hierarchical_text_sequences, get_attribute_masks, load_word_embedding_dict, build_embedd_table\n",
    "from evaluators.multitask_evaluator_all_attributes import Evaluator as AllAttEvaluator\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2215898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prompt id is 1 of type <class 'int'>\n",
      "Seed: 1\n",
      "Numhead :  2  | Features :  ../data/hand_crafted_v3.csv  | Pos_emb :  50\n"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(description=\"ProTACT model\")\n",
    "# parser.add_argument('--test_prompt_id', type=int, default=1, help='prompt id of test essay set')\n",
    "# parser.add_argument('--seed', type=int, default=12, help='set random seed')\n",
    "# parser.add_argument('--model_name', type=str,\n",
    "#                     choices=['ProTACT'],\n",
    "#                     help='name of model')\n",
    "# parser.add_argument('--num_heads', type=int, default=2, help='set the number of heads in Multihead Attention')\n",
    "# parser.add_argument('--features_path', type=str, default='data/hand_crafted_v3.csv')\n",
    "\n",
    "test_prompt_id = 1\n",
    "seed = 1\n",
    "num_heads = 2\n",
    "features_path = '../data/hand_crafted_v3.csv'\n",
    "\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "print(\"Test prompt id is {} of type {}\".format(test_prompt_id, type(test_prompt_id)))\n",
    "print(\"Seed: {}\".format(seed))\n",
    "\n",
    "configs = Configs()\n",
    "\n",
    "data_path = configs.DATA_PATH\n",
    "train_path = data_path + str(test_prompt_id) + '/train.pk'\n",
    "dev_path = data_path + str(test_prompt_id) + '/dev.pk'\n",
    "test_path = data_path + str(test_prompt_id) + '/test.pk'\n",
    "pretrained_embedding = configs.PRETRAINED_EMBEDDING\n",
    "embedding_path = configs.EMBEDDING_PATH\n",
    "readability_path = configs.READABILITY_PATH\n",
    "prompt_path = configs.PROMPT_PATH\n",
    "vocab_size = configs.VOCAB_SIZE\n",
    "epochs = configs.EPOCHS\n",
    "batch_size = configs.BATCH_SIZE\n",
    "print(\"Numhead : \", num_heads, \" | Features : \", features_path, \" | Pos_emb : \", configs.EMBEDDING_DIM)\n",
    "\n",
    "read_configs = {\n",
    "    'train_path': train_path,\n",
    "    'dev_path': dev_path,\n",
    "    'test_path': test_path,\n",
    "    'features_path': features_path,\n",
    "    'readability_path': readability_path,\n",
    "    'vocab_size': vocab_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1c27955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " prompt_pos size: 8\n",
      " prompt_words size: 8\n",
      " pos_x size: 9513\n",
      " readability_x size: 9513\n",
      " pos_x size: 1680\n",
      " readability_x size: 1680\n",
      " pos_x size: 1783\n",
      " readability_x size: 1783\n",
      "Loading GloVe ...\n",
      "OOV number =189, OOV ratio = 0.047262\n"
     ]
    }
   ],
   "source": [
    "pos_vocab = read_pos_vocab(read_configs)\n",
    "# read POS for prompts\n",
    "prompt_pos_data = read_prompts_pos(prompt_path, pos_vocab) # for prompt POS embedding \n",
    "\n",
    "word_vocab = read_word_vocab(read_configs)\n",
    "# read words for prompts \n",
    "prompt_data = read_prompts_we(prompt_path, word_vocab) # for prompt word embedding \n",
    "\n",
    "# read essays and prompts\n",
    "train_data, dev_data, test_data = read_essays_prompts(read_configs, prompt_data, prompt_pos_data, pos_vocab) \n",
    "\n",
    "if pretrained_embedding:\n",
    "    embedd_dict, embedd_dim, _ = load_word_embedding_dict(embedding_path)\n",
    "    embedd_matrix = build_embedd_table(word_vocab, embedd_dict, embedd_dim, caseless=True)\n",
    "    embed_table = [embedd_matrix]\n",
    "else:\n",
    "    embed_table = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "423b8538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_ids</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_pos</th>\n",
       "      <th>readability_x</th>\n",
       "      <th>features_x</th>\n",
       "      <th>data_y</th>\n",
       "      <th>prompt_ids</th>\n",
       "      <th>max_sentnum</th>\n",
       "      <th>max_sentlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7532</td>\n",
       "      <td>[[2, 3, 4, 2, 5, 6, 2, 5, 4, 7, 3, 8], [9, 5, ...</td>\n",
       "      <td>[[662, 2552, 736, 281, 165, 319, 106, 4], [255...</td>\n",
       "      <td>[[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...</td>\n",
       "      <td>[0.49193152567610715, 0.29664566400513215, 0.5...</td>\n",
       "      <td>[0.4506668631640999, 0.3840642800992836, 0.062...</td>\n",
       "      <td>[1, 1, -1, -1, -1, -1, 1, 1, 1]</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7229</td>\n",
       "      <td>[[2, 3, 4, 2, 5, 20, 2, 11, 7, 5, 4, 2, 5, 8],...</td>\n",
       "      <td>[[662, 2552, 736, 281, 165, 319, 106, 4], [255...</td>\n",
       "      <td>[[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...</td>\n",
       "      <td>[0.5579662498866749, 0.37479701404401994, 0.59...</td>\n",
       "      <td>[0.4513708636511923, 0.3586686128111479, 0.085...</td>\n",
       "      <td>[3, 3, -1, -1, -1, -1, 3, 3, 2]</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4154</td>\n",
       "      <td>[[9, 4, 2, 3, 4, 2, 29, 3, 4, 29, 3, 10, 5, 4,...</td>\n",
       "      <td>[[218, 125, 4], [122, 72, 73, 340, 1007, 124, ...</td>\n",
       "      <td>[[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8]...</td>\n",
       "      <td>[0.8612956765106549, 0.7423848792139746, 0.619...</td>\n",
       "      <td>[0.5640345883998679, 0.2858415150037477, 0.066...</td>\n",
       "      <td>[4, 4, 4, 4, 5, 4, -1, -1, -1]</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17950</td>\n",
       "      <td>[[12, 5, 10, 7, 13, 18, 24, 18, 3, 18, 20, 18,...</td>\n",
       "      <td>[[662, 248, 4], [133, 405, 1090, 2011, 4], [13...</td>\n",
       "      <td>[[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, ...</td>\n",
       "      <td>[0.20688685950461458, 0.1460481802533566, 0.35...</td>\n",
       "      <td>[0.21863912823111997, 0.1030009415010439, 0.04...</td>\n",
       "      <td>[11, 2, 2, -1, -1, 4, -1, -1, -1]</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9785</td>\n",
       "      <td>[[2, 5, 10, 2, 5, 4, 2, 5, 4, 14, 2, 11, 7, 12...</td>\n",
       "      <td>[[90, 271, 131, 84, 4], [190, 108, 150, 814, 8...</td>\n",
       "      <td>[[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6...</td>\n",
       "      <td>[0.7090757475733677, 0.48555603009134607, 0.79...</td>\n",
       "      <td>[0.5980343980343981, 0.5082625502524476, 0.090...</td>\n",
       "      <td>[1, 1, -1, -1, -1, -1, 1, 1, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9508</th>\n",
       "      <td>6877</td>\n",
       "      <td>[[4, 2, 5, 4, 5, 11, 20, 11, 18, 16, 7, 4, 29,...</td>\n",
       "      <td>[[662, 2552, 736, 281, 165, 319, 106, 4], [255...</td>\n",
       "      <td>[[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...</td>\n",
       "      <td>[0.6420710849952196, 0.4709075862939792, 0.767...</td>\n",
       "      <td>[0.5665003864259118, 0.4089167978068259, 0.093...</td>\n",
       "      <td>[2, 2, -1, -1, -1, -1, 2, 1, 1]</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9509</th>\n",
       "      <td>3661</td>\n",
       "      <td>[[5, 28, 2, 5, 4, 12, 7, 3, 4, 2, 7, 5, 8], [1...</td>\n",
       "      <td>[[218, 125, 4], [122, 72, 73, 340, 1007, 124, ...</td>\n",
       "      <td>[[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8]...</td>\n",
       "      <td>[0.7470330548911367, 0.5322450678768516, 0.688...</td>\n",
       "      <td>[0.7336936048109188, 0.3952062286100636, 0.031...</td>\n",
       "      <td>[4, 5, 4, 4, 5, 4, -1, -1, -1]</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510</th>\n",
       "      <td>10364</td>\n",
       "      <td>[[4, 15, 20, 11, 24, 5, 6, 11, 13, 18, 24, 4, ...</td>\n",
       "      <td>[[90, 271, 131, 84, 4], [190, 108, 150, 814, 8...</td>\n",
       "      <td>[[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6...</td>\n",
       "      <td>[0.6775704345317742, 0.5015464633073149, 0.707...</td>\n",
       "      <td>[0.44895975111802455, 0.27287771704373115, 0.1...</td>\n",
       "      <td>[1, 1, -1, -1, -1, -1, 1, 1, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9511</th>\n",
       "      <td>18367</td>\n",
       "      <td>[[9, 5, 14, 5, 6, 14, 3, 22, 5, 6, 15, 8], [14...</td>\n",
       "      <td>[[662, 248, 4], [133, 405, 1090, 2011, 4], [13...</td>\n",
       "      <td>[[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, ...</td>\n",
       "      <td>[0.4465909693384573, 0.375902607097603, 0.5005...</td>\n",
       "      <td>[0.2542676650242186, 0.08406393382610401, 0.09...</td>\n",
       "      <td>[18, 5, 5, -1, -1, 4, -1, -1, -1]</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9512</th>\n",
       "      <td>15347</td>\n",
       "      <td>[[4, 12, 22, 12, 2, 5, 5, 4, 2, 5, 5, 5, 24, 2...</td>\n",
       "      <td>[[756, 446, 1528, 178, 149, 113, 107, 56, 180,...</td>\n",
       "      <td>[[16, 7, 7, 3, 3, 20, 5, 5, 6, 12, 7, 3, 5, 8]...</td>\n",
       "      <td>[0.6385888045704757, 0.40596380660143777, 0.50...</td>\n",
       "      <td>[0.34372244585010514, 0.12172169029380711, 0.1...</td>\n",
       "      <td>[2, 1, -1, -1, -1, -1, 1, 1, 1]</td>\n",
       "      <td>6</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9513 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_ids                                              pos_x   \n",
       "0          7532  [[2, 3, 4, 2, 5, 6, 2, 5, 4, 7, 3, 8], [9, 5, ...  \\\n",
       "1          7229  [[2, 3, 4, 2, 5, 20, 2, 11, 7, 5, 4, 2, 5, 8],...   \n",
       "2          4154  [[9, 4, 2, 3, 4, 2, 29, 3, 4, 29, 3, 10, 5, 4,...   \n",
       "3         17950  [[12, 5, 10, 7, 13, 18, 24, 18, 3, 18, 20, 18,...   \n",
       "4          9785  [[2, 5, 10, 2, 5, 4, 2, 5, 4, 14, 2, 11, 7, 12...   \n",
       "...         ...                                                ...   \n",
       "9508       6877  [[4, 2, 5, 4, 5, 11, 20, 11, 18, 16, 7, 4, 29,...   \n",
       "9509       3661  [[5, 28, 2, 5, 4, 12, 7, 3, 4, 2, 7, 5, 8], [1...   \n",
       "9510      10364  [[4, 15, 20, 11, 24, 5, 6, 11, 13, 18, 24, 4, ...   \n",
       "9511      18367  [[9, 5, 14, 5, 6, 14, 3, 22, 5, 6, 15, 8], [14...   \n",
       "9512      15347  [[4, 12, 22, 12, 2, 5, 5, 4, 2, 5, 5, 5, 24, 2...   \n",
       "\n",
       "                                           prompt_words   \n",
       "0     [[662, 2552, 736, 281, 165, 319, 106, 4], [255...  \\\n",
       "1     [[662, 2552, 736, 281, 165, 319, 106, 4], [255...   \n",
       "2     [[218, 125, 4], [122, 72, 73, 340, 1007, 124, ...   \n",
       "3     [[662, 248, 4], [133, 405, 1090, 2011, 4], [13...   \n",
       "4     [[90, 271, 131, 84, 4], [190, 108, 150, 814, 8...   \n",
       "...                                                 ...   \n",
       "9508  [[662, 2552, 736, 281, 165, 319, 106, 4], [255...   \n",
       "9509  [[218, 125, 4], [122, 72, 73, 340, 1007, 124, ...   \n",
       "9510  [[90, 271, 131, 84, 4], [190, 108, 150, 814, 8...   \n",
       "9511  [[662, 248, 4], [133, 405, 1090, 2011, 4], [13...   \n",
       "9512  [[756, 446, 1528, 178, 149, 113, 107, 56, 180,...   \n",
       "\n",
       "                                             prompt_pos   \n",
       "0     [[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...  \\\n",
       "1     [[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...   \n",
       "2     [[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8]...   \n",
       "3     [[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, ...   \n",
       "4     [[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6...   \n",
       "...                                                 ...   \n",
       "9508  [[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...   \n",
       "9509  [[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8]...   \n",
       "9510  [[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6...   \n",
       "9511  [[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, ...   \n",
       "9512  [[16, 7, 7, 3, 3, 20, 5, 5, 6, 12, 7, 3, 5, 8]...   \n",
       "\n",
       "                                          readability_x   \n",
       "0     [0.49193152567610715, 0.29664566400513215, 0.5...  \\\n",
       "1     [0.5579662498866749, 0.37479701404401994, 0.59...   \n",
       "2     [0.8612956765106549, 0.7423848792139746, 0.619...   \n",
       "3     [0.20688685950461458, 0.1460481802533566, 0.35...   \n",
       "4     [0.7090757475733677, 0.48555603009134607, 0.79...   \n",
       "...                                                 ...   \n",
       "9508  [0.6420710849952196, 0.4709075862939792, 0.767...   \n",
       "9509  [0.7470330548911367, 0.5322450678768516, 0.688...   \n",
       "9510  [0.6775704345317742, 0.5015464633073149, 0.707...   \n",
       "9511  [0.4465909693384573, 0.375902607097603, 0.5005...   \n",
       "9512  [0.6385888045704757, 0.40596380660143777, 0.50...   \n",
       "\n",
       "                                             features_x   \n",
       "0     [0.4506668631640999, 0.3840642800992836, 0.062...  \\\n",
       "1     [0.4513708636511923, 0.3586686128111479, 0.085...   \n",
       "2     [0.5640345883998679, 0.2858415150037477, 0.066...   \n",
       "3     [0.21863912823111997, 0.1030009415010439, 0.04...   \n",
       "4     [0.5980343980343981, 0.5082625502524476, 0.090...   \n",
       "...                                                 ...   \n",
       "9508  [0.5665003864259118, 0.4089167978068259, 0.093...   \n",
       "9509  [0.7336936048109188, 0.3952062286100636, 0.031...   \n",
       "9510  [0.44895975111802455, 0.27287771704373115, 0.1...   \n",
       "9511  [0.2542676650242186, 0.08406393382610401, 0.09...   \n",
       "9512  [0.34372244585010514, 0.12172169029380711, 0.1...   \n",
       "\n",
       "                                 data_y  prompt_ids  max_sentnum  max_sentlen  \n",
       "0       [1, 1, -1, -1, -1, -1, 1, 1, 1]           3           97           50  \n",
       "1       [3, 3, -1, -1, -1, -1, 3, 3, 2]           3           97           50  \n",
       "2        [4, 4, 4, 4, 5, 4, -1, -1, -1]           2           97           50  \n",
       "3     [11, 2, 2, -1, -1, 4, -1, -1, -1]           7           97           50  \n",
       "4       [1, 1, -1, -1, -1, -1, 1, 1, 1]           4           97           50  \n",
       "...                                 ...         ...          ...          ...  \n",
       "9508    [2, 2, -1, -1, -1, -1, 2, 1, 1]           3           97           50  \n",
       "9509     [4, 5, 4, 4, 5, 4, -1, -1, -1]           2           97           50  \n",
       "9510    [1, 1, -1, -1, -1, -1, 1, 1, 1]           4           97           50  \n",
       "9511  [18, 5, 5, -1, -1, 4, -1, -1, -1]           7           97           50  \n",
       "9512    [2, 1, -1, -1, -1, -1, 1, 1, 1]           6           97           50  \n",
       "\n",
       "[9513 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(len(train_data['features_x'][0]))\n",
    "pd.DataFrame(train_data)\n",
    "# embedd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7e8f956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sent length: 50\n",
      "max sent num: 97\n",
      "max prompt sent length: 18\n",
      "max prompt sent num: 8\n",
      "================================\n",
      "X_train_pos:  (9513, 4850)\n",
      "X_train_prompt_words:  (9513, 4850)\n",
      "X_train_prompt_pos:  (9513, 4850)\n",
      "X_train_readability:  (9513, 35)\n",
      "X_train_ling:  (9513, 51)\n",
      "X_train_attribute_rel:  (9513, 9)\n",
      "Y_train:  (9513, 9)\n",
      "================================\n",
      "X_dev_pos:  (1680, 4850)\n",
      "X_dev_prompt_words:  (1680, 4850)\n",
      "X_dev_prompt_pos:  (1680, 4850)\n",
      "X_dev_readability:  (1680, 35)\n",
      "X_dev_ling:  (1680, 51)\n",
      "X_dev_attribute_rel:  (1680, 9)\n",
      "Y_dev:  (1680, 9)\n",
      "================================\n",
      "X_test_pos:  (1783, 4850)\n",
      "X_test_prompt_words:  (1783, 4850)\n",
      "X_test_prompt_pos:  (1783, 4850)\n",
      "X_test_readability:  (1783, 35)\n",
      "X_test_ling:  (1783, 51)\n",
      "X_test_attribute_rel:  (1783, 9)\n",
      "Y_test:  (1783, 9)\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "max_sentlen = max(train_data['max_sentlen'], dev_data['max_sentlen'], test_data['max_sentlen'])\n",
    "max_sentnum = max(train_data['max_sentnum'], dev_data['max_sentnum'], test_data['max_sentnum'])\n",
    "prompt_max_sentlen = prompt_data['max_sentlen']\n",
    "prompt_max_sentnum = prompt_data['max_sentnum']\n",
    "\n",
    "print('max sent length: {}'.format(max_sentlen))\n",
    "print('max sent num: {}'.format(max_sentnum))\n",
    "print('max prompt sent length: {}'.format(prompt_max_sentlen))\n",
    "print('max prompt sent num: {}'.format(prompt_max_sentnum))\n",
    "\n",
    "train_data['y_scaled'] = get_scaled_down_scores(train_data['data_y'], train_data['prompt_ids'])\n",
    "dev_data['y_scaled'] = get_scaled_down_scores(dev_data['data_y'], dev_data['prompt_ids'])\n",
    "test_data['y_scaled'] = get_scaled_down_scores(test_data['data_y'], test_data['prompt_ids'])\n",
    "\n",
    "X_train_pos = pad_hierarchical_text_sequences(train_data['pos_x'], max_sentnum, max_sentlen)\n",
    "X_dev_pos = pad_hierarchical_text_sequences(dev_data['pos_x'], max_sentnum, max_sentlen)\n",
    "X_test_pos = pad_hierarchical_text_sequences(test_data['pos_x'], max_sentnum, max_sentlen)\n",
    "\n",
    "X_train_pos = X_train_pos.reshape((X_train_pos.shape[0], X_train_pos.shape[1] * X_train_pos.shape[2]))\n",
    "X_dev_pos = X_dev_pos.reshape((X_dev_pos.shape[0], X_dev_pos.shape[1] * X_dev_pos.shape[2]))\n",
    "X_test_pos = X_test_pos.reshape((X_test_pos.shape[0], X_test_pos.shape[1] * X_test_pos.shape[2]))\n",
    "\n",
    "X_train_prompt = pad_hierarchical_text_sequences(train_data['prompt_words'], max_sentnum, max_sentlen)\n",
    "X_dev_prompt = pad_hierarchical_text_sequences(dev_data['prompt_words'], max_sentnum, max_sentlen)\n",
    "X_test_prompt = pad_hierarchical_text_sequences(test_data['prompt_words'], max_sentnum, max_sentlen)\n",
    "\n",
    "X_train_prompt = X_train_prompt.reshape((X_train_prompt.shape[0], X_train_prompt.shape[1] * X_train_prompt.shape[2]))\n",
    "X_dev_prompt = X_dev_prompt.reshape((X_dev_prompt.shape[0], X_dev_prompt.shape[1] * X_dev_prompt.shape[2]))\n",
    "X_test_prompt = X_test_prompt.reshape((X_test_prompt.shape[0], X_test_prompt.shape[1] * X_test_prompt.shape[2]))\n",
    "\n",
    "X_train_prompt_pos = pad_hierarchical_text_sequences(train_data['prompt_pos'], max_sentnum, max_sentlen)\n",
    "X_dev_prompt_pos = pad_hierarchical_text_sequences(dev_data['prompt_pos'], max_sentnum, max_sentlen)\n",
    "X_test_prompt_pos = pad_hierarchical_text_sequences(test_data['prompt_pos'], max_sentnum, max_sentlen)\n",
    "\n",
    "X_train_prompt_pos = X_train_prompt_pos.reshape((X_train_prompt_pos.shape[0], X_train_prompt_pos.shape[1] * X_train_prompt_pos.shape[2]))\n",
    "X_dev_prompt_pos = X_dev_prompt_pos.reshape((X_dev_prompt_pos.shape[0], X_dev_prompt_pos.shape[1] * X_dev_prompt_pos.shape[2]))\n",
    "X_test_prompt_pos = X_test_prompt_pos.reshape((X_test_prompt_pos.shape[0], X_test_prompt_pos.shape[1] * X_test_prompt_pos.shape[2]))\n",
    "\n",
    "X_train_linguistic_features = np.array(train_data['features_x'])\n",
    "X_dev_linguistic_features = np.array(dev_data['features_x'])\n",
    "X_test_linguistic_features = np.array(test_data['features_x'])\n",
    "\n",
    "X_train_readability = np.array(train_data['readability_x'])\n",
    "X_dev_readability = np.array(dev_data['readability_x'])\n",
    "X_test_readability = np.array(test_data['readability_x'])\n",
    "\n",
    "Y_train = np.array(train_data['y_scaled'])\n",
    "Y_dev = np.array(dev_data['y_scaled'])\n",
    "Y_test = np.array(test_data['y_scaled'])\n",
    "\n",
    "X_train_attribute_rel = get_attribute_masks(Y_train)\n",
    "X_dev_attribute_rel = get_attribute_masks(Y_dev)\n",
    "X_test_attribute_rel = get_attribute_masks(Y_test)\n",
    "\n",
    "print('================================')\n",
    "print('X_train_pos: ', X_train_pos.shape)\n",
    "print('X_train_prompt_words: ', X_train_prompt.shape)\n",
    "print('X_train_prompt_pos: ', X_train_prompt_pos.shape)\n",
    "print('X_train_readability: ', X_train_readability.shape)\n",
    "print('X_train_ling: ', X_train_linguistic_features.shape)\n",
    "print('X_train_attribute_rel: ', X_train_attribute_rel.shape)\n",
    "print('Y_train: ', Y_train.shape)\n",
    "\n",
    "print('================================')\n",
    "print('X_dev_pos: ', X_dev_pos.shape)\n",
    "print('X_dev_prompt_words: ', X_dev_prompt.shape)\n",
    "print('X_dev_prompt_pos: ', X_dev_prompt_pos.shape)\n",
    "print('X_dev_readability: ', X_dev_readability.shape)\n",
    "print('X_dev_ling: ', X_dev_linguistic_features.shape)\n",
    "print('X_dev_attribute_rel: ', X_dev_attribute_rel.shape)\n",
    "print('Y_dev: ', Y_dev.shape)\n",
    "\n",
    "print('================================')\n",
    "print('X_test_pos: ', X_test_pos.shape)\n",
    "print('X_test_prompt_words: ', X_test_prompt.shape)\n",
    "print('X_test_prompt_pos: ', X_test_prompt_pos.shape)\n",
    "print('X_test_readability: ', X_test_readability.shape)\n",
    "print('X_test_ling: ', X_test_linguistic_features.shape)\n",
    "print('X_test_attribute_rel: ', X_test_attribute_rel.shape)\n",
    "print('Y_test: ', Y_test.shape)\n",
    "print('================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc4092c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_ids</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_pos</th>\n",
       "      <th>readability_x</th>\n",
       "      <th>features_x</th>\n",
       "      <th>data_y</th>\n",
       "      <th>prompt_ids</th>\n",
       "      <th>max_sentnum</th>\n",
       "      <th>max_sentlen</th>\n",
       "      <th>y_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7532</td>\n",
       "      <td>[[2, 3, 4, 2, 5, 6, 2, 5, 4, 7, 3, 8], [9, 5, ...</td>\n",
       "      <td>[[662, 2552, 736, 281, 165, 319, 106, 4], [255...</td>\n",
       "      <td>[[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...</td>\n",
       "      <td>[0.49193152567610715, 0.29664566400513215, 0.5...</td>\n",
       "      <td>[0.4506668631640999, 0.3840642800992836, 0.062...</td>\n",
       "      <td>[1, 1, -1, -1, -1, -1, 1, 1, 1]</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.3333333333333333, 0.3333333333333333, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7229</td>\n",
       "      <td>[[2, 3, 4, 2, 5, 20, 2, 11, 7, 5, 4, 2, 5, 8],...</td>\n",
       "      <td>[[662, 2552, 736, 281, 165, 319, 106, 4], [255...</td>\n",
       "      <td>[[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...</td>\n",
       "      <td>[0.5579662498866749, 0.37479701404401994, 0.59...</td>\n",
       "      <td>[0.4513708636511923, 0.3586686128111479, 0.085...</td>\n",
       "      <td>[3, 3, -1, -1, -1, -1, 3, 3, 2]</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "      <td>[1.0, 1.0, -1, -1, -1, -1, 1.0, 1.0, 0.6666666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4154</td>\n",
       "      <td>[[9, 4, 2, 3, 4, 2, 29, 3, 4, 29, 3, 10, 5, 4,...</td>\n",
       "      <td>[[218, 125, 4], [122, 72, 73, 340, 1007, 124, ...</td>\n",
       "      <td>[[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8]...</td>\n",
       "      <td>[0.8612956765106549, 0.7423848792139746, 0.619...</td>\n",
       "      <td>[0.5640345883998679, 0.2858415150037477, 0.066...</td>\n",
       "      <td>[4, 4, 4, 4, 5, 4, -1, -1, -1]</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.6, 0.6, 0.6, 0.6, 0.8, 0.6, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17950</td>\n",
       "      <td>[[12, 5, 10, 7, 13, 18, 24, 18, 3, 18, 20, 18,...</td>\n",
       "      <td>[[662, 248, 4], [133, 405, 1090, 2011, 4], [13...</td>\n",
       "      <td>[[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, ...</td>\n",
       "      <td>[0.20688685950461458, 0.1460481802533566, 0.35...</td>\n",
       "      <td>[0.21863912823111997, 0.1030009415010439, 0.04...</td>\n",
       "      <td>[11, 2, 2, -1, -1, 4, -1, -1, -1]</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.36666666666666664, 0.3333333333333333, 0.33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9785</td>\n",
       "      <td>[[2, 5, 10, 2, 5, 4, 2, 5, 4, 14, 2, 11, 7, 12...</td>\n",
       "      <td>[[90, 271, 131, 84, 4], [190, 108, 150, 814, 8...</td>\n",
       "      <td>[[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6...</td>\n",
       "      <td>[0.7090757475733677, 0.48555603009134607, 0.79...</td>\n",
       "      <td>[0.5980343980343981, 0.5082625502524476, 0.090...</td>\n",
       "      <td>[1, 1, -1, -1, -1, -1, 1, 1, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.3333333333333333, 0.3333333333333333, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9508</th>\n",
       "      <td>6877</td>\n",
       "      <td>[[4, 2, 5, 4, 5, 11, 20, 11, 18, 16, 7, 4, 29,...</td>\n",
       "      <td>[[662, 2552, 736, 281, 165, 319, 106, 4], [255...</td>\n",
       "      <td>[[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...</td>\n",
       "      <td>[0.6420710849952196, 0.4709075862939792, 0.767...</td>\n",
       "      <td>[0.5665003864259118, 0.4089167978068259, 0.093...</td>\n",
       "      <td>[2, 2, -1, -1, -1, -1, 2, 1, 1]</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.6666666666666666, 0.6666666666666666, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9509</th>\n",
       "      <td>3661</td>\n",
       "      <td>[[5, 28, 2, 5, 4, 12, 7, 3, 4, 2, 7, 5, 8], [1...</td>\n",
       "      <td>[[218, 125, 4], [122, 72, 73, 340, 1007, 124, ...</td>\n",
       "      <td>[[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8]...</td>\n",
       "      <td>[0.7470330548911367, 0.5322450678768516, 0.688...</td>\n",
       "      <td>[0.7336936048109188, 0.3952062286100636, 0.031...</td>\n",
       "      <td>[4, 5, 4, 4, 5, 4, -1, -1, -1]</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.6, 0.8, 0.6, 0.6, 0.8, 0.6, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510</th>\n",
       "      <td>10364</td>\n",
       "      <td>[[4, 15, 20, 11, 24, 5, 6, 11, 13, 18, 24, 4, ...</td>\n",
       "      <td>[[90, 271, 131, 84, 4], [190, 108, 150, 814, 8...</td>\n",
       "      <td>[[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6...</td>\n",
       "      <td>[0.6775704345317742, 0.5015464633073149, 0.707...</td>\n",
       "      <td>[0.44895975111802455, 0.27287771704373115, 0.1...</td>\n",
       "      <td>[1, 1, -1, -1, -1, -1, 1, 1, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.3333333333333333, 0.3333333333333333, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9511</th>\n",
       "      <td>18367</td>\n",
       "      <td>[[9, 5, 14, 5, 6, 14, 3, 22, 5, 6, 15, 8], [14...</td>\n",
       "      <td>[[662, 248, 4], [133, 405, 1090, 2011, 4], [13...</td>\n",
       "      <td>[[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, ...</td>\n",
       "      <td>[0.4465909693384573, 0.375902607097603, 0.5005...</td>\n",
       "      <td>[0.2542676650242186, 0.08406393382610401, 0.09...</td>\n",
       "      <td>[18, 5, 5, -1, -1, 4, -1, -1, -1]</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.6, 0.8333333333333334, 0.8333333333333334, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9512</th>\n",
       "      <td>15347</td>\n",
       "      <td>[[4, 12, 22, 12, 2, 5, 5, 4, 2, 5, 5, 5, 24, 2...</td>\n",
       "      <td>[[756, 446, 1528, 178, 149, 113, 107, 56, 180,...</td>\n",
       "      <td>[[16, 7, 7, 3, 3, 20, 5, 5, 6, 12, 7, 3, 5, 8]...</td>\n",
       "      <td>[0.6385888045704757, 0.40596380660143777, 0.50...</td>\n",
       "      <td>[0.34372244585010514, 0.12172169029380711, 0.1...</td>\n",
       "      <td>[2, 1, -1, -1, -1, -1, 1, 1, 1]</td>\n",
       "      <td>6</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.5, 0.25, -1, -1, -1, -1, 0.25, 0.25, 0.25]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9513 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_ids                                              pos_x   \n",
       "0          7532  [[2, 3, 4, 2, 5, 6, 2, 5, 4, 7, 3, 8], [9, 5, ...  \\\n",
       "1          7229  [[2, 3, 4, 2, 5, 20, 2, 11, 7, 5, 4, 2, 5, 8],...   \n",
       "2          4154  [[9, 4, 2, 3, 4, 2, 29, 3, 4, 29, 3, 10, 5, 4,...   \n",
       "3         17950  [[12, 5, 10, 7, 13, 18, 24, 18, 3, 18, 20, 18,...   \n",
       "4          9785  [[2, 5, 10, 2, 5, 4, 2, 5, 4, 14, 2, 11, 7, 12...   \n",
       "...         ...                                                ...   \n",
       "9508       6877  [[4, 2, 5, 4, 5, 11, 20, 11, 18, 16, 7, 4, 29,...   \n",
       "9509       3661  [[5, 28, 2, 5, 4, 12, 7, 3, 4, 2, 7, 5, 8], [1...   \n",
       "9510      10364  [[4, 15, 20, 11, 24, 5, 6, 11, 13, 18, 24, 4, ...   \n",
       "9511      18367  [[9, 5, 14, 5, 6, 14, 3, 22, 5, 6, 15, 8], [14...   \n",
       "9512      15347  [[4, 12, 22, 12, 2, 5, 5, 4, 2, 5, 5, 5, 24, 2...   \n",
       "\n",
       "                                           prompt_words   \n",
       "0     [[662, 2552, 736, 281, 165, 319, 106, 4], [255...  \\\n",
       "1     [[662, 2552, 736, 281, 165, 319, 106, 4], [255...   \n",
       "2     [[218, 125, 4], [122, 72, 73, 340, 1007, 124, ...   \n",
       "3     [[662, 248, 4], [133, 405, 1090, 2011, 4], [13...   \n",
       "4     [[90, 271, 131, 84, 4], [190, 108, 150, 814, 8...   \n",
       "...                                                 ...   \n",
       "9508  [[662, 2552, 736, 281, 165, 319, 106, 4], [255...   \n",
       "9509  [[218, 125, 4], [122, 72, 73, 340, 1007, 124, ...   \n",
       "9510  [[90, 271, 131, 84, 4], [190, 108, 150, 814, 8...   \n",
       "9511  [[662, 248, 4], [133, 405, 1090, 2011, 4], [13...   \n",
       "9512  [[756, 446, 1528, 178, 149, 113, 107, 56, 180,...   \n",
       "\n",
       "                                             prompt_pos   \n",
       "0     [[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...  \\\n",
       "1     [[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...   \n",
       "2     [[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8]...   \n",
       "3     [[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, ...   \n",
       "4     [[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6...   \n",
       "...                                                 ...   \n",
       "9508  [[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...   \n",
       "9509  [[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8]...   \n",
       "9510  [[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6...   \n",
       "9511  [[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, ...   \n",
       "9512  [[16, 7, 7, 3, 3, 20, 5, 5, 6, 12, 7, 3, 5, 8]...   \n",
       "\n",
       "                                          readability_x   \n",
       "0     [0.49193152567610715, 0.29664566400513215, 0.5...  \\\n",
       "1     [0.5579662498866749, 0.37479701404401994, 0.59...   \n",
       "2     [0.8612956765106549, 0.7423848792139746, 0.619...   \n",
       "3     [0.20688685950461458, 0.1460481802533566, 0.35...   \n",
       "4     [0.7090757475733677, 0.48555603009134607, 0.79...   \n",
       "...                                                 ...   \n",
       "9508  [0.6420710849952196, 0.4709075862939792, 0.767...   \n",
       "9509  [0.7470330548911367, 0.5322450678768516, 0.688...   \n",
       "9510  [0.6775704345317742, 0.5015464633073149, 0.707...   \n",
       "9511  [0.4465909693384573, 0.375902607097603, 0.5005...   \n",
       "9512  [0.6385888045704757, 0.40596380660143777, 0.50...   \n",
       "\n",
       "                                             features_x   \n",
       "0     [0.4506668631640999, 0.3840642800992836, 0.062...  \\\n",
       "1     [0.4513708636511923, 0.3586686128111479, 0.085...   \n",
       "2     [0.5640345883998679, 0.2858415150037477, 0.066...   \n",
       "3     [0.21863912823111997, 0.1030009415010439, 0.04...   \n",
       "4     [0.5980343980343981, 0.5082625502524476, 0.090...   \n",
       "...                                                 ...   \n",
       "9508  [0.5665003864259118, 0.4089167978068259, 0.093...   \n",
       "9509  [0.7336936048109188, 0.3952062286100636, 0.031...   \n",
       "9510  [0.44895975111802455, 0.27287771704373115, 0.1...   \n",
       "9511  [0.2542676650242186, 0.08406393382610401, 0.09...   \n",
       "9512  [0.34372244585010514, 0.12172169029380711, 0.1...   \n",
       "\n",
       "                                 data_y  prompt_ids  max_sentnum  max_sentlen   \n",
       "0       [1, 1, -1, -1, -1, -1, 1, 1, 1]           3           97           50  \\\n",
       "1       [3, 3, -1, -1, -1, -1, 3, 3, 2]           3           97           50   \n",
       "2        [4, 4, 4, 4, 5, 4, -1, -1, -1]           2           97           50   \n",
       "3     [11, 2, 2, -1, -1, 4, -1, -1, -1]           7           97           50   \n",
       "4       [1, 1, -1, -1, -1, -1, 1, 1, 1]           4           97           50   \n",
       "...                                 ...         ...          ...          ...   \n",
       "9508    [2, 2, -1, -1, -1, -1, 2, 1, 1]           3           97           50   \n",
       "9509     [4, 5, 4, 4, 5, 4, -1, -1, -1]           2           97           50   \n",
       "9510    [1, 1, -1, -1, -1, -1, 1, 1, 1]           4           97           50   \n",
       "9511  [18, 5, 5, -1, -1, 4, -1, -1, -1]           7           97           50   \n",
       "9512    [2, 1, -1, -1, -1, -1, 1, 1, 1]           6           97           50   \n",
       "\n",
       "                                               y_scaled  \n",
       "0     [0.3333333333333333, 0.3333333333333333, -1, -...  \n",
       "1     [1.0, 1.0, -1, -1, -1, -1, 1.0, 1.0, 0.6666666...  \n",
       "2            [0.6, 0.6, 0.6, 0.6, 0.8, 0.6, -1, -1, -1]  \n",
       "3     [0.36666666666666664, 0.3333333333333333, 0.33...  \n",
       "4     [0.3333333333333333, 0.3333333333333333, -1, -...  \n",
       "...                                                 ...  \n",
       "9508  [0.6666666666666666, 0.6666666666666666, -1, -...  \n",
       "9509         [0.6, 0.8, 0.6, 0.6, 0.8, 0.6, -1, -1, -1]  \n",
       "9510  [0.3333333333333333, 0.3333333333333333, -1, -...  \n",
       "9511  [0.6, 0.8333333333333334, 0.8333333333333334, ...  \n",
       "9512      [0.5, 0.25, -1, -1, -1, -1, 0.25, 0.25, 0.25]  \n",
       "\n",
       "[9513 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "745a6704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3,  4, ...,  0,  0,  0],\n",
       "       [ 2,  3,  4, ...,  0,  0,  0],\n",
       "       [ 9,  4,  2, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 4, 15, 20, ...,  0,  0,  0],\n",
       "       [ 9,  5, 14, ...,  0,  0,  0],\n",
       "       [ 4, 12, 22, ...,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_features_list = [X_train_pos, X_train_prompt, X_train_prompt_pos, X_train_linguistic_features, X_train_readability]\n",
    "X_train_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1331a5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33333333,  0.33333333, -1.        , -1.        , -1.        ,\n",
       "       -1.        ,  0.33333333,  0.33333333,  0.33333333])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b1f527d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55cd0505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " prompt_word_input (InputLa  [(None, 4850)]               0         []                            \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " prompt_pos_input (InputLay  [(None, 4850)]               0         []                            \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)      [(None, 4850)]               0         []                            \n",
      "                                                                                                  \n",
      " prompt (Embedding)          (None, 4850, 50)             200000    ['prompt_word_input[0][0]']   \n",
      "                                                                                                  \n",
      " pos_prompt (Embedding)      (None, 4850, 50)             1800      ['prompt_pos_input[0][0]']    \n",
      "                                                                                                  \n",
      " pos_x (Embedding)           (None, 4850, 50)             1800      ['pos_input[0][0]']           \n",
      "                                                                                                  \n",
      " prompt_maskedout (ZeroMask  (None, 4850, 50)             0         ['prompt[0][0]']              \n",
      " edEntries)                                                                                       \n",
      "                                                                                                  \n",
      " prompt_pos_maskedout (Zero  (None, 4850, 50)             0         ['pos_prompt[0][0]']          \n",
      " MaskedEntries)                                                                                   \n",
      "                                                                                                  \n",
      " pos_x_maskedout (ZeroMaske  (None, 4850, 50)             0         ['pos_x[0][0]']               \n",
      " dEntries)                                                                                        \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 4850, 50)             0         ['prompt_maskedout[0][0]',    \n",
      "                                                                     'prompt_pos_maskedout[0][0]']\n",
      "                                                                                                  \n",
      " pos_drop_x (Dropout)        (None, 4850, 50)             0         ['pos_x_maskedout[0][0]']     \n",
      "                                                                                                  \n",
      " prompt_drop_x (Dropout)     (None, 4850, 50)             0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " pos_resh_W (Reshape)        (None, 97, 50, 50)           0         ['pos_drop_x[0][0]']          \n",
      "                                                                                                  \n",
      " prompt_resh_W (Reshape)     (None, 97, 50, 50)           0         ['prompt_drop_x[0][0]']       \n",
      "                                                                                                  \n",
      " pos_zcnn (TimeDistributed)  (None, 97, 46, 100)          25100     ['pos_resh_W[0][0]']          \n",
      "                                                                                                  \n",
      " prompt_zcnn (TimeDistribut  (None, 97, 46, 100)          25100     ['prompt_resh_W[0][0]']       \n",
      " ed)                                                                                              \n",
      "                                                                                                  \n",
      " pos_avg_zcnn (TimeDistribu  (None, 97, 100)              10100     ['pos_zcnn[0][0]']            \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " prompt_avg_zcnn (TimeDistr  (None, 97, 100)              10100     ['prompt_zcnn[0][0]']         \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " iHeadAttention)                                                                                  \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (Mu  (None, None, 100)            40400     ['prompt_avg_zcnn[0][0]']     \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, None, 100)            80400     ['multi_head_attention[0][0]']\n",
      "                                                                                                  \n",
      " lstm_9 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_9[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lstm_1 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_8 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_8[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, 100)                  10100     ['lstm[0][0]']                \n",
      "                                                                                                  \n",
      " attention_11 (Attention)    (None, 100)                  10100     ['lstm_9[0][0]']              \n",
      "                                                                                                  \n",
      " attention_2 (Attention)     (None, 100)                  10100     ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      " attention_3 (Attention)     (None, 100)                  10100     ['lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      " attention_4 (Attention)     (None, 100)                  10100     ['lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      " attention_5 (Attention)     (None, 100)                  10100     ['lstm_4[0][0]']              \n",
      "                                                                                                  \n",
      " attention_6 (Attention)     (None, 100)                  10100     ['lstm_5[0][0]']              \n",
      "                                                                                                  \n",
      " attention_7 (Attention)     (None, 100)                  10100     ['lstm_6[0][0]']              \n",
      "                                                                                                  \n",
      " attention_8 (Attention)     (None, 100)                  10100     ['lstm_7[0][0]']              \n",
      "                                                                                                  \n",
      " attention_9 (Attention)     (None, 100)                  10100     ['lstm_8[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_pe (M  (None, None, 100)            40400     ['attention_1[0][0]',         \n",
      " ultiHeadAttention_PE)                                               'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " multi_head_attention_pe_1   (None, None, 100)            40400     ['attention_2[0][0]',         \n",
      " (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " multi_head_attention_pe_2   (None, None, 100)            40400     ['attention_3[0][0]',         \n",
      " (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " multi_head_attention_pe_3   (None, None, 100)            40400     ['attention_4[0][0]',         \n",
      " (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " multi_head_attention_pe_4   (None, None, 100)            40400     ['attention_5[0][0]',         \n",
      " (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " multi_head_attention_pe_5   (None, None, 100)            40400     ['attention_6[0][0]',         \n",
      " (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " multi_head_attention_pe_6   (None, None, 100)            40400     ['attention_7[0][0]',         \n",
      " (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " multi_head_attention_pe_7   (None, None, 100)            40400     ['attention_8[0][0]',         \n",
      " (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " multi_head_attention_pe_8   (None, None, 100)            40400     ['attention_9[0][0]',         \n",
      " (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " lstm_10 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " lstm_11 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe_1[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " lstm_12 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe_2[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " lstm_13 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe_3[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lstm_14 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe_4[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " lstm_15 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe_5[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " lstm_16 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe_6[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " lstm_17 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe_7[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " lstm_18 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe_8[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " attention_12 (Attention)    (None, 100)                  10100     ['lstm_10[0][0]']             \n",
      "                                                                                                  \n",
      " linguistic_input (InputLay  [(None, 51)]                 0         []                            \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " readability_input (InputLa  [(None, 35)]                 0         []                            \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " attention_13 (Attention)    (None, 100)                  10100     ['lstm_11[0][0]']             \n",
      "                                                                                                  \n",
      " attention_14 (Attention)    (None, 100)                  10100     ['lstm_12[0][0]']             \n",
      "                                                                                                  \n",
      " attention_15 (Attention)    (None, 100)                  10100     ['lstm_13[0][0]']             \n",
      "                                                                                                  \n",
      " attention_16 (Attention)    (None, 100)                  10100     ['lstm_14[0][0]']             \n",
      "                                                                                                  \n",
      " attention_17 (Attention)    (None, 100)                  10100     ['lstm_15[0][0]']             \n",
      "                                                                                                  \n",
      " attention_18 (Attention)    (None, 100)                  10100     ['lstm_16[0][0]']             \n",
      "                                                                                                  \n",
      " attention_19 (Attention)    (None, 100)                  10100     ['lstm_17[0][0]']             \n",
      "                                                                                                  \n",
      " attention_20 (Attention)    (None, 100)                  10100     ['lstm_18[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 186)                  0         ['attention_12[0][0]',        \n",
      "                                                                     'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 186)                  0         ['attention_13[0][0]',        \n",
      " )                                                                   'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 186)                  0         ['attention_14[0][0]',        \n",
      " )                                                                   'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 186)                  0         ['attention_15[0][0]',        \n",
      " )                                                                   'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 186)                  0         ['attention_16[0][0]',        \n",
      " )                                                                   'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 186)                  0         ['attention_17[0][0]',        \n",
      " )                                                                   'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 186)                  0         ['attention_18[0][0]',        \n",
      " )                                                                   'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 186)                  0         ['attention_19[0][0]',        \n",
      " )                                                                   'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate  (None, 186)                  0         ['attention_20[0][0]',        \n",
      " )                                                                   'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 1, 186)               0         ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 1, 186)               0         ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)         (None, 1, 186)               0         ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)         (None, 1, 186)               0         ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " reshape_4 (Reshape)         (None, 1, 186)               0         ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)         (None, 1, 186)               0         ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)         (None, 1, 186)               0         ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)         (None, 1, 186)               0         ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_8 (Reshape)         (None, 1, 186)               0         ['concatenate_8[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate  (None, 9, 186)               0         ['reshape[0][0]',             \n",
      " )                                                                   'reshape_1[0][0]',           \n",
      "                                                                     'reshape_2[0][0]',           \n",
      "                                                                     'reshape_3[0][0]',           \n",
      "                                                                     'reshape_4[0][0]',           \n",
      "                                                                     'reshape_5[0][0]',           \n",
      "                                                                     'reshape_6[0][0]',           \n",
      "                                                                     'reshape_7[0][0]',           \n",
      "                                                                     'reshape_8[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " masked_selection (MaskedSe  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
      " lection)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " masked_selection_1 (Masked  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
      " Selection)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " masked_selection_2 (Masked  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
      " Selection)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " masked_selection_3 (Masked  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
      " Selection)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " masked_selection_4 (Masked  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
      " Selection)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " masked_selection_5 (Masked  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
      " Selection)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " masked_selection_6 (Masked  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
      " Selection)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " masked_selection_7 (Masked  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
      " Selection)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_8  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " masked_selection_8 (Masked  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
      " Selection)                                                                                       \n",
      "                                                                                                  \n",
      " attention_21 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'masked_selection[0][0]']    \n",
      "                                                                                                  \n",
      " attention_22 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'masked_selection_1[0][0]']  \n",
      "                                                                                                  \n",
      " attention_23 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_2[0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                    ][0]',                        \n",
      "                                                                     'masked_selection_2[0][0]']  \n",
      "                                                                                                  \n",
      " attention_24 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_3[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'masked_selection_3[0][0]']  \n",
      "                                                                                                  \n",
      " attention_25 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'masked_selection_4[0][0]']  \n",
      "                                                                                                  \n",
      " attention_26 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_5[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'masked_selection_5[0][0]']  \n",
      "                                                                                                  \n",
      " attention_27 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_6[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'masked_selection_6[0][0]']  \n",
      "                                                                                                  \n",
      " attention_28 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_7[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'masked_selection_7[0][0]']  \n",
      "                                                                                                  \n",
      " attention_29 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_8[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'masked_selection_8[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem[0][\n",
      " e)                                                                 0]',                          \n",
      "                                                                     'attention_21[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem_1[0\n",
      " e)                                                                 ][0]',                        \n",
      "                                                                     'attention_22[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem_2[0\n",
      " e)                                                                 ][0]',                        \n",
      "                                                                     'attention_23[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem_3[0\n",
      " e)                                                                 ][0]',                        \n",
      "                                                                     'attention_24[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem_4[0\n",
      " e)                                                                 ][0]',                        \n",
      "                                                                     'attention_25[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem_5[0\n",
      " e)                                                                 ][0]',                        \n",
      "                                                                     'attention_26[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem_6[0\n",
      " e)                                                                 ][0]',                        \n",
      "                                                                     'attention_27[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem_7[0\n",
      " e)                                                                 ][0]',                        \n",
      "                                                                     'attention_28[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem_8[0\n",
      " e)                                                                 ][0]',                        \n",
      "                                                                     'attention_29[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 372)                  0         ['concatenate_10[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 372)                  0         ['concatenate_11[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 372)                  0         ['concatenate_12[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)         (None, 372)                  0         ['concatenate_13[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)         (None, 372)                  0         ['concatenate_14[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)         (None, 372)                  0         ['concatenate_15[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)         (None, 372)                  0         ['concatenate_16[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)         (None, 372)                  0         ['concatenate_17[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)         (None, 372)                  0         ['concatenate_18[0][0]']      \n",
      "                                                                                                  \n",
      " dense_76 (Dense)            (None, 1)                    373       ['flatten[0][0]']             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_77 (Dense)            (None, 1)                    373       ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_78 (Dense)            (None, 1)                    373       ['flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_79 (Dense)            (None, 1)                    373       ['flatten_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_80 (Dense)            (None, 1)                    373       ['flatten_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_81 (Dense)            (None, 1)                    373       ['flatten_5[0][0]']           \n",
      "                                                                                                  \n",
      " dense_82 (Dense)            (None, 1)                    373       ['flatten_6[0][0]']           \n",
      "                                                                                                  \n",
      " dense_83 (Dense)            (None, 1)                    373       ['flatten_7[0][0]']           \n",
      "                                                                                                  \n",
      " dense_84 (Dense)            (None, 1)                    373       ['flatten_8[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenat  (None, 9)                    0         ['dense_76[0][0]',            \n",
      " e)                                                                  'dense_77[0][0]',            \n",
      "                                                                     'dense_78[0][0]',            \n",
      "                                                                     'dense_79[0][0]',            \n",
      "                                                                     'dense_80[0][0]',            \n",
      "                                                                     'dense_81[0][0]',            \n",
      "                                                                     'dense_82[0][0]',            \n",
      "                                                                     'dense_83[0][0]',            \n",
      "                                                                     'dense_84[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2764457 (10.55 MB)\n",
      "Trainable params: 2764457 (10.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "53/53 [==============================] - 14s 187ms/step\n",
      "56/56 [==============================] - 11s 191ms/step\n",
      "CURRENT EPOCH: -1\n",
      "[DEV] AVG QWK: -0.007\n",
      "[DEV] score QWK: 0.102\n",
      "[DEV] content QWK: 0.059\n",
      "[DEV] organization QWK: -0.003\n",
      "[DEV] word_choice QWK: -0.078\n",
      "[DEV] sentence_fluency QWK: -0.145\n",
      "[DEV] conventions QWK: -0.005\n",
      "[DEV] prompt_adherence QWK: 0.089\n",
      "[DEV] language QWK: -0.038\n",
      "[DEV] narrativity QWK: -0.046\n",
      "------------------------\n",
      "[TEST] AVG QWK: -0.002\n",
      "[TEST] score QWK: 0.146\n",
      "[TEST] content QWK: 0.06\n",
      "[TEST] organization QWK: 0.007\n",
      "[TEST] word_choice QWK: -0.203\n",
      "[TEST] sentence_fluency QWK: -0.001\n",
      "[TEST] conventions QWK: -0.022\n",
      "------------------------\n",
      "[BEST TEST] AVG QWK: -0.002, {epoch}: -1\n",
      "[BEST TEST] score QWK: 0.146\n",
      "[BEST TEST] content QWK: 0.06\n",
      "[BEST TEST] organization QWK: 0.007\n",
      "[BEST TEST] word_choice QWK: -0.203\n",
      "[BEST TEST] sentence_fluency QWK: -0.001\n",
      "[BEST TEST] conventions QWK: -0.022\n",
      "--------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_features_list = [X_train_pos, X_train_prompt, X_train_prompt_pos, X_train_linguistic_features, X_train_readability]\n",
    "dev_features_list = [X_dev_pos, X_dev_prompt, X_dev_prompt_pos, X_dev_linguistic_features, X_dev_readability]\n",
    "test_features_list = [X_test_pos, X_test_prompt, X_test_prompt_pos, X_test_linguistic_features, X_test_readability]\n",
    "\n",
    "model = build_ProTACT(len(pos_vocab), len(word_vocab), max_sentnum, max_sentlen, \n",
    "                  X_train_readability.shape[1],\n",
    "                  X_train_linguistic_features.shape[1],\n",
    "                  configs, Y_train.shape[1], num_heads, embed_table)\n",
    "\n",
    "evaluator = AllAttEvaluator(test_prompt_id, dev_data['prompt_ids'], test_data['prompt_ids'], dev_features_list,\n",
    "                            test_features_list, Y_dev, Y_test, seed)\n",
    "\n",
    "evaluator.evaluate(model, -1, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a9aac81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " prompt_word_input (InputLa  [(None, 4850)]               0         []                            \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " prompt_pos_input (InputLay  [(None, 4850)]               0         []                            \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)      [(None, 4850)]               0         []                            \n",
      "                                                                                                  \n",
      " prompt (Embedding)          (None, 4850, 50)             200000    ['prompt_word_input[0][0]']   \n",
      "                                                                                                  \n",
      " pos_prompt (Embedding)      (None, 4850, 50)             1800      ['prompt_pos_input[0][0]']    \n",
      "                                                                                                  \n",
      " pos_x (Embedding)           (None, 4850, 50)             1800      ['pos_input[0][0]']           \n",
      "                                                                                                  \n",
      " prompt_maskedout (ZeroMask  (None, 4850, 50)             0         ['prompt[0][0]']              \n",
      " edEntries)                                                                                       \n",
      "                                                                                                  \n",
      " prompt_pos_maskedout (Zero  (None, 4850, 50)             0         ['pos_prompt[0][0]']          \n",
      " MaskedEntries)                                                                                   \n",
      "                                                                                                  \n",
      " pos_x_maskedout (ZeroMaske  (None, 4850, 50)             0         ['pos_x[0][0]']               \n",
      " dEntries)                                                                                        \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 4850, 50)             0         ['prompt_maskedout[0][0]',    \n",
      "                                                                     'prompt_pos_maskedout[0][0]']\n",
      "                                                                                                  \n",
      " pos_drop_x (Dropout)        (None, 4850, 50)             0         ['pos_x_maskedout[0][0]']     \n",
      "                                                                                                  \n",
      " prompt_drop_x (Dropout)     (None, 4850, 50)             0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " pos_resh_W (Reshape)        (None, 97, 50, 50)           0         ['pos_drop_x[0][0]']          \n",
      "                                                                                                  \n",
      " prompt_resh_W (Reshape)     (None, 97, 50, 50)           0         ['prompt_drop_x[0][0]']       \n",
      "                                                                                                  \n",
      " pos_zcnn (TimeDistributed)  (None, 97, 46, 100)          25100     ['pos_resh_W[0][0]']          \n",
      "                                                                                                  \n",
      " prompt_zcnn (TimeDistribut  (None, 97, 46, 100)          25100     ['prompt_resh_W[0][0]']       \n",
      " ed)                                                                                              \n",
      "                                                                                                  \n",
      " pos_avg_zcnn (TimeDistribu  (None, 97, 100)              10100     ['pos_zcnn[0][0]']            \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " prompt_avg_zcnn (TimeDistr  (None, 97, 100)              10100     ['prompt_zcnn[0][0]']         \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " iHeadAttention)                                                                                  \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (Mu  (None, None, 100)            40400     ['prompt_avg_zcnn[0][0]']     \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (Mu  (None, None, 100)            40400     ['pos_avg_zcnn[0][0]']        \n",
      " ltiHeadAttention)                                                                                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, None, 100)            80400     ['multi_head_attention[0][0]']\n",
      "                                                                                                  \n",
      " lstm_9 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_9[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lstm_1 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_8 (LSTM)               (None, None, 100)            80400     ['multi_head_attention_8[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, 100)                  10100     ['lstm[0][0]']                \n",
      "                                                                                                  \n",
      " attention_11 (Attention)    (None, 100)                  10100     ['lstm_9[0][0]']              \n",
      "                                                                                                  \n",
      " attention_2 (Attention)     (None, 100)                  10100     ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      " attention_3 (Attention)     (None, 100)                  10100     ['lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      " attention_4 (Attention)     (None, 100)                  10100     ['lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      " attention_5 (Attention)     (None, 100)                  10100     ['lstm_4[0][0]']              \n",
      "                                                                                                  \n",
      " attention_6 (Attention)     (None, 100)                  10100     ['lstm_5[0][0]']              \n",
      "                                                                                                  \n",
      " attention_7 (Attention)     (None, 100)                  10100     ['lstm_6[0][0]']              \n",
      "                                                                                                  \n",
      " attention_8 (Attention)     (None, 100)                  10100     ['lstm_7[0][0]']              \n",
      "                                                                                                  \n",
      " attention_9 (Attention)     (None, 100)                  10100     ['lstm_8[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_pe (M  (None, None, 100)            40400     ['attention_1[0][0]',         \n",
      " ultiHeadAttention_PE)                                               'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " multi_head_attention_pe_1   (None, None, 100)            40400     ['attention_2[0][0]',         \n",
      " (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " multi_head_attention_pe_2   (None, None, 100)            40400     ['attention_3[0][0]',         \n",
      " (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " multi_head_attention_pe_3   (None, None, 100)            40400     ['attention_4[0][0]',         \n",
      " (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " multi_head_attention_pe_4   (None, None, 100)            40400     ['attention_5[0][0]',         \n",
      " (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " multi_head_attention_pe_5   (None, None, 100)            40400     ['attention_6[0][0]',         \n",
      " (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " multi_head_attention_pe_6   (None, None, 100)            40400     ['attention_7[0][0]',         \n",
      " (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " multi_head_attention_pe_7   (None, None, 100)            40400     ['attention_8[0][0]',         \n",
      " (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " multi_head_attention_pe_8   (None, None, 100)            40400     ['attention_9[0][0]',         \n",
      " (MultiHeadAttention_PE)                                             'attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " lstm_10 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " lstm_11 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe_1[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " lstm_12 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe_2[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " lstm_13 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe_3[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lstm_14 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe_4[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " lstm_15 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe_5[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " lstm_16 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe_6[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " lstm_17 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe_7[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " lstm_18 (LSTM)              (None, None, 100)            80400     ['multi_head_attention_pe_8[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " attention_12 (Attention)    (None, 100)                  10100     ['lstm_10[0][0]']             \n",
      "                                                                                                  \n",
      " linguistic_input (InputLay  [(None, 51)]                 0         []                            \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " readability_input (InputLa  [(None, 35)]                 0         []                            \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " attention_13 (Attention)    (None, 100)                  10100     ['lstm_11[0][0]']             \n",
      "                                                                                                  \n",
      " attention_14 (Attention)    (None, 100)                  10100     ['lstm_12[0][0]']             \n",
      "                                                                                                  \n",
      " attention_15 (Attention)    (None, 100)                  10100     ['lstm_13[0][0]']             \n",
      "                                                                                                  \n",
      " attention_16 (Attention)    (None, 100)                  10100     ['lstm_14[0][0]']             \n",
      "                                                                                                  \n",
      " attention_17 (Attention)    (None, 100)                  10100     ['lstm_15[0][0]']             \n",
      "                                                                                                  \n",
      " attention_18 (Attention)    (None, 100)                  10100     ['lstm_16[0][0]']             \n",
      "                                                                                                  \n",
      " attention_19 (Attention)    (None, 100)                  10100     ['lstm_17[0][0]']             \n",
      "                                                                                                  \n",
      " attention_20 (Attention)    (None, 100)                  10100     ['lstm_18[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 186)                  0         ['attention_12[0][0]',        \n",
      "                                                                     'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 186)                  0         ['attention_13[0][0]',        \n",
      " )                                                                   'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 186)                  0         ['attention_14[0][0]',        \n",
      " )                                                                   'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 186)                  0         ['attention_15[0][0]',        \n",
      " )                                                                   'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 186)                  0         ['attention_16[0][0]',        \n",
      " )                                                                   'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 186)                  0         ['attention_17[0][0]',        \n",
      " )                                                                   'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 186)                  0         ['attention_18[0][0]',        \n",
      " )                                                                   'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 186)                  0         ['attention_19[0][0]',        \n",
      " )                                                                   'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate  (None, 186)                  0         ['attention_20[0][0]',        \n",
      " )                                                                   'linguistic_input[0][0]',    \n",
      "                                                                     'readability_input[0][0]']   \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 1, 186)               0         ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 1, 186)               0         ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)         (None, 1, 186)               0         ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)         (None, 1, 186)               0         ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " reshape_4 (Reshape)         (None, 1, 186)               0         ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)         (None, 1, 186)               0         ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)         (None, 1, 186)               0         ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)         (None, 1, 186)               0         ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_8 (Reshape)         (None, 1, 186)               0         ['concatenate_8[0][0]']       \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)      (None, 9, 186)               0         ['reshape[0][0]',             \n",
      "                                                                     'reshape_1[0][0]',           \n",
      "                                                                     'reshape_2[0][0]',           \n",
      "                                                                     'reshape_3[0][0]',           \n",
      "                                                                     'reshape_4[0][0]',           \n",
      "                                                                     'reshape_5[0][0]',           \n",
      "                                                                     'reshape_6[0][0]',           \n",
      "                                                                     'reshape_7[0][0]',           \n",
      "                                                                     'reshape_8[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 1, 186)               0         ['tf.concat[0][0]']           \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.boolean_mask   (None, None, 186)            0         ['tf.concat[0][0]']           \n",
      " (SlicingOpLambda)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 1, 186)               0         ['tf.concat[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.boolean_mask_  (None, None, 186)            0         ['tf.concat[0][0]']           \n",
      " 1 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, 1, 186)               0         ['tf.concat[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.boolean_mask_  (None, None, 186)            0         ['tf.concat[0][0]']           \n",
      " 2 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 1, 186)               0         ['tf.concat[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.boolean_mask_  (None, None, 186)            0         ['tf.concat[0][0]']           \n",
      " 3 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4  (None, 1, 186)               0         ['tf.concat[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.boolean_mask_  (None, None, 186)            0         ['tf.concat[0][0]']           \n",
      " 4 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5  (None, 1, 186)               0         ['tf.concat[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.boolean_mask_  (None, None, 186)            0         ['tf.concat[0][0]']           \n",
      " 5 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6  (None, 1, 186)               0         ['tf.concat[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.boolean_mask_  (None, None, 186)            0         ['tf.concat[0][0]']           \n",
      " 6 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7  (None, 1, 186)               0         ['tf.concat[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.boolean_mask_  (None, None, 186)            0         ['tf.concat[0][0]']           \n",
      " 7 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_8  (None, 1, 186)               0         ['tf.concat[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.boolean_mask_  (None, None, 186)            0         ['tf.concat[0][0]']           \n",
      " 8 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " attention_21 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'tf.compat.v1.boolean_mask[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " attention_22 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.compat.v1.boolean_mask_1[\n",
      "                                                                    0][0]']                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " attention_23 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.compat.v1.boolean_mask_2[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " attention_24 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_3[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.compat.v1.boolean_mask_3[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " attention_25 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.compat.v1.boolean_mask_4[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " attention_26 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_5[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.compat.v1.boolean_mask_5[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " attention_27 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_6[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.compat.v1.boolean_mask_6[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " attention_28 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_7[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.compat.v1.boolean_mask_7[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " attention_29 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_8[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.compat.v1.boolean_mask_8[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'attention_21[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'attention_22[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'attention_23[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_4 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem_3[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'attention_24[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_5 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'attention_25[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_6 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem_5[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'attention_26[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_7 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem_6[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'attention_27[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_8 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem_7[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'attention_28[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_9 (TFOpLambda)    (None, 1, 372)               0         ['tf.__operators__.getitem_8[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'attention_29[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 372)                  0         ['tf.concat_1[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 372)                  0         ['tf.concat_2[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 372)                  0         ['tf.concat_3[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)         (None, 372)                  0         ['tf.concat_4[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)         (None, 372)                  0         ['tf.concat_5[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)         (None, 372)                  0         ['tf.concat_6[0][0]']         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " flatten_6 (Flatten)         (None, 372)                  0         ['tf.concat_7[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)         (None, 372)                  0         ['tf.concat_8[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)         (None, 372)                  0         ['tf.concat_9[0][0]']         \n",
      "                                                                                                  \n",
      " dense_76 (Dense)            (None, 1)                    373       ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_77 (Dense)            (None, 1)                    373       ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_78 (Dense)            (None, 1)                    373       ['flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_79 (Dense)            (None, 1)                    373       ['flatten_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_80 (Dense)            (None, 1)                    373       ['flatten_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_81 (Dense)            (None, 1)                    373       ['flatten_5[0][0]']           \n",
      "                                                                                                  \n",
      " dense_82 (Dense)            (None, 1)                    373       ['flatten_6[0][0]']           \n",
      "                                                                                                  \n",
      " dense_83 (Dense)            (None, 1)                    373       ['flatten_7[0][0]']           \n",
      "                                                                                                  \n",
      " dense_84 (Dense)            (None, 1)                    373       ['flatten_8[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate  (None, 9)                    0         ['dense_76[0][0]',            \n",
      " )                                                                   'dense_77[0][0]',            \n",
      "                                                                     'dense_78[0][0]',            \n",
      "                                                                     'dense_79[0][0]',            \n",
      "                                                                     'dense_80[0][0]',            \n",
      "                                                                     'dense_81[0][0]',            \n",
      "                                                                     'dense_82[0][0]',            \n",
      "                                                                     'dense_83[0][0]',            \n",
      "                                                                     'dense_84[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2764457 (10.55 MB)\n",
      "Trainable params: 2764457 (10.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b247461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomHistory(keras.callbacks.Callback):\n",
    "#     def init(self):\n",
    "#         self.train_loss = []\n",
    "#         self.val_loss = []\n",
    "#         self.train_acc = []\n",
    "#         self.val_acc = []        \n",
    "        \n",
    "#     def on_epoch_end(self, batch, logs={}):\n",
    "#         self.train_loss.append(logs.get('loss'))\n",
    "#         self.val_loss.append(logs.get('val_loss'))\n",
    "#         self.train_acc.append(logs.get('acc'))\n",
    "#         self.val_acc.append(logs.get('val_acc'))\n",
    "# custom_hist = CustomHistory()\n",
    "# custom_hist.init() \n",
    "\n",
    "#  for ii in range(epochs):\n",
    "#     print('Epoch %s/%s' % (str(ii + 1), epochs))\n",
    "#     start_time = time.time()\n",
    "#     model.fit(\n",
    "#         train_features_list,\n",
    "#         Y_train, batch_size=batch_size, epochs=5, verbose=0, shuffle=True, validation_data=(dev_features_list,Y_dev),callbacks=[custom_hist,checkpoint])\n",
    "#     tt_time = time.time() - start_time\n",
    "#     print(\"Training one epoch in %.3f s\" % tt_time)\n",
    "#     evaluator.evaluate(model, ii + 1)\n",
    "#     print(\"Train Loss: \", custom_hist.train_loss[-1], \"|| Val Loss: \", custom_hist.val_loss[-1])\n",
    "\n",
    "# evaluator.print_final_info()\n",
    "\n",
    "'''# show the loss as the graph\n",
    "fig, loss_graph = plt.subplots()\n",
    "loss_graph.plot(custom_hist.train_loss,'y',label='train loss')\n",
    "loss_graph.plot(custom_hist.val_loss,'r',label='val loss')\n",
    "loss_graph.set_xlabel('epoch')\n",
    "loss_graph.set_ylabel('loss')\n",
    "plt.savefig(str('images/protact/test_prompt_'+ str(test_prompt_id) + '_seed_' + str(seed) + '_loss.png'))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c5dd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장한 체크포인트 있다면: 이어서 학습 시작할때 \n",
    "# Checkpoint 폴더 안에 있는 .h5 파일 지울것\n",
    "# model.load_weights('Checkpoint/tensor{epoch}')\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    # epoch 마다 파일명 다르게 저장\n",
    "    filepath='Checkpoint/bestmodel{epoch}.h5',\n",
    "\n",
    "    # epoch 마다 weights 들만 저장\n",
    "    save_freq='epoch',\n",
    "    save_weights_only = True,\n",
    "\n",
    "    # validation accruary 가 최대일때만 저장 \n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb7f3c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "trait num:  9\n",
      "trait num:  9\n",
      "952/952 [==============================] - ETA: 0s - loss: 0.0163trait num:  9\n",
      "Epoch 1: Train Loss: 0.016327474266290665 || Val Loss: 0.013890832662582397\n",
      "Epoch 1 completed in 262.809 seconds\n",
      "53/53 [==============================] - 10s 182ms/step\n",
      "56/56 [==============================] - 10s 183ms/step\n",
      "CURRENT EPOCH: 1\n",
      "[DEV] AVG QWK: 0.626\n",
      "[DEV] score QWK: 0.733\n",
      "[DEV] content QWK: 0.616\n",
      "[DEV] organization QWK: 0.639\n",
      "[DEV] word_choice QWK: 0.541\n",
      "[DEV] sentence_fluency QWK: 0.554\n",
      "[DEV] conventions QWK: 0.617\n",
      "[DEV] prompt_adherence QWK: 0.645\n",
      "[DEV] language QWK: 0.647\n",
      "[DEV] narrativity QWK: 0.641\n",
      "------------------------\n",
      "[TEST] AVG QWK: 0.593\n",
      "[TEST] score QWK: 0.818\n",
      "[TEST] content QWK: 0.6\n",
      "[TEST] organization QWK: 0.536\n",
      "[TEST] word_choice QWK: 0.523\n",
      "[TEST] sentence_fluency QWK: 0.563\n",
      "[TEST] conventions QWK: 0.517\n",
      "------------------------\n",
      "[BEST TEST] AVG QWK: 0.593, {epoch}: 1\n",
      "[BEST TEST] score QWK: 0.818\n",
      "[BEST TEST] content QWK: 0.6\n",
      "[BEST TEST] organization QWK: 0.536\n",
      "[BEST TEST] word_choice QWK: 0.523\n",
      "[BEST TEST] sentence_fluency QWK: 0.563\n",
      "[BEST TEST] conventions QWK: 0.517\n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "952/952 [==============================] - 283s 268ms/step - loss: 0.0163 - val_loss: 0.0139\n",
      "Epoch 2/50\n",
      " 23/952 [..............................] - ETA: 3:26 - loss: 0.0131"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m         evaluator\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     25\u001b[0m custom_hist \u001b[38;5;241m=\u001b[39m CustomHistory()\n\u001b[0;32m---> 26\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_features_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdev_features_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_dev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcustom_hist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniforge3/envs/jup/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class CustomHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.train_acc = []\n",
    "        self.val_acc = [] \n",
    "        self.epoch_times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.train_loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        self.train_acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        epoch_time = time.time() - self.start_time\n",
    "        self.epoch_times.append(epoch_time)\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss: {logs.get('loss')} || Val Loss: {logs.get('val_loss')}\")\n",
    "        print(f\"Epoch {epoch + 1} completed in {epoch_time:.3f} seconds\")\n",
    "\n",
    "        # Evaluate the model (you might need to adjust this to your specific evaluation function)\n",
    "        evaluator.evaluate(self.model, epoch + 1)\n",
    "\n",
    "custom_hist = CustomHistory()\n",
    "model.fit(\n",
    "    train_features_list,\n",
    "    Y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    validation_data=(dev_features_list, Y_dev),\n",
    "    callbacks=[custom_hist, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01487fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 10s 188ms/step\n",
      "56/56 [==============================] - 10s 185ms/step\n",
      "CURRENT EPOCH: 1\n",
      "[DEV] AVG QWK: 0.626\n",
      "[DEV] score QWK: 0.733\n",
      "[DEV] content QWK: 0.616\n",
      "[DEV] organization QWK: 0.639\n",
      "[DEV] word_choice QWK: 0.541\n",
      "[DEV] sentence_fluency QWK: 0.554\n",
      "[DEV] conventions QWK: 0.617\n",
      "[DEV] prompt_adherence QWK: 0.645\n",
      "[DEV] language QWK: 0.647\n",
      "[DEV] narrativity QWK: 0.641\n",
      "------------------------\n",
      "[TEST] AVG QWK: 0.593\n",
      "[TEST] score QWK: 0.818\n",
      "[TEST] content QWK: 0.6\n",
      "[TEST] organization QWK: 0.536\n",
      "[TEST] word_choice QWK: 0.523\n",
      "[TEST] sentence_fluency QWK: 0.563\n",
      "[TEST] conventions QWK: 0.517\n",
      "------------------------\n",
      "[BEST TEST] AVG QWK: 0.593, {epoch}: 1\n",
      "[BEST TEST] score QWK: 0.818\n",
      "[BEST TEST] content QWK: 0.6\n",
      "[BEST TEST] organization QWK: 0.536\n",
      "[BEST TEST] word_choice QWK: 0.523\n",
      "[BEST TEST] sentence_fluency QWK: 0.563\n",
      "[BEST TEST] conventions QWK: 0.517\n",
      "--------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 실행 X\n",
    "# TEST: 위에서 진행된곳 까지 결과가 같다.\n",
    "model.load_weights('Checkpoint/bestmodel1.h5')\n",
    "evaluator.evaluate(model,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de4013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
