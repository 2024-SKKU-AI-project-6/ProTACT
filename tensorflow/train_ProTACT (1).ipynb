{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Colab Notebook/인지프/ProTACT 프로젝트/ProTACT2/tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiMIVkZgxCKw",
        "outputId": "23d95205-1af5-41df-f35d-1a69a6b695eb"
      },
      "id": "OiMIVkZgxCKw",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebook/인지프/ProTACT 프로젝트/ProTACT2/tensorflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ade1964c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ade1964c",
        "outputId": "b932228c-4227-4bd9-bdaf-93d4d5cef4ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "# Load autoreload extension\n",
        "%load_ext autoreload\n",
        "\n",
        "# Set autoreload behavior\n",
        "%autoreload 2\n",
        "import os\n",
        "import time\n",
        "import argparse\n",
        "import random\n",
        "import numpy as np\n",
        "from models.ProTACT import build_ProTACT\n",
        "import tensorflow as tf\n",
        "from configs.configs import Configs\n",
        "from utils.read_data_pr import read_pos_vocab, read_word_vocab, read_prompts_we, read_essays_prompts, read_prompts_pos\n",
        "from utils.general_utils import get_scaled_down_scores, pad_hierarchical_text_sequences, get_attribute_masks, load_word_embedding_dict, build_embedd_table\n",
        "from evaluators.multitask_evaluator_all_attributes import Evaluator as AllAttEvaluator\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2215898e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2215898e",
        "outputId": "0fdad3f4-6618-4889-bb1a-0be5764390dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test prompt id is 1 of type <class 'int'>\n",
            "Seed: 1\n",
            "Numhead :  2  | Features :  ../data/hand_crafted_v3.csv  | Pos_emb :  50\n"
          ]
        }
      ],
      "source": [
        "# parser = argparse.ArgumentParser(description=\"ProTACT model\")\n",
        "# parser.add_argument('--test_prompt_id', type=int, default=1, help='prompt id of test essay set')\n",
        "# parser.add_argument('--seed', type=int, default=12, help='set random seed')\n",
        "# parser.add_argument('--model_name', type=str,\n",
        "#                     choices=['ProTACT'],\n",
        "#                     help='name of model')\n",
        "# parser.add_argument('--num_heads', type=int, default=2, help='set the number of heads in Multihead Attention')\n",
        "# parser.add_argument('--features_path', type=str, default='data/hand_crafted_v3.csv')\n",
        "\n",
        "test_prompt_id = 1\n",
        "seed = 1\n",
        "num_heads = 2\n",
        "features_path = '../data/hand_crafted_v3.csv'\n",
        "\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "print(\"Test prompt id is {} of type {}\".format(test_prompt_id, type(test_prompt_id)))\n",
        "print(\"Seed: {}\".format(seed))\n",
        "\n",
        "configs = Configs()\n",
        "\n",
        "data_path = configs.DATA_PATH\n",
        "train_path = data_path + str(test_prompt_id) + '/train.pk'\n",
        "dev_path = data_path + str(test_prompt_id) + '/dev.pk'\n",
        "test_path = data_path + str(test_prompt_id) + '/test.pk'\n",
        "pretrained_embedding = configs.PRETRAINED_EMBEDDING\n",
        "embedding_path = configs.EMBEDDING_PATH\n",
        "readability_path = configs.READABILITY_PATH\n",
        "prompt_path = configs.PROMPT_PATH\n",
        "vocab_size = configs.VOCAB_SIZE\n",
        "epochs = configs.EPOCHS\n",
        "batch_size = configs.BATCH_SIZE\n",
        "print(\"Numhead : \", num_heads, \" | Features : \", features_path, \" | Pos_emb : \", configs.EMBEDDING_DIM)\n",
        "\n",
        "read_configs = {\n",
        "    'train_path': train_path,\n",
        "    'dev_path': dev_path,\n",
        "    'test_path': test_path,\n",
        "    'features_path': features_path,\n",
        "    'readability_path': readability_path,\n",
        "    'vocab_size': vocab_size\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c1c27955",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1c27955",
        "outputId": "a63e4c12-6c46-47f8-cb16-a1a93729dcce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " prompt_pos size: 8\n",
            " prompt_words size: 8\n",
            " pos_x size: 9513\n",
            " readability_x size: 9513\n",
            " pos_x size: 1680\n",
            " readability_x size: 1680\n",
            " pos_x size: 1783\n",
            " readability_x size: 1783\n",
            "Loading GloVe ...\n",
            "OOV number =189, OOV ratio = 0.047262\n"
          ]
        }
      ],
      "source": [
        "pos_vocab = read_pos_vocab(read_configs)\n",
        "# read POS for prompts\n",
        "prompt_pos_data = read_prompts_pos(prompt_path, pos_vocab) # for prompt POS embedding\n",
        "\n",
        "word_vocab = read_word_vocab(read_configs)\n",
        "# read words for prompts\n",
        "prompt_data = read_prompts_we(prompt_path, word_vocab) # for prompt word embedding\n",
        "\n",
        "# read essays and prompts\n",
        "train_data, dev_data, test_data = read_essays_prompts(read_configs, prompt_data, prompt_pos_data, pos_vocab)\n",
        "\n",
        "if pretrained_embedding:\n",
        "    embedd_dict, embedd_dim, _ = load_word_embedding_dict(embedding_path)\n",
        "    embedd_matrix = build_embedd_table(word_vocab, embedd_dict, embedd_dim, caseless=True)\n",
        "    embed_table = [embedd_matrix]\n",
        "else:\n",
        "    embed_table = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "423b8538",
      "metadata": {
        "id": "423b8538",
        "outputId": "f96ba3de-3b3f-4a52-fdd8-67eb0f4da506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_ids</th>\n",
              "      <th>pos_x</th>\n",
              "      <th>prompt_words</th>\n",
              "      <th>prompt_pos</th>\n",
              "      <th>readability_x</th>\n",
              "      <th>features_x</th>\n",
              "      <th>data_y</th>\n",
              "      <th>prompt_ids</th>\n",
              "      <th>max_sentnum</th>\n",
              "      <th>max_sentlen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7532</td>\n",
              "      <td>[[2, 3, 4, 2, 5, 6, 2, 5, 4, 7, 3, 8], [9, 5, ...</td>\n",
              "      <td>[[662, 2552, 736, 281, 165, 319, 106, 4], [255...</td>\n",
              "      <td>[[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...</td>\n",
              "      <td>[0.49193152567610715, 0.29664566400513215, 0.5...</td>\n",
              "      <td>[0.4506668631640999, 0.3840642800992836, 0.062...</td>\n",
              "      <td>[1, 1, -1, -1, -1, -1, 1, 1, 1]</td>\n",
              "      <td>3</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7229</td>\n",
              "      <td>[[2, 3, 4, 2, 5, 20, 2, 11, 7, 5, 4, 2, 5, 8],...</td>\n",
              "      <td>[[662, 2552, 736, 281, 165, 319, 106, 4], [255...</td>\n",
              "      <td>[[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...</td>\n",
              "      <td>[0.5579662498866749, 0.37479701404401994, 0.59...</td>\n",
              "      <td>[0.4513708636511923, 0.3586686128111479, 0.085...</td>\n",
              "      <td>[3, 3, -1, -1, -1, -1, 3, 3, 2]</td>\n",
              "      <td>3</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4154</td>\n",
              "      <td>[[9, 4, 2, 3, 4, 2, 29, 3, 4, 29, 3, 10, 5, 4,...</td>\n",
              "      <td>[[218, 125, 4], [122, 72, 73, 340, 1007, 124, ...</td>\n",
              "      <td>[[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8]...</td>\n",
              "      <td>[0.8612956765106549, 0.7423848792139746, 0.619...</td>\n",
              "      <td>[0.5640345883998679, 0.2858415150037477, 0.066...</td>\n",
              "      <td>[4, 4, 4, 4, 5, 4, -1, -1, -1]</td>\n",
              "      <td>2</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17950</td>\n",
              "      <td>[[12, 5, 10, 7, 13, 18, 24, 18, 3, 18, 20, 18,...</td>\n",
              "      <td>[[662, 248, 4], [133, 405, 1090, 2011, 4], [13...</td>\n",
              "      <td>[[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, ...</td>\n",
              "      <td>[0.20688685950461458, 0.1460481802533566, 0.35...</td>\n",
              "      <td>[0.21863912823111997, 0.1030009415010439, 0.04...</td>\n",
              "      <td>[11, 2, 2, -1, -1, 4, -1, -1, -1]</td>\n",
              "      <td>7</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9785</td>\n",
              "      <td>[[2, 5, 10, 2, 5, 4, 2, 5, 4, 14, 2, 11, 7, 12...</td>\n",
              "      <td>[[90, 271, 131, 84, 4], [190, 108, 150, 814, 8...</td>\n",
              "      <td>[[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6...</td>\n",
              "      <td>[0.7090757475733677, 0.48555603009134607, 0.79...</td>\n",
              "      <td>[0.5980343980343981, 0.5082625502524476, 0.090...</td>\n",
              "      <td>[1, 1, -1, -1, -1, -1, 1, 1, 1]</td>\n",
              "      <td>4</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9508</th>\n",
              "      <td>6877</td>\n",
              "      <td>[[4, 2, 5, 4, 5, 11, 20, 11, 18, 16, 7, 4, 29,...</td>\n",
              "      <td>[[662, 2552, 736, 281, 165, 319, 106, 4], [255...</td>\n",
              "      <td>[[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...</td>\n",
              "      <td>[0.6420710849952196, 0.4709075862939792, 0.767...</td>\n",
              "      <td>[0.5665003864259118, 0.4089167978068259, 0.093...</td>\n",
              "      <td>[2, 2, -1, -1, -1, -1, 2, 1, 1]</td>\n",
              "      <td>3</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9509</th>\n",
              "      <td>3661</td>\n",
              "      <td>[[5, 28, 2, 5, 4, 12, 7, 3, 4, 2, 7, 5, 8], [1...</td>\n",
              "      <td>[[218, 125, 4], [122, 72, 73, 340, 1007, 124, ...</td>\n",
              "      <td>[[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8]...</td>\n",
              "      <td>[0.7470330548911367, 0.5322450678768516, 0.688...</td>\n",
              "      <td>[0.7336936048109188, 0.3952062286100636, 0.031...</td>\n",
              "      <td>[4, 5, 4, 4, 5, 4, -1, -1, -1]</td>\n",
              "      <td>2</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9510</th>\n",
              "      <td>10364</td>\n",
              "      <td>[[4, 15, 20, 11, 24, 5, 6, 11, 13, 18, 24, 4, ...</td>\n",
              "      <td>[[90, 271, 131, 84, 4], [190, 108, 150, 814, 8...</td>\n",
              "      <td>[[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6...</td>\n",
              "      <td>[0.6775704345317742, 0.5015464633073149, 0.707...</td>\n",
              "      <td>[0.44895975111802455, 0.27287771704373115, 0.1...</td>\n",
              "      <td>[1, 1, -1, -1, -1, -1, 1, 1, 1]</td>\n",
              "      <td>4</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9511</th>\n",
              "      <td>18367</td>\n",
              "      <td>[[9, 5, 14, 5, 6, 14, 3, 22, 5, 6, 15, 8], [14...</td>\n",
              "      <td>[[662, 248, 4], [133, 405, 1090, 2011, 4], [13...</td>\n",
              "      <td>[[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, ...</td>\n",
              "      <td>[0.4465909693384573, 0.375902607097603, 0.5005...</td>\n",
              "      <td>[0.2542676650242186, 0.08406393382610401, 0.09...</td>\n",
              "      <td>[18, 5, 5, -1, -1, 4, -1, -1, -1]</td>\n",
              "      <td>7</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9512</th>\n",
              "      <td>15347</td>\n",
              "      <td>[[4, 12, 22, 12, 2, 5, 5, 4, 2, 5, 5, 5, 24, 2...</td>\n",
              "      <td>[[756, 446, 1528, 178, 149, 113, 107, 56, 180,...</td>\n",
              "      <td>[[16, 7, 7, 3, 3, 20, 5, 5, 6, 12, 7, 3, 5, 8]...</td>\n",
              "      <td>[0.6385888045704757, 0.40596380660143777, 0.50...</td>\n",
              "      <td>[0.34372244585010514, 0.12172169029380711, 0.1...</td>\n",
              "      <td>[2, 1, -1, -1, -1, -1, 1, 1, 1]</td>\n",
              "      <td>6</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9513 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      essay_ids                                              pos_x  \\\n",
              "0          7532  [[2, 3, 4, 2, 5, 6, 2, 5, 4, 7, 3, 8], [9, 5, ...   \n",
              "1          7229  [[2, 3, 4, 2, 5, 20, 2, 11, 7, 5, 4, 2, 5, 8],...   \n",
              "2          4154  [[9, 4, 2, 3, 4, 2, 29, 3, 4, 29, 3, 10, 5, 4,...   \n",
              "3         17950  [[12, 5, 10, 7, 13, 18, 24, 18, 3, 18, 20, 18,...   \n",
              "4          9785  [[2, 5, 10, 2, 5, 4, 2, 5, 4, 14, 2, 11, 7, 12...   \n",
              "...         ...                                                ...   \n",
              "9508       6877  [[4, 2, 5, 4, 5, 11, 20, 11, 18, 16, 7, 4, 29,...   \n",
              "9509       3661  [[5, 28, 2, 5, 4, 12, 7, 3, 4, 2, 7, 5, 8], [1...   \n",
              "9510      10364  [[4, 15, 20, 11, 24, 5, 6, 11, 13, 18, 24, 4, ...   \n",
              "9511      18367  [[9, 5, 14, 5, 6, 14, 3, 22, 5, 6, 15, 8], [14...   \n",
              "9512      15347  [[4, 12, 22, 12, 2, 5, 5, 4, 2, 5, 5, 5, 24, 2...   \n",
              "\n",
              "                                           prompt_words  \\\n",
              "0     [[662, 2552, 736, 281, 165, 319, 106, 4], [255...   \n",
              "1     [[662, 2552, 736, 281, 165, 319, 106, 4], [255...   \n",
              "2     [[218, 125, 4], [122, 72, 73, 340, 1007, 124, ...   \n",
              "3     [[662, 248, 4], [133, 405, 1090, 2011, 4], [13...   \n",
              "4     [[90, 271, 131, 84, 4], [190, 108, 150, 814, 8...   \n",
              "...                                                 ...   \n",
              "9508  [[662, 2552, 736, 281, 165, 319, 106, 4], [255...   \n",
              "9509  [[218, 125, 4], [122, 72, 73, 340, 1007, 124, ...   \n",
              "9510  [[90, 271, 131, 84, 4], [190, 108, 150, 814, 8...   \n",
              "9511  [[662, 248, 4], [133, 405, 1090, 2011, 4], [13...   \n",
              "9512  [[756, 446, 1528, 178, 149, 113, 107, 56, 180,...   \n",
              "\n",
              "                                             prompt_pos  \\\n",
              "0     [[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...   \n",
              "1     [[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...   \n",
              "2     [[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8]...   \n",
              "3     [[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, ...   \n",
              "4     [[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6...   \n",
              "...                                                 ...   \n",
              "9508  [[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...   \n",
              "9509  [[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8]...   \n",
              "9510  [[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6...   \n",
              "9511  [[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, ...   \n",
              "9512  [[16, 7, 7, 3, 3, 20, 5, 5, 6, 12, 7, 3, 5, 8]...   \n",
              "\n",
              "                                          readability_x  \\\n",
              "0     [0.49193152567610715, 0.29664566400513215, 0.5...   \n",
              "1     [0.5579662498866749, 0.37479701404401994, 0.59...   \n",
              "2     [0.8612956765106549, 0.7423848792139746, 0.619...   \n",
              "3     [0.20688685950461458, 0.1460481802533566, 0.35...   \n",
              "4     [0.7090757475733677, 0.48555603009134607, 0.79...   \n",
              "...                                                 ...   \n",
              "9508  [0.6420710849952196, 0.4709075862939792, 0.767...   \n",
              "9509  [0.7470330548911367, 0.5322450678768516, 0.688...   \n",
              "9510  [0.6775704345317742, 0.5015464633073149, 0.707...   \n",
              "9511  [0.4465909693384573, 0.375902607097603, 0.5005...   \n",
              "9512  [0.6385888045704757, 0.40596380660143777, 0.50...   \n",
              "\n",
              "                                             features_x  \\\n",
              "0     [0.4506668631640999, 0.3840642800992836, 0.062...   \n",
              "1     [0.4513708636511923, 0.3586686128111479, 0.085...   \n",
              "2     [0.5640345883998679, 0.2858415150037477, 0.066...   \n",
              "3     [0.21863912823111997, 0.1030009415010439, 0.04...   \n",
              "4     [0.5980343980343981, 0.5082625502524476, 0.090...   \n",
              "...                                                 ...   \n",
              "9508  [0.5665003864259118, 0.4089167978068259, 0.093...   \n",
              "9509  [0.7336936048109188, 0.3952062286100636, 0.031...   \n",
              "9510  [0.44895975111802455, 0.27287771704373115, 0.1...   \n",
              "9511  [0.2542676650242186, 0.08406393382610401, 0.09...   \n",
              "9512  [0.34372244585010514, 0.12172169029380711, 0.1...   \n",
              "\n",
              "                                 data_y  prompt_ids  max_sentnum  max_sentlen  \n",
              "0       [1, 1, -1, -1, -1, -1, 1, 1, 1]           3           97           50  \n",
              "1       [3, 3, -1, -1, -1, -1, 3, 3, 2]           3           97           50  \n",
              "2        [4, 4, 4, 4, 5, 4, -1, -1, -1]           2           97           50  \n",
              "3     [11, 2, 2, -1, -1, 4, -1, -1, -1]           7           97           50  \n",
              "4       [1, 1, -1, -1, -1, -1, 1, 1, 1]           4           97           50  \n",
              "...                                 ...         ...          ...          ...  \n",
              "9508    [2, 2, -1, -1, -1, -1, 2, 1, 1]           3           97           50  \n",
              "9509     [4, 5, 4, 4, 5, 4, -1, -1, -1]           2           97           50  \n",
              "9510    [1, 1, -1, -1, -1, -1, 1, 1, 1]           4           97           50  \n",
              "9511  [18, 5, 5, -1, -1, 4, -1, -1, -1]           7           97           50  \n",
              "9512    [2, 1, -1, -1, -1, -1, 1, 1, 1]           6           97           50  \n",
              "\n",
              "[9513 rows x 10 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "print(len(train_data['features_x'][0]))\n",
        "pd.DataFrame(train_data)\n",
        "# embedd_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c7e8f956",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7e8f956",
        "outputId": "1108a5f0-b8a1-44b6-f5d7-db6a4f05f2ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max sent length: 50\n",
            "max sent num: 97\n",
            "max prompt sent length: 18\n",
            "max prompt sent num: 8\n",
            "================================\n",
            "X_train_pos:  (9513, 4850)\n",
            "X_train_prompt_words:  (9513, 4850)\n",
            "X_train_prompt_pos:  (9513, 4850)\n",
            "X_train_readability:  (9513, 35)\n",
            "X_train_ling:  (9513, 51)\n",
            "X_train_attribute_rel:  (9513, 9)\n",
            "Y_train:  (9513, 9)\n",
            "================================\n",
            "X_dev_pos:  (1680, 4850)\n",
            "X_dev_prompt_words:  (1680, 4850)\n",
            "X_dev_prompt_pos:  (1680, 4850)\n",
            "X_dev_readability:  (1680, 35)\n",
            "X_dev_ling:  (1680, 51)\n",
            "X_dev_attribute_rel:  (1680, 9)\n",
            "Y_dev:  (1680, 9)\n",
            "================================\n",
            "X_test_pos:  (1783, 4850)\n",
            "X_test_prompt_words:  (1783, 4850)\n",
            "X_test_prompt_pos:  (1783, 4850)\n",
            "X_test_readability:  (1783, 35)\n",
            "X_test_ling:  (1783, 51)\n",
            "X_test_attribute_rel:  (1783, 9)\n",
            "Y_test:  (1783, 9)\n",
            "================================\n"
          ]
        }
      ],
      "source": [
        "max_sentlen = max(train_data['max_sentlen'], dev_data['max_sentlen'], test_data['max_sentlen'])\n",
        "max_sentnum = max(train_data['max_sentnum'], dev_data['max_sentnum'], test_data['max_sentnum'])\n",
        "prompt_max_sentlen = prompt_data['max_sentlen']\n",
        "prompt_max_sentnum = prompt_data['max_sentnum']\n",
        "\n",
        "print('max sent length: {}'.format(max_sentlen))\n",
        "print('max sent num: {}'.format(max_sentnum))\n",
        "print('max prompt sent length: {}'.format(prompt_max_sentlen))\n",
        "print('max prompt sent num: {}'.format(prompt_max_sentnum))\n",
        "\n",
        "train_data['y_scaled'] = get_scaled_down_scores(train_data['data_y'], train_data['prompt_ids'])\n",
        "dev_data['y_scaled'] = get_scaled_down_scores(dev_data['data_y'], dev_data['prompt_ids'])\n",
        "test_data['y_scaled'] = get_scaled_down_scores(test_data['data_y'], test_data['prompt_ids'])\n",
        "\n",
        "X_train_pos = pad_hierarchical_text_sequences(train_data['pos_x'], max_sentnum, max_sentlen)\n",
        "X_dev_pos = pad_hierarchical_text_sequences(dev_data['pos_x'], max_sentnum, max_sentlen)\n",
        "X_test_pos = pad_hierarchical_text_sequences(test_data['pos_x'], max_sentnum, max_sentlen)\n",
        "\n",
        "X_train_pos = X_train_pos.reshape((X_train_pos.shape[0], X_train_pos.shape[1] * X_train_pos.shape[2]))\n",
        "X_dev_pos = X_dev_pos.reshape((X_dev_pos.shape[0], X_dev_pos.shape[1] * X_dev_pos.shape[2]))\n",
        "X_test_pos = X_test_pos.reshape((X_test_pos.shape[0], X_test_pos.shape[1] * X_test_pos.shape[2]))\n",
        "\n",
        "X_train_prompt = pad_hierarchical_text_sequences(train_data['prompt_words'], max_sentnum, max_sentlen)\n",
        "X_dev_prompt = pad_hierarchical_text_sequences(dev_data['prompt_words'], max_sentnum, max_sentlen)\n",
        "X_test_prompt = pad_hierarchical_text_sequences(test_data['prompt_words'], max_sentnum, max_sentlen)\n",
        "\n",
        "X_train_prompt = X_train_prompt.reshape((X_train_prompt.shape[0], X_train_prompt.shape[1] * X_train_prompt.shape[2]))\n",
        "X_dev_prompt = X_dev_prompt.reshape((X_dev_prompt.shape[0], X_dev_prompt.shape[1] * X_dev_prompt.shape[2]))\n",
        "X_test_prompt = X_test_prompt.reshape((X_test_prompt.shape[0], X_test_prompt.shape[1] * X_test_prompt.shape[2]))\n",
        "\n",
        "X_train_prompt_pos = pad_hierarchical_text_sequences(train_data['prompt_pos'], max_sentnum, max_sentlen)\n",
        "X_dev_prompt_pos = pad_hierarchical_text_sequences(dev_data['prompt_pos'], max_sentnum, max_sentlen)\n",
        "X_test_prompt_pos = pad_hierarchical_text_sequences(test_data['prompt_pos'], max_sentnum, max_sentlen)\n",
        "\n",
        "X_train_prompt_pos = X_train_prompt_pos.reshape((X_train_prompt_pos.shape[0], X_train_prompt_pos.shape[1] * X_train_prompt_pos.shape[2]))\n",
        "X_dev_prompt_pos = X_dev_prompt_pos.reshape((X_dev_prompt_pos.shape[0], X_dev_prompt_pos.shape[1] * X_dev_prompt_pos.shape[2]))\n",
        "X_test_prompt_pos = X_test_prompt_pos.reshape((X_test_prompt_pos.shape[0], X_test_prompt_pos.shape[1] * X_test_prompt_pos.shape[2]))\n",
        "\n",
        "X_train_linguistic_features = np.array(train_data['features_x'])\n",
        "X_dev_linguistic_features = np.array(dev_data['features_x'])\n",
        "X_test_linguistic_features = np.array(test_data['features_x'])\n",
        "\n",
        "X_train_readability = np.array(train_data['readability_x'])\n",
        "X_dev_readability = np.array(dev_data['readability_x'])\n",
        "X_test_readability = np.array(test_data['readability_x'])\n",
        "\n",
        "Y_train = np.array(train_data['y_scaled'])\n",
        "Y_dev = np.array(dev_data['y_scaled'])\n",
        "Y_test = np.array(test_data['y_scaled'])\n",
        "\n",
        "X_train_attribute_rel = get_attribute_masks(Y_train)\n",
        "X_dev_attribute_rel = get_attribute_masks(Y_dev)\n",
        "X_test_attribute_rel = get_attribute_masks(Y_test)\n",
        "\n",
        "print('================================')\n",
        "print('X_train_pos: ', X_train_pos.shape)\n",
        "print('X_train_prompt_words: ', X_train_prompt.shape)\n",
        "print('X_train_prompt_pos: ', X_train_prompt_pos.shape)\n",
        "print('X_train_readability: ', X_train_readability.shape)\n",
        "print('X_train_ling: ', X_train_linguistic_features.shape)\n",
        "print('X_train_attribute_rel: ', X_train_attribute_rel.shape)\n",
        "print('Y_train: ', Y_train.shape)\n",
        "\n",
        "print('================================')\n",
        "print('X_dev_pos: ', X_dev_pos.shape)\n",
        "print('X_dev_prompt_words: ', X_dev_prompt.shape)\n",
        "print('X_dev_prompt_pos: ', X_dev_prompt_pos.shape)\n",
        "print('X_dev_readability: ', X_dev_readability.shape)\n",
        "print('X_dev_ling: ', X_dev_linguistic_features.shape)\n",
        "print('X_dev_attribute_rel: ', X_dev_attribute_rel.shape)\n",
        "print('Y_dev: ', Y_dev.shape)\n",
        "\n",
        "print('================================')\n",
        "print('X_test_pos: ', X_test_pos.shape)\n",
        "print('X_test_prompt_words: ', X_test_prompt.shape)\n",
        "print('X_test_prompt_pos: ', X_test_prompt_pos.shape)\n",
        "print('X_test_readability: ', X_test_readability.shape)\n",
        "print('X_test_ling: ', X_test_linguistic_features.shape)\n",
        "print('X_test_attribute_rel: ', X_test_attribute_rel.shape)\n",
        "print('Y_test: ', Y_test.shape)\n",
        "print('================================')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cc4092c",
      "metadata": {
        "id": "2cc4092c",
        "outputId": "89fb96c5-ff62-4252-fa6b-af832632ee51"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_ids</th>\n",
              "      <th>pos_x</th>\n",
              "      <th>prompt_words</th>\n",
              "      <th>prompt_pos</th>\n",
              "      <th>readability_x</th>\n",
              "      <th>features_x</th>\n",
              "      <th>data_y</th>\n",
              "      <th>prompt_ids</th>\n",
              "      <th>max_sentnum</th>\n",
              "      <th>max_sentlen</th>\n",
              "      <th>y_scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7532</td>\n",
              "      <td>[[2, 3, 4, 2, 5, 6, 2, 5, 4, 7, 3, 8], [9, 5, ...</td>\n",
              "      <td>[[662, 2552, 736, 281, 165, 319, 106, 4], [255...</td>\n",
              "      <td>[[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...</td>\n",
              "      <td>[0.49193152567610715, 0.29664566400513215, 0.5...</td>\n",
              "      <td>[0.4506668631640999, 0.3840642800992836, 0.062...</td>\n",
              "      <td>[1, 1, -1, -1, -1, -1, 1, 1, 1]</td>\n",
              "      <td>3</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "      <td>[0.3333333333333333, 0.3333333333333333, -1, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7229</td>\n",
              "      <td>[[2, 3, 4, 2, 5, 20, 2, 11, 7, 5, 4, 2, 5, 8],...</td>\n",
              "      <td>[[662, 2552, 736, 281, 165, 319, 106, 4], [255...</td>\n",
              "      <td>[[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...</td>\n",
              "      <td>[0.5579662498866749, 0.37479701404401994, 0.59...</td>\n",
              "      <td>[0.4513708636511923, 0.3586686128111479, 0.085...</td>\n",
              "      <td>[3, 3, -1, -1, -1, -1, 3, 3, 2]</td>\n",
              "      <td>3</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "      <td>[1.0, 1.0, -1, -1, -1, -1, 1.0, 1.0, 0.6666666...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4154</td>\n",
              "      <td>[[9, 4, 2, 3, 4, 2, 29, 3, 4, 29, 3, 10, 5, 4,...</td>\n",
              "      <td>[[218, 125, 4], [122, 72, 73, 340, 1007, 124, ...</td>\n",
              "      <td>[[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8]...</td>\n",
              "      <td>[0.8612956765106549, 0.7423848792139746, 0.619...</td>\n",
              "      <td>[0.5640345883998679, 0.2858415150037477, 0.066...</td>\n",
              "      <td>[4, 4, 4, 4, 5, 4, -1, -1, -1]</td>\n",
              "      <td>2</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "      <td>[0.6, 0.6, 0.6, 0.6, 0.8, 0.6, -1, -1, -1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17950</td>\n",
              "      <td>[[12, 5, 10, 7, 13, 18, 24, 18, 3, 18, 20, 18,...</td>\n",
              "      <td>[[662, 248, 4], [133, 405, 1090, 2011, 4], [13...</td>\n",
              "      <td>[[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, ...</td>\n",
              "      <td>[0.20688685950461458, 0.1460481802533566, 0.35...</td>\n",
              "      <td>[0.21863912823111997, 0.1030009415010439, 0.04...</td>\n",
              "      <td>[11, 2, 2, -1, -1, 4, -1, -1, -1]</td>\n",
              "      <td>7</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "      <td>[0.36666666666666664, 0.3333333333333333, 0.33...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9785</td>\n",
              "      <td>[[2, 5, 10, 2, 5, 4, 2, 5, 4, 14, 2, 11, 7, 12...</td>\n",
              "      <td>[[90, 271, 131, 84, 4], [190, 108, 150, 814, 8...</td>\n",
              "      <td>[[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6...</td>\n",
              "      <td>[0.7090757475733677, 0.48555603009134607, 0.79...</td>\n",
              "      <td>[0.5980343980343981, 0.5082625502524476, 0.090...</td>\n",
              "      <td>[1, 1, -1, -1, -1, -1, 1, 1, 1]</td>\n",
              "      <td>4</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "      <td>[0.3333333333333333, 0.3333333333333333, -1, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9508</th>\n",
              "      <td>6877</td>\n",
              "      <td>[[4, 2, 5, 4, 5, 11, 20, 11, 18, 16, 7, 4, 29,...</td>\n",
              "      <td>[[662, 2552, 736, 281, 165, 319, 106, 4], [255...</td>\n",
              "      <td>[[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...</td>\n",
              "      <td>[0.6420710849952196, 0.4709075862939792, 0.767...</td>\n",
              "      <td>[0.5665003864259118, 0.4089167978068259, 0.093...</td>\n",
              "      <td>[2, 2, -1, -1, -1, -1, 2, 1, 1]</td>\n",
              "      <td>3</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "      <td>[0.6666666666666666, 0.6666666666666666, -1, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9509</th>\n",
              "      <td>3661</td>\n",
              "      <td>[[5, 28, 2, 5, 4, 12, 7, 3, 4, 2, 7, 5, 8], [1...</td>\n",
              "      <td>[[218, 125, 4], [122, 72, 73, 340, 1007, 124, ...</td>\n",
              "      <td>[[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8]...</td>\n",
              "      <td>[0.7470330548911367, 0.5322450678768516, 0.688...</td>\n",
              "      <td>[0.7336936048109188, 0.3952062286100636, 0.031...</td>\n",
              "      <td>[4, 5, 4, 4, 5, 4, -1, -1, -1]</td>\n",
              "      <td>2</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "      <td>[0.6, 0.8, 0.6, 0.6, 0.8, 0.6, -1, -1, -1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9510</th>\n",
              "      <td>10364</td>\n",
              "      <td>[[4, 15, 20, 11, 24, 5, 6, 11, 13, 18, 24, 4, ...</td>\n",
              "      <td>[[90, 271, 131, 84, 4], [190, 108, 150, 814, 8...</td>\n",
              "      <td>[[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6...</td>\n",
              "      <td>[0.6775704345317742, 0.5015464633073149, 0.707...</td>\n",
              "      <td>[0.44895975111802455, 0.27287771704373115, 0.1...</td>\n",
              "      <td>[1, 1, -1, -1, -1, -1, 1, 1, 1]</td>\n",
              "      <td>4</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "      <td>[0.3333333333333333, 0.3333333333333333, -1, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9511</th>\n",
              "      <td>18367</td>\n",
              "      <td>[[9, 5, 14, 5, 6, 14, 3, 22, 5, 6, 15, 8], [14...</td>\n",
              "      <td>[[662, 248, 4], [133, 405, 1090, 2011, 4], [13...</td>\n",
              "      <td>[[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, ...</td>\n",
              "      <td>[0.4465909693384573, 0.375902607097603, 0.5005...</td>\n",
              "      <td>[0.2542676650242186, 0.08406393382610401, 0.09...</td>\n",
              "      <td>[18, 5, 5, -1, -1, 4, -1, -1, -1]</td>\n",
              "      <td>7</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "      <td>[0.6, 0.8333333333333334, 0.8333333333333334, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9512</th>\n",
              "      <td>15347</td>\n",
              "      <td>[[4, 12, 22, 12, 2, 5, 5, 4, 2, 5, 5, 5, 24, 2...</td>\n",
              "      <td>[[756, 446, 1528, 178, 149, 113, 107, 56, 180,...</td>\n",
              "      <td>[[16, 7, 7, 3, 3, 20, 5, 5, 6, 12, 7, 3, 5, 8]...</td>\n",
              "      <td>[0.6385888045704757, 0.40596380660143777, 0.50...</td>\n",
              "      <td>[0.34372244585010514, 0.12172169029380711, 0.1...</td>\n",
              "      <td>[2, 1, -1, -1, -1, -1, 1, 1, 1]</td>\n",
              "      <td>6</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "      <td>[0.5, 0.25, -1, -1, -1, -1, 0.25, 0.25, 0.25]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9513 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      essay_ids                                              pos_x  \\\n",
              "0          7532  [[2, 3, 4, 2, 5, 6, 2, 5, 4, 7, 3, 8], [9, 5, ...   \n",
              "1          7229  [[2, 3, 4, 2, 5, 20, 2, 11, 7, 5, 4, 2, 5, 8],...   \n",
              "2          4154  [[9, 4, 2, 3, 4, 2, 29, 3, 4, 29, 3, 10, 5, 4,...   \n",
              "3         17950  [[12, 5, 10, 7, 13, 18, 24, 18, 3, 18, 20, 18,...   \n",
              "4          9785  [[2, 5, 10, 2, 5, 4, 2, 5, 4, 14, 2, 11, 7, 12...   \n",
              "...         ...                                                ...   \n",
              "9508       6877  [[4, 2, 5, 4, 5, 11, 20, 11, 18, 16, 7, 4, 29,...   \n",
              "9509       3661  [[5, 28, 2, 5, 4, 12, 7, 3, 4, 2, 7, 5, 8], [1...   \n",
              "9510      10364  [[4, 15, 20, 11, 24, 5, 6, 11, 13, 18, 24, 4, ...   \n",
              "9511      18367  [[9, 5, 14, 5, 6, 14, 3, 22, 5, 6, 15, 8], [14...   \n",
              "9512      15347  [[4, 12, 22, 12, 2, 5, 5, 4, 2, 5, 5, 5, 24, 2...   \n",
              "\n",
              "                                           prompt_words  \\\n",
              "0     [[662, 2552, 736, 281, 165, 319, 106, 4], [255...   \n",
              "1     [[662, 2552, 736, 281, 165, 319, 106, 4], [255...   \n",
              "2     [[218, 125, 4], [122, 72, 73, 340, 1007, 124, ...   \n",
              "3     [[662, 248, 4], [133, 405, 1090, 2011, 4], [13...   \n",
              "4     [[90, 271, 131, 84, 4], [190, 108, 150, 814, 8...   \n",
              "...                                                 ...   \n",
              "9508  [[662, 2552, 736, 281, 165, 319, 106, 4], [255...   \n",
              "9509  [[218, 125, 4], [122, 72, 73, 340, 1007, 124, ...   \n",
              "9510  [[90, 271, 131, 84, 4], [190, 108, 150, 814, 8...   \n",
              "9511  [[662, 248, 4], [133, 405, 1090, 2011, 4], [13...   \n",
              "9512  [[756, 446, 1528, 178, 149, 113, 107, 56, 180,...   \n",
              "\n",
              "                                             prompt_pos  \\\n",
              "0     [[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...   \n",
              "1     [[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...   \n",
              "2     [[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8]...   \n",
              "3     [[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, ...   \n",
              "4     [[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6...   \n",
              "...                                                 ...   \n",
              "9508  [[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5,...   \n",
              "9509  [[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8]...   \n",
              "9510  [[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6...   \n",
              "9511  [[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, ...   \n",
              "9512  [[16, 7, 7, 3, 3, 20, 5, 5, 6, 12, 7, 3, 5, 8]...   \n",
              "\n",
              "                                          readability_x  \\\n",
              "0     [0.49193152567610715, 0.29664566400513215, 0.5...   \n",
              "1     [0.5579662498866749, 0.37479701404401994, 0.59...   \n",
              "2     [0.8612956765106549, 0.7423848792139746, 0.619...   \n",
              "3     [0.20688685950461458, 0.1460481802533566, 0.35...   \n",
              "4     [0.7090757475733677, 0.48555603009134607, 0.79...   \n",
              "...                                                 ...   \n",
              "9508  [0.6420710849952196, 0.4709075862939792, 0.767...   \n",
              "9509  [0.7470330548911367, 0.5322450678768516, 0.688...   \n",
              "9510  [0.6775704345317742, 0.5015464633073149, 0.707...   \n",
              "9511  [0.4465909693384573, 0.375902607097603, 0.5005...   \n",
              "9512  [0.6385888045704757, 0.40596380660143777, 0.50...   \n",
              "\n",
              "                                             features_x  \\\n",
              "0     [0.4506668631640999, 0.3840642800992836, 0.062...   \n",
              "1     [0.4513708636511923, 0.3586686128111479, 0.085...   \n",
              "2     [0.5640345883998679, 0.2858415150037477, 0.066...   \n",
              "3     [0.21863912823111997, 0.1030009415010439, 0.04...   \n",
              "4     [0.5980343980343981, 0.5082625502524476, 0.090...   \n",
              "...                                                 ...   \n",
              "9508  [0.5665003864259118, 0.4089167978068259, 0.093...   \n",
              "9509  [0.7336936048109188, 0.3952062286100636, 0.031...   \n",
              "9510  [0.44895975111802455, 0.27287771704373115, 0.1...   \n",
              "9511  [0.2542676650242186, 0.08406393382610401, 0.09...   \n",
              "9512  [0.34372244585010514, 0.12172169029380711, 0.1...   \n",
              "\n",
              "                                 data_y  prompt_ids  max_sentnum  max_sentlen  \\\n",
              "0       [1, 1, -1, -1, -1, -1, 1, 1, 1]           3           97           50   \n",
              "1       [3, 3, -1, -1, -1, -1, 3, 3, 2]           3           97           50   \n",
              "2        [4, 4, 4, 4, 5, 4, -1, -1, -1]           2           97           50   \n",
              "3     [11, 2, 2, -1, -1, 4, -1, -1, -1]           7           97           50   \n",
              "4       [1, 1, -1, -1, -1, -1, 1, 1, 1]           4           97           50   \n",
              "...                                 ...         ...          ...          ...   \n",
              "9508    [2, 2, -1, -1, -1, -1, 2, 1, 1]           3           97           50   \n",
              "9509     [4, 5, 4, 4, 5, 4, -1, -1, -1]           2           97           50   \n",
              "9510    [1, 1, -1, -1, -1, -1, 1, 1, 1]           4           97           50   \n",
              "9511  [18, 5, 5, -1, -1, 4, -1, -1, -1]           7           97           50   \n",
              "9512    [2, 1, -1, -1, -1, -1, 1, 1, 1]           6           97           50   \n",
              "\n",
              "                                               y_scaled  \n",
              "0     [0.3333333333333333, 0.3333333333333333, -1, -...  \n",
              "1     [1.0, 1.0, -1, -1, -1, -1, 1.0, 1.0, 0.6666666...  \n",
              "2            [0.6, 0.6, 0.6, 0.6, 0.8, 0.6, -1, -1, -1]  \n",
              "3     [0.36666666666666664, 0.3333333333333333, 0.33...  \n",
              "4     [0.3333333333333333, 0.3333333333333333, -1, -...  \n",
              "...                                                 ...  \n",
              "9508  [0.6666666666666666, 0.6666666666666666, -1, -...  \n",
              "9509         [0.6, 0.8, 0.6, 0.6, 0.8, 0.6, -1, -1, -1]  \n",
              "9510  [0.3333333333333333, 0.3333333333333333, -1, -...  \n",
              "9511  [0.6, 0.8333333333333334, 0.8333333333333334, ...  \n",
              "9512      [0.5, 0.25, -1, -1, -1, -1, 0.25, 0.25, 0.25]  \n",
              "\n",
              "[9513 rows x 11 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "745a6704",
      "metadata": {
        "id": "745a6704"
      },
      "outputs": [],
      "source": [
        "# train_features_list = [X_train_pos, X_train_prompt, X_train_prompt_pos, X_train_linguistic_features, X_train_readability]\n",
        "X_train_pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1331a5d3",
      "metadata": {
        "id": "1331a5d3"
      },
      "outputs": [],
      "source": [
        "Y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b1f527d",
      "metadata": {
        "id": "2b1f527d"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "55cd0505",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55cd0505",
        "outputId": "c9f7dbf4-5730-437c-eab1-39018c29b094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " pos_input (InputLayer)      [(None, 4850)]               0         []                            \n",
            "                                                                                                  \n",
            " pos_x (Embedding)           (None, 4850, 50)             1800      ['pos_input[0][0]']           \n",
            "                                                                                                  \n",
            " prompt_word_input (InputLa  [(None, 4850)]               0         []                            \n",
            " yer)                                                                                             \n",
            "                                                                                                  \n",
            " prompt_pos_input (InputLay  [(None, 4850)]               0         []                            \n",
            " er)                                                                                              \n",
            "                                                                                                  \n",
            " pos_x_maskedout (ZeroMaske  (None, 4850, 50)             0         ['pos_x[0][0]']               \n",
            " dEntries)                                                                                        \n",
            "                                                                                                  \n",
            " prompt (Embedding)          (None, 4850, 50)             200000    ['prompt_word_input[0][0]']   \n",
            "                                                                                                  \n",
            " pos_prompt (Embedding)      (None, 4850, 50)             1800      ['prompt_pos_input[0][0]']    \n",
            "                                                                                                  \n",
            " prompt_maskedout (ZeroMask  (None, 4850, 50)             0         ['prompt[0][0]']              \n",
            " edEntries)                                                                                       \n",
            "                                                                                                  \n",
            " prompt_pos_maskedout (Zero  (None, 4850, 50)             0         ['pos_prompt[0][0]']          \n",
            " MaskedEntries)                                                                                   \n",
            "                                                                                                  \n",
            " positional_encoding_2 (pos  (None, 4850, 50)             0         ['pos_x_maskedout[0][0]']     \n",
            " itionalEncoding)                                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 4850, 50)             0         ['prompt_maskedout[0][0]',    \n",
            "                                                                     'prompt_pos_maskedout[0][0]',\n",
            "                                                                     'positional_encoding_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " prompt_drop_x (Dropout)     (None, 4850, 50)             0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " prompt_resh_W (Reshape)     (None, 97, 50, 50)           0         ['prompt_drop_x[0][0]']       \n",
            "                                                                                                  \n",
            " prompt_attention_output (T  (None, 97, None, 50)         10200     ['prompt_resh_W[0][0]']       \n",
            " imeDistributed)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.add_20 (T  (None, 97, 50, 50)           0         ['prompt_resh_W[0][0]',       \n",
            " FOpLambda)                                                          'prompt_attention_output[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " positional_encoding (posit  (None, 4850, 50)             0         ['pos_x_maskedout[0][0]']     \n",
            " ionalEncoding)                                                                                   \n",
            "                                                                                                  \n",
            " prompt_attention_output_no  (None, 97, 50, 50)           100       ['tf.__operators__.add_20[0][0\n",
            " rm (TimeDistributed)                                               ]']                           \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 4850, 50)             0         ['pos_x_maskedout[0][0]',     \n",
            "                                                                     'positional_encoding[0][0]'] \n",
            "                                                                                                  \n",
            " prompt_dense_1 (TimeDistri  (None, 97, 50, 100)          5100      ['prompt_attention_output_norm\n",
            " buted)                                                             [0][0]']                      \n",
            "                                                                                                  \n",
            " pos_drop_x (Dropout)        (None, 4850, 50)             0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " prompt_dense_2 (TimeDistri  (None, 97, 50, 50)           5050      ['prompt_dense_1[0][0]']      \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " pos_resh_W (Reshape)        (None, 97, 50, 50)           0         ['pos_drop_x[0][0]']          \n",
            "                                                                                                  \n",
            " time_distributed_2 (TimeDi  (None, 97, 50, 50)           0         ['prompt_dense_2[0][0]']      \n",
            " stributed)                                                                                       \n",
            "                                                                                                  \n",
            " pos_attention_output (Time  (None, 97, None, 50)         10200     ['pos_resh_W[0][0]']          \n",
            " Distributed)                                                                                     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_21 (T  (None, 97, 50, 50)           0         ['prompt_attention_output[0][0\n",
            " FOpLambda)                                                         ]',                           \n",
            "                                                                     'time_distributed_2[0][0]']  \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOp  (None, 97, 50, 50)           0         ['pos_resh_W[0][0]',          \n",
            " Lambda)                                                             'pos_attention_output[0][0]']\n",
            "                                                                                                  \n",
            " time_distributed_3 (TimeDi  (None, 97, 50, 50)           100       ['tf.__operators__.add_21[0][0\n",
            " stributed)                                                         ]']                           \n",
            "                                                                                                  \n",
            " pos_attention_output_norm   (None, 97, 50, 50)           100       ['tf.__operators__.add[0][0]']\n",
            " (TimeDistributed)                                                                                \n",
            "                                                                                                  \n",
            " prompt_transformer_embeddi  (None, 97, 50)               0         ['time_distributed_3[0][0]']  \n",
            " ng (TimeDistributed)                                                                             \n",
            "                                                                                                  \n",
            " pos_dense_1 (TimeDistribut  (None, 97, 50, 100)          5100      ['pos_attention_output_norm[0]\n",
            " ed)                                                                [0]']                         \n",
            "                                                                                                  \n",
            " positional_encoding_3 (pos  (None, 97, 50)               0         ['prompt_transformer_embedding\n",
            " itionalEncoding)                                                   [0][0]']                      \n",
            "                                                                                                  \n",
            " pos_dense_2 (TimeDistribut  (None, 97, 50, 50)           5050      ['pos_dense_1[0][0]']         \n",
            " ed)                                                                                              \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 97, 50)               0         ['prompt_transformer_embedding\n",
            "                                                                    [0][0]',                      \n",
            "                                                                     'positional_encoding_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " time_distributed (TimeDist  (None, 97, 50, 50)           0         ['pos_dense_2[0][0]']         \n",
            " ributed)                                                                                         \n",
            "                                                                                                  \n",
            " multi_head_attention_12 (M  (None, None, 50)             10200     ['add_3[0][0]']               \n",
            " ultiHeadAttention)                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TF  (None, 97, 50, 50)           0         ['pos_attention_output[0][0]',\n",
            " OpLambda)                                                           'time_distributed[0][0]']    \n",
            "                                                                                                  \n",
            " tf.__operators__.add_22 (T  (None, 97, 50)               0         ['prompt_transformer_embedding\n",
            " FOpLambda)                                                         [0][0]',                      \n",
            "                                                                     'multi_head_attention_12[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDi  (None, 97, 50, 50)           100       ['tf.__operators__.add_1[0][0]\n",
            " stributed)                                                         ']                            \n",
            "                                                                                                  \n",
            " layer_normalization_22 (La  (None, 97, 50)               100       ['tf.__operators__.add_22[0][0\n",
            " yerNormalization)                                                  ]']                           \n",
            "                                                                                                  \n",
            " pos_transformer_embedding   (None, 97, 50)               0         ['time_distributed_1[0][0]']  \n",
            " (TimeDistributed)                                                                                \n",
            "                                                                                                  \n",
            " dense_74 (Dense)            (None, 97, 100)              5100      ['layer_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " positional_encoding_1 (pos  (None, 97, 50)               0         ['pos_transformer_embedding[0]\n",
            " itionalEncoding)                                                   [0]']                         \n",
            "                                                                                                  \n",
            " dense_75 (Dense)            (None, 97, 50)               5050      ['dense_74[0][0]']            \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 97, 50)               0         ['pos_transformer_embedding[0]\n",
            "                                                                    [0]',                         \n",
            "                                                                     'positional_encoding_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_24 (Dropout)        (None, 97, 50)               0         ['dense_75[0][0]']            \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (Mu  (None, None, 50)             10200     ['add_1[0][0]']               \n",
            " ltiHeadAttention)                                                                                \n",
            "                                                                                                  \n",
            " tf.__operators__.add_23 (T  (None, 97, 50)               0         ['multi_head_attention_12[0][0\n",
            " FOpLambda)                                                         ]',                           \n",
            "                                                                     'dropout_24[0][0]']          \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (Mu  (None, None, 50)             10200     ['add_1[0][0]']               \n",
            " ltiHeadAttention)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_4 (Mu  (None, None, 50)             10200     ['add_1[0][0]']               \n",
            " ltiHeadAttention)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_5 (Mu  (None, None, 50)             10200     ['add_1[0][0]']               \n",
            " ltiHeadAttention)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_6 (Mu  (None, None, 50)             10200     ['add_1[0][0]']               \n",
            " ltiHeadAttention)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_7 (Mu  (None, None, 50)             10200     ['add_1[0][0]']               \n",
            " ltiHeadAttention)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_8 (Mu  (None, None, 50)             10200     ['add_1[0][0]']               \n",
            " ltiHeadAttention)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_9 (Mu  (None, None, 50)             10200     ['add_1[0][0]']               \n",
            " ltiHeadAttention)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_10 (M  (None, None, 50)             10200     ['add_1[0][0]']               \n",
            " ultiHeadAttention)                                                                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, None, 100)            60400     ['multi_head_attention_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " layer_normalization_23 (La  (None, 97, 50)               100       ['tf.__operators__.add_23[0][0\n",
            " yerNormalization)                                                  ]']                           \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, None, 100)            60400     ['multi_head_attention_3[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               (None, None, 100)            60400     ['multi_head_attention_4[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)               (None, None, 100)            60400     ['multi_head_attention_5[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)               (None, None, 100)            60400     ['multi_head_attention_6[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)               (None, None, 100)            60400     ['multi_head_attention_7[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " lstm_6 (LSTM)               (None, None, 100)            60400     ['multi_head_attention_8[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " lstm_7 (LSTM)               (None, None, 100)            60400     ['multi_head_attention_9[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " lstm_8 (LSTM)               (None, None, 100)            60400     ['multi_head_attention_10[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " attention (Attention)       (None, 100)                  10100     ['lstm[0][0]']                \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)          (None, 50)                   0         ['layer_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " attention_1 (Attention)     (None, 100)                  10100     ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            " attention_2 (Attention)     (None, 100)                  10100     ['lstm_2[0][0]']              \n",
            "                                                                                                  \n",
            " attention_3 (Attention)     (None, 100)                  10100     ['lstm_3[0][0]']              \n",
            "                                                                                                  \n",
            " attention_4 (Attention)     (None, 100)                  10100     ['lstm_4[0][0]']              \n",
            "                                                                                                  \n",
            " attention_5 (Attention)     (None, 100)                  10100     ['lstm_5[0][0]']              \n",
            "                                                                                                  \n",
            " attention_6 (Attention)     (None, 100)                  10100     ['lstm_6[0][0]']              \n",
            "                                                                                                  \n",
            " attention_7 (Attention)     (None, 100)                  10100     ['lstm_7[0][0]']              \n",
            "                                                                                                  \n",
            " attention_8 (Attention)     (None, 100)                  10100     ['lstm_8[0][0]']              \n",
            "                                                                                                  \n",
            " multi_head_attention_pe (M  (None, None, 50)             15200     ['attention[0][0]',           \n",
            " ultiHeadAttention_PE)                                               'lambda_11[0][0]']           \n",
            "                                                                                                  \n",
            " multi_head_attention_pe_1   (None, None, 50)             15200     ['attention_1[0][0]',         \n",
            " (MultiHeadAttention_PE)                                             'lambda_11[0][0]']           \n",
            "                                                                                                  \n",
            " multi_head_attention_pe_2   (None, None, 50)             15200     ['attention_2[0][0]',         \n",
            " (MultiHeadAttention_PE)                                             'lambda_11[0][0]']           \n",
            "                                                                                                  \n",
            " multi_head_attention_pe_3   (None, None, 50)             15200     ['attention_3[0][0]',         \n",
            " (MultiHeadAttention_PE)                                             'lambda_11[0][0]']           \n",
            "                                                                                                  \n",
            " multi_head_attention_pe_4   (None, None, 50)             15200     ['attention_4[0][0]',         \n",
            " (MultiHeadAttention_PE)                                             'lambda_11[0][0]']           \n",
            "                                                                                                  \n",
            " multi_head_attention_pe_5   (None, None, 50)             15200     ['attention_5[0][0]',         \n",
            " (MultiHeadAttention_PE)                                             'lambda_11[0][0]']           \n",
            "                                                                                                  \n",
            " multi_head_attention_pe_6   (None, None, 50)             15200     ['attention_6[0][0]',         \n",
            " (MultiHeadAttention_PE)                                             'lambda_11[0][0]']           \n",
            "                                                                                                  \n",
            " multi_head_attention_pe_7   (None, None, 50)             15200     ['attention_7[0][0]',         \n",
            " (MultiHeadAttention_PE)                                             'lambda_11[0][0]']           \n",
            "                                                                                                  \n",
            " multi_head_attention_pe_8   (None, None, 50)             15200     ['attention_8[0][0]',         \n",
            " (MultiHeadAttention_PE)                                             'lambda_11[0][0]']           \n",
            "                                                                                                  \n",
            " lstm_9 (LSTM)               (None, None, 100)            60400     ['multi_head_attention_pe[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " lstm_10 (LSTM)              (None, None, 100)            60400     ['multi_head_attention_pe_1[0]\n",
            "                                                                    [0]']                         \n",
            "                                                                                                  \n",
            " lstm_11 (LSTM)              (None, None, 100)            60400     ['multi_head_attention_pe_2[0]\n",
            "                                                                    [0]']                         \n",
            "                                                                                                  \n",
            " lstm_12 (LSTM)              (None, None, 100)            60400     ['multi_head_attention_pe_3[0]\n",
            "                                                                    [0]']                         \n",
            "                                                                                                  \n",
            " lstm_13 (LSTM)              (None, None, 100)            60400     ['multi_head_attention_pe_4[0]\n",
            "                                                                    [0]']                         \n",
            "                                                                                                  \n",
            " lstm_14 (LSTM)              (None, None, 100)            60400     ['multi_head_attention_pe_5[0]\n",
            "                                                                    [0]']                         \n",
            "                                                                                                  \n",
            " lstm_15 (LSTM)              (None, None, 100)            60400     ['multi_head_attention_pe_6[0]\n",
            "                                                                    [0]']                         \n",
            "                                                                                                  \n",
            " lstm_16 (LSTM)              (None, None, 100)            60400     ['multi_head_attention_pe_7[0]\n",
            "                                                                    [0]']                         \n",
            "                                                                                                  \n",
            " lstm_17 (LSTM)              (None, None, 100)            60400     ['multi_head_attention_pe_8[0]\n",
            "                                                                    [0]']                         \n",
            "                                                                                                  \n",
            " attention_9 (Attention)     (None, 100)                  10100     ['lstm_9[0][0]']              \n",
            "                                                                                                  \n",
            " linguistic_input (InputLay  [(None, 51)]                 0         []                            \n",
            " er)                                                                                              \n",
            "                                                                                                  \n",
            " readability_input (InputLa  [(None, 35)]                 0         []                            \n",
            " yer)                                                                                             \n",
            "                                                                                                  \n",
            " attention_10 (Attention)    (None, 100)                  10100     ['lstm_10[0][0]']             \n",
            "                                                                                                  \n",
            " attention_11 (Attention)    (None, 100)                  10100     ['lstm_11[0][0]']             \n",
            "                                                                                                  \n",
            " attention_12 (Attention)    (None, 100)                  10100     ['lstm_12[0][0]']             \n",
            "                                                                                                  \n",
            " attention_13 (Attention)    (None, 100)                  10100     ['lstm_13[0][0]']             \n",
            "                                                                                                  \n",
            " attention_14 (Attention)    (None, 100)                  10100     ['lstm_14[0][0]']             \n",
            "                                                                                                  \n",
            " attention_15 (Attention)    (None, 100)                  10100     ['lstm_15[0][0]']             \n",
            "                                                                                                  \n",
            " attention_16 (Attention)    (None, 100)                  10100     ['lstm_16[0][0]']             \n",
            "                                                                                                  \n",
            " attention_17 (Attention)    (None, 100)                  10100     ['lstm_17[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 186)                  0         ['attention_9[0][0]',         \n",
            "                                                                     'linguistic_input[0][0]',    \n",
            "                                                                     'readability_input[0][0]']   \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 186)                  0         ['attention_10[0][0]',        \n",
            " )                                                                   'linguistic_input[0][0]',    \n",
            "                                                                     'readability_input[0][0]']   \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 186)                  0         ['attention_11[0][0]',        \n",
            " )                                                                   'linguistic_input[0][0]',    \n",
            "                                                                     'readability_input[0][0]']   \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 186)                  0         ['attention_12[0][0]',        \n",
            " )                                                                   'linguistic_input[0][0]',    \n",
            "                                                                     'readability_input[0][0]']   \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 186)                  0         ['attention_13[0][0]',        \n",
            " )                                                                   'linguistic_input[0][0]',    \n",
            "                                                                     'readability_input[0][0]']   \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 186)                  0         ['attention_14[0][0]',        \n",
            " )                                                                   'linguistic_input[0][0]',    \n",
            "                                                                     'readability_input[0][0]']   \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate  (None, 186)                  0         ['attention_15[0][0]',        \n",
            " )                                                                   'linguistic_input[0][0]',    \n",
            "                                                                     'readability_input[0][0]']   \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate  (None, 186)                  0         ['attention_16[0][0]',        \n",
            " )                                                                   'linguistic_input[0][0]',    \n",
            "                                                                     'readability_input[0][0]']   \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate  (None, 186)                  0         ['attention_17[0][0]',        \n",
            " )                                                                   'linguistic_input[0][0]',    \n",
            "                                                                     'readability_input[0][0]']   \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 1, 186)               0         ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)         (None, 1, 186)               0         ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)         (None, 1, 186)               0         ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)         (None, 1, 186)               0         ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " reshape_4 (Reshape)         (None, 1, 186)               0         ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            " reshape_5 (Reshape)         (None, 1, 186)               0         ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " reshape_6 (Reshape)         (None, 1, 186)               0         ['concatenate_6[0][0]']       \n",
            "                                                                                                  \n",
            " reshape_7 (Reshape)         (None, 1, 186)               0         ['concatenate_7[0][0]']       \n",
            "                                                                                                  \n",
            " reshape_8 (Reshape)         (None, 1, 186)               0         ['concatenate_8[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate  (None, 9, 186)               0         ['reshape[0][0]',             \n",
            " )                                                                   'reshape_1[0][0]',           \n",
            "                                                                     'reshape_2[0][0]',           \n",
            "                                                                     'reshape_3[0][0]',           \n",
            "                                                                     'reshape_4[0][0]',           \n",
            "                                                                     'reshape_5[0][0]',           \n",
            "                                                                     'reshape_6[0][0]',           \n",
            "                                                                     'reshape_7[0][0]',           \n",
            "                                                                     'reshape_8[0][0]']           \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
            " SlicingOpLambda)                                                                                 \n",
            "                                                                                                  \n",
            " masked_selection (MaskedSe  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
            " lection)                                                                                         \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " masked_selection_1 (Masked  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
            " Selection)                                                                                       \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_2  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " masked_selection_2 (Masked  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
            " Selection)                                                                                       \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_3  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " masked_selection_3 (Masked  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
            " Selection)                                                                                       \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_4  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " masked_selection_4 (Masked  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
            " Selection)                                                                                       \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_5  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " masked_selection_5 (Masked  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
            " Selection)                                                                                       \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_6  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " masked_selection_6 (Masked  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
            " Selection)                                                                                       \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_7  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " masked_selection_7 (Masked  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
            " Selection)                                                                                       \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_8  (None, 1, 186)               0         ['concatenate_9[0][0]']       \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " masked_selection_8 (Masked  (None, None, 186)            0         ['concatenate_9[0][0]']       \n",
            " Selection)                                                                                       \n",
            "                                                                                                  \n",
            " attention_18 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem[0][\n",
            "                                                                    0]',                          \n",
            "                                                                     'masked_selection[0][0]']    \n",
            "                                                                                                  \n",
            " attention_19 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_1[0\n",
            "                                                                    ][0]',                        \n",
            "                                                                     'masked_selection_1[0][0]']  \n",
            "                                                                                                  \n",
            " attention_20 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_2[0\n",
            "                                                                    ][0]',                        \n",
            "                                                                     'masked_selection_2[0][0]']  \n",
            "                                                                                                  \n",
            " attention_21 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_3[0\n",
            "                                                                    ][0]',                        \n",
            "                                                                     'masked_selection_3[0][0]']  \n",
            "                                                                                                  \n",
            " attention_22 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_4[0\n",
            "                                                                    ][0]',                        \n",
            "                                                                     'masked_selection_4[0][0]']  \n",
            "                                                                                                  \n",
            " attention_23 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_5[0\n",
            "                                                                    ][0]',                        \n",
            "                                                                     'masked_selection_5[0][0]']  \n",
            "                                                                                                  \n",
            " attention_24 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_6[0\n",
            "                                                                    ][0]',                        \n",
            "                                                                     'masked_selection_6[0][0]']  \n",
            "                                                                                                  \n",
            " attention_25 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_7[0\n",
            "                                                                    ][0]',                        \n",
            "                                                                     'masked_selection_7[0][0]']  \n",
            "                                                                                                  \n",
            " attention_26 (Attention)    (None, 1, 186)               0         ['tf.__operators__.getitem_8[0\n",
            "                                                                    ][0]',                        \n",
            "                                                                     'masked_selection_8[0][0]']  \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem[0][\n",
            " e)                                                                 0]',                          \n",
            "                                                                     'attention_18[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem_1[0\n",
            " e)                                                                 ][0]',                        \n",
            "                                                                     'attention_19[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem_2[0\n",
            " e)                                                                 ][0]',                        \n",
            "                                                                     'attention_20[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem_3[0\n",
            " e)                                                                 ][0]',                        \n",
            "                                                                     'attention_21[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem_4[0\n",
            " e)                                                                 ][0]',                        \n",
            "                                                                     'attention_22[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem_5[0\n",
            " e)                                                                 ][0]',                        \n",
            "                                                                     'attention_23[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem_6[0\n",
            " e)                                                                 ][0]',                        \n",
            "                                                                     'attention_24[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_17 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem_7[0\n",
            " e)                                                                 ][0]',                        \n",
            "                                                                     'attention_25[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_18 (Concatenat  (None, 1, 372)               0         ['tf.__operators__.getitem_8[0\n",
            " e)                                                                 ][0]',                        \n",
            "                                                                     'attention_26[0][0]']        \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 372)                  0         ['concatenate_10[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 372)                  0         ['concatenate_11[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 372)                  0         ['concatenate_12[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)         (None, 372)                  0         ['concatenate_13[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)         (None, 372)                  0         ['concatenate_14[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_5 (Flatten)         (None, 372)                  0         ['concatenate_15[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_6 (Flatten)         (None, 372)                  0         ['concatenate_16[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_7 (Flatten)         (None, 372)                  0         ['concatenate_17[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)         (None, 372)                  0         ['concatenate_18[0][0]']      \n",
            "                                                                                                  \n",
            " dense_112 (Dense)           (None, 1)                    373       ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dense_113 (Dense)           (None, 1)                    373       ['flatten_1[0][0]']           \n",
            "                                                                                                  \n",
            " dense_114 (Dense)           (None, 1)                    373       ['flatten_2[0][0]']           \n",
            "                                                                                                  \n",
            " dense_115 (Dense)           (None, 1)                    373       ['flatten_3[0][0]']           \n",
            "                                                                                                  \n",
            " dense_116 (Dense)           (None, 1)                    373       ['flatten_4[0][0]']           \n",
            "                                                                                                  \n",
            " dense_117 (Dense)           (None, 1)                    373       ['flatten_5[0][0]']           \n",
            "                                                                                                  \n",
            " dense_118 (Dense)           (None, 1)                    373       ['flatten_6[0][0]']           \n",
            "                                                                                                  \n",
            " dense_119 (Dense)           (None, 1)                    373       ['flatten_7[0][0]']           \n",
            "                                                                                                  \n",
            " dense_120 (Dense)           (None, 1)                    373       ['flatten_8[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_19 (Concatenat  (None, 9)                    0         ['dense_112[0][0]',           \n",
            " e)                                                                  'dense_113[0][0]',           \n",
            "                                                                     'dense_114[0][0]',           \n",
            "                                                                     'dense_115[0][0]',           \n",
            "                                                                     'dense_116[0][0]',           \n",
            "                                                                     'dense_117[0][0]',           \n",
            "                                                                     'dense_118[0][0]',           \n",
            "                                                                     'dense_119[0][0]',           \n",
            "                                                                     'dense_120[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1766207 (6.74 MB)\n",
            "Trainable params: 1766207 (6.74 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "53/53 [==============================] - 18s 90ms/step\n",
            "56/56 [==============================] - 4s 77ms/step\n",
            "CURRENT EPOCH: -1\n",
            "[DEV] AVG QWK: -0.004\n",
            "[DEV] score QWK: 0.008\n",
            "[DEV] content QWK: -0.036\n",
            "[DEV] organization QWK: 0.044\n",
            "[DEV] word_choice QWK: 0.062\n",
            "[DEV] sentence_fluency QWK: -0.068\n",
            "[DEV] conventions QWK: 0.04\n",
            "[DEV] prompt_adherence QWK: 0.013\n",
            "[DEV] language QWK: 0.037\n",
            "[DEV] narrativity QWK: -0.138\n",
            "------------------------\n",
            "[TEST] AVG QWK: -0.041\n",
            "[TEST] score QWK: 0.029\n",
            "[TEST] content QWK: -0.029\n",
            "[TEST] organization QWK: -0.001\n",
            "[TEST] word_choice QWK: 0.001\n",
            "[TEST] sentence_fluency QWK: -0.153\n",
            "[TEST] conventions QWK: -0.092\n",
            "------------------------\n",
            "[BEST TEST] AVG QWK: -0.041, {epoch}: -1\n",
            "[BEST TEST] score QWK: 0.029\n",
            "[BEST TEST] content QWK: -0.029\n",
            "[BEST TEST] organization QWK: -0.001\n",
            "[BEST TEST] word_choice QWK: 0.001\n",
            "[BEST TEST] sentence_fluency QWK: -0.153\n",
            "[BEST TEST] conventions QWK: -0.092\n",
            "--------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "train_features_list = [X_train_pos, X_train_prompt, X_train_prompt_pos, X_train_linguistic_features, X_train_readability]\n",
        "dev_features_list = [X_dev_pos, X_dev_prompt, X_dev_prompt_pos, X_dev_linguistic_features, X_dev_readability]\n",
        "test_features_list = [X_test_pos, X_test_prompt, X_test_prompt_pos, X_test_linguistic_features, X_test_readability]\n",
        "\n",
        "model = build_ProTACT(len(pos_vocab), len(word_vocab), max_sentnum, max_sentlen,\n",
        "                  X_train_readability.shape[1],\n",
        "                  X_train_linguistic_features.shape[1],\n",
        "                  configs, Y_train.shape[1], num_heads, embed_table)\n",
        "\n",
        "evaluator = AllAttEvaluator(test_prompt_id, dev_data['prompt_ids'], test_data['prompt_ids'], dev_features_list,\n",
        "                            test_features_list, Y_dev, Y_test, seed)\n",
        "\n",
        "evaluator.evaluate(model, -1, print_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a9aac81",
      "metadata": {
        "id": "2a9aac81"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b247461",
      "metadata": {
        "id": "0b247461"
      },
      "outputs": [],
      "source": [
        "# class CustomHistory(keras.callbacks.Callback):\n",
        "#     def init(self):\n",
        "#         self.train_loss = []\n",
        "#         self.val_loss = []\n",
        "#         self.train_acc = []\n",
        "#         self.val_acc = []\n",
        "\n",
        "#     def on_epoch_end(self, batch, logs={}):\n",
        "#         self.train_loss.append(logs.get('loss'))\n",
        "#         self.val_loss.append(logs.get('val_loss'))\n",
        "#         self.train_acc.append(logs.get('acc'))\n",
        "#         self.val_acc.append(logs.get('val_acc'))\n",
        "# custom_hist = CustomHistory()\n",
        "# custom_hist.init()\n",
        "\n",
        "#  for ii in range(epochs):\n",
        "#     print('Epoch %s/%s' % (str(ii + 1), epochs))\n",
        "#     start_time = time.time()\n",
        "#     model.fit(\n",
        "#         train_features_list,\n",
        "#         Y_train, batch_size=batch_size, epochs=5, verbose=0, shuffle=True, validation_data=(dev_features_list,Y_dev),callbacks=[custom_hist,checkpoint])\n",
        "#     tt_time = time.time() - start_time\n",
        "#     print(\"Training one epoch in %.3f s\" % tt_time)\n",
        "#     evaluator.evaluate(model, ii + 1)\n",
        "#     print(\"Train Loss: \", custom_hist.train_loss[-1], \"|| Val Loss: \", custom_hist.val_loss[-1])\n",
        "\n",
        "# evaluator.print_final_info()\n",
        "\n",
        "'''# show the loss as the graph\n",
        "fig, loss_graph = plt.subplots()\n",
        "loss_graph.plot(custom_hist.train_loss,'y',label='train loss')\n",
        "loss_graph.plot(custom_hist.val_loss,'r',label='val loss')\n",
        "loss_graph.set_xlabel('epoch')\n",
        "loss_graph.set_ylabel('loss')\n",
        "plt.savefig(str('images/protact/test_prompt_'+ str(test_prompt_id) + '_seed_' + str(seed) + '_loss.png'))'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "90c5dd61",
      "metadata": {
        "id": "90c5dd61"
      },
      "outputs": [],
      "source": [
        "# 저장한 체크포인트 있다면: 이어서 학습 시작할때\n",
        "# Checkpoint 폴더 안에 있는 .h5 파일 지울것\n",
        "# model.load_weights('Checkpoint/tensor{epoch}')\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    # epoch 마다 파일명 다르게 저장\n",
        "    filepath='Checkpoint/bestmodel{epoch}.weights.h5',\n",
        "\n",
        "    # epoch 마다 weights 들만 저장\n",
        "    save_freq='epoch',\n",
        "    save_weights_only = True,\n",
        "\n",
        "    # validation accruary 가 최대일때만 저장\n",
        "    monitor='val_loss',\n",
        "    mode='min'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb7f3c27",
      "metadata": {
        "id": "eb7f3c27"
      },
      "outputs": [],
      "source": [
        "class CustomHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "        self.epoch_times = []\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.train_loss.append(logs.get('loss'))\n",
        "        self.val_loss.append(logs.get('val_loss'))\n",
        "        epoch_time = time.time() - self.start_time\n",
        "        self.epoch_times.append(epoch_time)\n",
        "        print(f\"Epoch {epoch + 1}: Train Loss: {logs.get('loss')} || Val Loss: {logs.get('val_loss')}\")\n",
        "        print(f\"Epoch {epoch + 1} completed in {epoch_time:.3f} seconds\")\n",
        "\n",
        "        # Evaluate the model (you might need to adjust this to your specific evaluation function)\n",
        "        evaluator.evaluate(self.model, epoch + 1)\n",
        "\n",
        "custom_hist = CustomHistory()\n",
        "model.fit(\n",
        "    train_features_list,\n",
        "    Y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    verbose=1,\n",
        "    shuffle=True,\n",
        "    validation_data=(dev_features_list, Y_dev),\n",
        "    callbacks=[custom_hist, checkpoint]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomHistory(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, test_prompt_id, seed, save_graphs_freq=10, save_dir='training_data'):\n",
        "        super(CustomHistory, self).__init__()\n",
        "        self.test_prompt_id = test_prompt_id\n",
        "        self.seed = seed\n",
        "        self.save_graphs_freq = save_graphs_freq\n",
        "        self.save_dir = save_dir\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "        self.train_acc = []\n",
        "        self.val_acc = []\n",
        "        self.epoch_times = []\n",
        "        self.qwk_dev = []\n",
        "        self.qwk_test = []\n",
        "        self.kappa_dev_history = []\n",
        "        self.kappa_test_history = []\n",
        "\n",
        "        # Create directory if it does not exist\n",
        "        os.makedirs(self.save_dir, exist_ok=True)\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.train_loss.append(logs.get('loss'))\n",
        "        self.val_loss.append(logs.get('val_loss'))\n",
        "        self.train_acc.append(logs.get('acc'))\n",
        "        self.val_acc.append(logs.get('val_acc'))\n",
        "        epoch_time = time.time() - self.start_time\n",
        "        self.epoch_times.append(epoch_time)\n",
        "        print(f\"Epoch {epoch + 1}: Train Loss: {logs.get('loss')} || Val Loss: {logs.get('val_loss')}\")\n",
        "        print(f\"Epoch {epoch + 1} completed in {epoch_time:.3f} seconds\")\n",
        "\n",
        "        # Evaluate the model and get QWK values\n",
        "        evaluation_results = evaluator.evaluate(self.model, epoch + 1)\n",
        "        self.qwk_dev.append(evaluation_results[\"dev_kappa_mean\"])\n",
        "        self.qwk_test.append(evaluation_results[\"test_kappa_mean\"])\n",
        "        self.kappa_dev_history.append(evaluation_results[\"kappa_dev\"])\n",
        "        self.kappa_test_history.append(evaluation_results[\"kappa_test\"])\n",
        "\n",
        "        # Save data to .pkl file\n",
        "        self.save_to_pickle(epoch + 1)\n",
        "\n",
        "        # Save loss graph\n",
        "        if (epoch + 1) % self.save_graphs_freq == 0 or (epoch + 1) == 100:\n",
        "            self.save_loss_graph(epoch + 1)\n",
        "\n",
        "    def save_to_pickle(self, epoch):\n",
        "        data = {\n",
        "            'train_loss': self.train_loss,\n",
        "            'val_loss': self.val_loss,\n",
        "            'train_acc': self.train_acc,\n",
        "            'val_acc': self.val_acc,\n",
        "            'epoch_times': self.epoch_times,\n",
        "            'qwk_dev': self.qwk_dev,\n",
        "            'qwk_test': self.qwk_test,\n",
        "            'kappa_dev_history': self.kappa_dev_history,\n",
        "            'kappa_test_history': self.kappa_test_history\n",
        "        }\n",
        "        filepath = os.path.join(self.save_dir, f'training_data_epoch_{epoch}.pkl')\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(data, f)\n",
        "\n",
        "    def save_loss_graph(self, epoch):\n",
        "        # Plot and save the loss graph\n",
        "        fig, loss_graph = plt.subplots()\n",
        "        loss_graph.plot(self.train_loss, 'y', label='train loss')\n",
        "        loss_graph.plot(self.val_loss, 'r', label='val loss')\n",
        "        loss_graph.set_xlabel('epoch')\n",
        "        loss_graph.set_ylabel('loss')\n",
        "        loss_graph.set_title('Train and Validation Loss')\n",
        "        loss_graph.legend()\n",
        "        filepath = os.path.join(self.save_dir, f'test_prompt_{self.test_prompt_id}_seed_{self.seed}_loss_epoch_{epoch}.png')\n",
        "        plt.savefig(filepath)\n",
        "        plt.close()\n",
        "custom_hist = CustomHistory(test_prompt_id=test_prompt_id, seed=seed, save_dir='training_data')\n"
      ],
      "metadata": {
        "id": "gsVDC29gxuc3"
      },
      "id": "gsVDC29gxuc3",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint 파일들 확인\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Checkpoint directory\n",
        "checkpoint_dir = 'Checkpoint'\n",
        "checkpoint_files = glob.glob(os.path.join(checkpoint_dir, 'bestmodel_epoch_*.h5'))\n",
        "\n",
        "# Sort the checkpoint files by epoch number\n",
        "checkpoint_files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
        "\n",
        "# Get the latest checkpoint file\n",
        "latest_checkpoint = checkpoint_files[-1] if checkpoint_files else None\n",
        "print(f'Latest checkpoint: {latest_checkpoint}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ckw58fRBxz4i",
        "outputId": "3f827a66-f4e4-4da4-cc3d-e48f8e6cfda6"
      },
      "id": "Ckw58fRBxz4i",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest checkpoint: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if there is a latest checkpoint\n",
        "initial_epoch = 0\n",
        "load = False # True -> 학습 재개\n",
        "if latest_checkpoint and load:\n",
        "    print(f'Loading weights from {latest_checkpoint}')\n",
        "    model.load_weights(latest_checkpoint)\n",
        "    initial_epoch = int(latest_checkpoint.split('_')[-1].split('.')[0]) if latest_checkpoint else 0\n",
        "else:\n",
        "    print('No latest checkpoint found. Starting from scratch.')\n",
        "\n",
        "# 모델 학습 코드\n",
        "model.fit(\n",
        "    train_features_list,\n",
        "    Y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=50, # 적절한 에포크 수로 설정\n",
        "    verbose=1,\n",
        "    shuffle=True,\n",
        "    validation_data=(dev_features_list, Y_dev),\n",
        "    callbacks=[custom_hist, checkpoint],\n",
        "    initial_epoch=initial_epoch  # 학습을 재개할 에포크\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "id": "parXd_3Px0bM",
        "outputId": "dce83dcb-26ed-40bb-9f04-ec83b9b7f8bf"
      },
      "id": "parXd_3Px0bM",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No latest checkpoint found. Starting from scratch.\n",
            "Epoch 1/50\n",
            "952/952 [==============================] - ETA: 0s - loss: 0.0177Epoch 1: Train Loss: 0.01767650619149208 || Val Loss: 0.015156797133386135\n",
            "Epoch 1 completed in 274.045 seconds\n",
            "53/53 [==============================] - 5s 90ms/step\n",
            "56/56 [==============================] - 4s 72ms/step\n",
            "CURRENT EPOCH: 1\n",
            "[DEV] AVG QWK: 0.581\n",
            "[DEV] score QWK: 0.709\n",
            "[DEV] content QWK: 0.562\n",
            "[DEV] organization QWK: 0.599\n",
            "[DEV] word_choice QWK: 0.571\n",
            "[DEV] sentence_fluency QWK: 0.514\n",
            "[DEV] conventions QWK: 0.561\n",
            "[DEV] prompt_adherence QWK: 0.559\n",
            "[DEV] language QWK: 0.568\n",
            "[DEV] narrativity QWK: 0.586\n",
            "------------------------\n",
            "[TEST] AVG QWK: 0.588\n",
            "[TEST] score QWK: 0.814\n",
            "[TEST] content QWK: 0.62\n",
            "[TEST] organization QWK: 0.529\n",
            "[TEST] word_choice QWK: 0.566\n",
            "[TEST] sentence_fluency QWK: 0.521\n",
            "[TEST] conventions QWK: 0.48\n",
            "------------------------\n",
            "[BEST TEST] AVG QWK: 0.588, {epoch}: 1\n",
            "[BEST TEST] score QWK: 0.814\n",
            "[BEST TEST] content QWK: 0.62\n",
            "[BEST TEST] organization QWK: 0.529\n",
            "[BEST TEST] word_choice QWK: 0.566\n",
            "[BEST TEST] sentence_fluency QWK: 0.521\n",
            "[BEST TEST] conventions QWK: 0.48\n",
            "--------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-cefc58146597>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 모델 학습 코드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtrain_features_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-fcb853ae0b72>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Evaluate the model and get QWK values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mevaluation_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqwk_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dev_kappa_mean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqwk_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_kappa_mean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkappa_dev_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kappa_dev\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01487fa8",
      "metadata": {
        "id": "01487fa8"
      },
      "outputs": [],
      "source": [
        "# 실행 X\n",
        "# TEST: 위에서 진행된곳 까지 결과가 같다.\n",
        "model.load_weights('Checkpoint/bestmodel1.h5')\n",
        "evaluator.evaluate(model,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86de4013",
      "metadata": {
        "id": "86de4013"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}